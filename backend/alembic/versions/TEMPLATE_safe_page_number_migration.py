"""
TEMPLATE: å®‰å…¨çš„ page_number â†’ page_numbers è¿ç§»
è¿™æ˜¯ä¸€ä¸ªæ”¹è¿›çš„è¿ç§»æ¨¡æ¿ï¼ŒåŒ…å«æ•°æ®è¿ç§»é€»è¾‘

âš ï¸ æ³¨æ„ï¼šè¿™æ˜¯æ¨¡æ¿æ–‡ä»¶ï¼Œä¸ä¼šè¢« Alembic è‡ªåŠ¨æ‰§è¡Œ
å¦‚æœéœ€è¦é‡æ–°è¿ç§»ï¼Œè¯·å¤åˆ¶æ­¤æ¨¡æ¿å¹¶ä¿®æ”¹ revision ID
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers - å¦‚æœå®é™…ä½¿ç”¨ï¼Œéœ€è¦ä¿®æ”¹è¿™äº›
revision: str = 'TEMPLATE_SAFE_MIGRATION'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """
    å®‰å…¨çš„å‡çº§æµç¨‹ï¼š
    1. æ·»åŠ æ–°åˆ—
    2. è¿ç§»æ•°æ®
    3. éªŒè¯æ•°æ®
    4. åˆ é™¤æ—§åˆ—
    """
    connection = op.get_bind()

    # Step 1: æ·»åŠ æ–°åˆ—ï¼ˆå…è®¸ NULLï¼‰
    with op.batch_alter_table('document_chunks', schema=None) as batch_op:
        batch_op.add_column(sa.Column('page_numbers', sa.JSON(), nullable=True))
        batch_op.add_column(sa.Column('bbox', sa.JSON(), nullable=True))
        batch_op.add_column(sa.Column('quality_score', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('pipeline_version', sa.String(length=50), nullable=True))

    print("âœ“ æ–°åˆ—å·²æ·»åŠ ")

    # Step 2: è¿ç§»æ•°æ®ï¼ˆå…³é”®æ­¥éª¤ï¼ï¼‰
    print("å¼€å§‹è¿ç§» page_number æ•°æ®...")

    # ä½¿ç”¨åŸç”Ÿ SQL è¿›è¡Œæ•°æ®è¿ç§»
    connection.execute(sa.text("""
        UPDATE document_chunks
        SET page_numbers = jsonb_build_array(page_number)
        WHERE page_number IS NOT NULL
    """))

    print("âœ“ æ•°æ®è¿ç§»å®Œæˆ")

    # Step 3: éªŒè¯æ•°æ®
    result = connection.execute(sa.text("""
        SELECT
            COUNT(*) as total,
            COUNT(page_number) as old_column_count,
            COUNT(page_numbers) as new_column_count
        FROM document_chunks
    """))

    stats = result.fetchone()
    print(f"éªŒè¯ç»“æœï¼šæ€»è®°å½• {stats[0]}, æ—§åˆ—æœ‰å€¼ {stats[1]}, æ–°åˆ—æœ‰å€¼ {stats[2]}")

    if stats[1] != stats[2]:
        raise Exception(
            f"æ•°æ®è¿ç§»éªŒè¯å¤±è´¥ï¼æ—§åˆ—æœ‰ {stats[1]} æ¡è®°å½•ï¼Œä½†æ–°åˆ—åªæœ‰ {stats[2]} æ¡è®°å½•ã€‚"
        )

    print("âœ“ æ•°æ®éªŒè¯é€šè¿‡")

    # Step 4: åˆ é™¤æ—§åˆ—
    with op.batch_alter_table('document_chunks', schema=None) as batch_op:
        batch_op.drop_column('page_number')

    print("âœ“ æ—§åˆ—å·²åˆ é™¤")

    # Step 5: æ›´æ–°ç´¢å¼•
    with op.batch_alter_table('document_chunks', schema=None) as batch_op:
        # åˆ é™¤æ—§ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            batch_op.drop_index('idx_document_chunks_chunk_index')
        except:
            pass

        try:
            batch_op.drop_index('idx_document_chunks_deleted_at')
        except:
            pass

        try:
            batch_op.drop_index('idx_document_chunks_file_id')
        except:
            pass

        try:
            batch_op.drop_index('idx_document_chunks_user_id')
        except:
            pass

        # åˆ›å»ºæ–°ç´¢å¼•
        batch_op.create_index(
            batch_op.f('ix_document_chunks_deleted_at'),
            ['deleted_at'],
            unique=False
        )
        batch_op.create_index(
            batch_op.f('ix_document_chunks_file_id'),
            ['file_id'],
            unique=False
        )
        batch_op.create_index(
            batch_op.f('ix_document_chunks_user_id'),
            ['user_id'],
            unique=False
        )
        batch_op.create_index(
            batch_op.f('idx_document_chunks_chunk_index'),
            ['file_id', 'chunk_index'],
            unique=True
        )

    print("âœ“ ç´¢å¼•å·²æ›´æ–°")
    print("ğŸ‰ è¿ç§»å®Œæˆï¼")


def downgrade() -> None:
    """
    é™çº§æµç¨‹ï¼šæ¢å¤æ—§ç»“æ„
    âš ï¸ æ³¨æ„ï¼šé™çº§ä¼šä¸¢å¤±å¤šé¡µåˆ‡ç‰‡ä¿¡æ¯ï¼ˆpage_numbers æ˜¯æ•°ç»„ï¼Œpage_number æ˜¯å•ä¸ªå€¼ï¼‰
    """
    connection = op.get_bind()

    # Step 1: æ·»åŠ å›æ—§åˆ—
    with op.batch_alter_table('document_chunks', schema=None) as batch_op:
        batch_op.add_column(
            sa.Column('page_number', sa.INTEGER(), autoincrement=False, nullable=True)
        )

    print("âœ“ æ—§åˆ—å·²æ·»åŠ å›æ¥")

    # Step 2: å°è¯•æ¢å¤æ•°æ®ï¼ˆåªå–ç¬¬ä¸€ä¸ªé¡µç ï¼‰
    print("å¼€å§‹æ¢å¤æ•°æ®...")

    connection.execute(sa.text("""
        UPDATE document_chunks
        SET page_number = (page_numbers->0)::int
        WHERE page_numbers IS NOT NULL
        AND jsonb_array_length(page_numbers) > 0
    """))

    print("âš  æ•°æ®å·²æ¢å¤åˆ°æ—§æ ¼å¼ï¼ˆå¤šé¡µåˆ‡ç‰‡åªä¿ç•™äº†ç¬¬ä¸€é¡µï¼‰")

    # Step 3: åˆ é™¤æ–°åˆ—
    with op.batch_alter_table('document_chunks', schema=None) as batch_op:
        batch_op.drop_column('pipeline_version')
        batch_op.drop_column('quality_score')
        batch_op.drop_column('bbox')
        batch_op.drop_column('page_numbers')

    print("âœ“ æ–°åˆ—å·²åˆ é™¤")
    print("ğŸ‰ é™çº§å®Œæˆï¼")


# ==========================================
# ä½¿ç”¨è¯´æ˜
# ==========================================
"""
å¦‚æœéœ€è¦å®é™…ä½¿ç”¨æ­¤æ¨¡æ¿ï¼š

1. å¤åˆ¶æ­¤æ–‡ä»¶å¹¶é‡å‘½åï¼š
   cp TEMPLATE_safe_page_number_migration.py xxxx_safe_page_migration.py

2. ç”Ÿæˆæ–°çš„ revision IDï¼š
   alembic revision --autogenerate -m "safe page migration"

3. å°†æ­¤æ¨¡æ¿çš„ upgrade() å’Œ downgrade() å¤åˆ¶åˆ°æ–°ç”Ÿæˆçš„æ–‡ä»¶

4. è¿è¡Œè¿ç§»ï¼š
   alembic upgrade head

5. éªŒè¯ç»“æœï¼š
   python scripts/migrate_page_numbers.py
"""
