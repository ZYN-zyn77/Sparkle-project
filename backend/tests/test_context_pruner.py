"""
ContextPruner åŠŸèƒ½æµ‹è¯•

æµ‹è¯•åœºæ™¯:
1. å†å²æ¶ˆæ¯å°‘äºé˜ˆå€¼ - ç›´æ¥è¿”å›
2. å†å²æ¶ˆæ¯åœ¨é˜ˆå€¼ä¹‹é—´ - æ»‘åŠ¨çª—å£
3. å†å²æ¶ˆæ¯è¶…è¿‡é˜ˆå€¼ - è§¦å‘æ€»ç»“
4. æ€»ç»“ç¼“å­˜æœºåˆ¶
5. ä¸ Orchestrator é›†æˆ
"""

import asyncio
import json
import time
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
import redis.asyncio as redis

from app.orchestration.context_pruner import ContextPruner
from app.orchestration.summarization_worker import SummarizationWorker
from app.orchestration.orchestrator import ChatOrchestrator


class TestContextPruner:
    """ContextPruner å•å…ƒæµ‹è¯•"""

    @pytest.fixture
    async def redis_client(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ Redis å®¢æˆ·ç«¯"""
        client = redis.from_url("redis://localhost:6379/15", decode_responses=False)
        try:
            await client.ping()
            yield client
            await client.flushdb()  # æ¸…ç†æµ‹è¯•æ•°æ®
        except:
            pytest.skip("Redis not available")
        finally:
            await client.close()

    @pytest.fixture
    def context_pruner(self, redis_client):
        """åˆ›å»º ContextPruner å®ä¾‹"""
        return ContextPruner(
            redis_client=redis_client,
            max_history_messages=5,
            summary_threshold=10,
            summary_cache_ttl=3600
        )

    @pytest.mark.asyncio
    async def test_small_history(self, context_pruner, redis_client):
        """æµ‹è¯•ï¼šå†å²æ¶ˆæ¯å°‘äºé˜ˆå€¼ï¼Œç›´æ¥è¿”å›"""
        session_id = "test_session_small"

        # å‡†å¤‡å°‘é‡å†å²
        history = [
            {"role": "user", "content": "ä½ å¥½", "timestamp": 1000},
            {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ", "timestamp": 1001},
            {"role": "user", "content": "æˆ‘æƒ³å­¦ä¹  Python", "timestamp": 1002},
        ]

        # å†™å…¥ Redis
        for msg in history:
            await redis_client.rpush(f"chat:history:{session_id}", json.dumps(msg))

        # è·å–ä¿®å‰ªåçš„å†å²
        result = await context_pruner.get_pruned_history(session_id, "user_123")

        # éªŒè¯
        assert result["original_count"] == 3
        assert result["pruned_count"] == 3
        assert result["summary_used"] is False
        assert result["summary"] is None
        assert len(result["messages"]) == 3

    @pytest.mark.asyncio
    async def test_sliding_window(self, context_pruner, redis_client):
        """æµ‹è¯•ï¼šä¸­ç­‰å†å²ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£"""
        session_id = "test_session_window"

        # å‡†å¤‡ 8 æ¡å†å²ï¼ˆè¶…è¿‡ max_history=5ï¼Œä½†æœªè¾¾åˆ° summary_threshold=10ï¼‰
        history = [
            {"role": "user", "content": f"æ¶ˆæ¯ {i}", "timestamp": 1000 + i}
            for i in range(8)
        ]

        for msg in history:
            await redis_client.rpush(f"chat:history:{session_id}", json.dumps(msg))

        result = await context_pruner.get_pruned_history(session_id, "user_123")

        # éªŒè¯
        assert result["original_count"] == 8
        assert result["pruned_count"] == 5
        assert result["summary_used"] is False
        assert result["summary"] is None
        assert len(result["messages"]) == 5

        # éªŒè¯æ˜¯æœ€å 5 æ¡
        assert result["messages"][0]["content"] == "æ¶ˆæ¯ 3"
        assert result["messages"][-1]["content"] == "æ¶ˆæ¯ 7"

    @pytest.mark.asyncio
    async def test_summary_trigger(self, context_pruner, redis_client):
        """æµ‹è¯•ï¼šå†å²è¶…è¿‡é˜ˆå€¼ï¼Œè§¦å‘æ€»ç»“"""
        session_id = "test_session_summary"

        # å‡†å¤‡ 15 æ¡å†å²ï¼ˆè¶…è¿‡ summary_threshold=10ï¼‰
        history = [
            {"role": "user", "content": f"æ¶ˆæ¯ {i}", "timestamp": 1000 + i}
            for i in range(15)
        ]

        for msg in history:
            await redis_client.rpush(f"chat:history:{session_id}", json.dumps(msg))

        result = await context_pruner.get_pruned_history(session_id, "user_123")

        # éªŒè¯
        assert result["original_count"] == 15
        assert result["pruned_count"] == 5  # æœ€è¿‘ 5 æ¡
        assert result["summary_used"] is True
        assert len(result["messages"]) == 5

        # éªŒè¯æ€»ç»“ä»»åŠ¡å·²æ¨é€åˆ°é˜Ÿåˆ—
        queue_len = await redis_client.llen("queue:summarization")
        assert queue_len == 1

        # éªŒè¯é˜Ÿåˆ—å†…å®¹
        task_data = await redis_client.lindex("queue:summarization", 0)
        task = json.loads(task_data)
        assert task["session_id"] == session_id
        assert len(task["history"]) == 10  # é™¤æœ€è¿‘ 5 æ¡å¤–çš„å†å²

    @pytest.mark.asyncio
    async def test_summary_cache(self, context_pruner, redis_client):
        """æµ‹è¯•ï¼šæ€»ç»“ç¼“å­˜æœºåˆ¶"""
        session_id = "test_session_cache"

        # å‡†å¤‡å†å²
        history = [
            {"role": "user", "content": f"æ¶ˆæ¯ {i}", "timestamp": 1000 + i}
            for i in range(15)
        ]

        for msg in history:
            await redis_client.rpush(f"chat:history:{session_id}", json.dumps(msg))

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ - åº”è¯¥è§¦å‘æ€»ç»“ä»»åŠ¡
        result1 = await context_pruner.get_pruned_history(session_id, "user_123")
        assert result1["summary"] is None  # ç¼“å­˜æœªå°±ç»ª

        # æ¨¡æ‹Ÿæ€»ç»“å®Œæˆï¼ˆæ‰‹åŠ¨è®¾ç½®ç¼“å­˜ï¼‰
        summary_text = "ç”¨æˆ·ä¹‹å‰è¯¢é—®äº† Python å­¦ä¹ ç›¸å…³é—®é¢˜ï¼Œæˆ‘ä»¬è®¨è®ºäº†åŸºç¡€è¯­æ³•å’Œæœ€ä½³å®è·µ"
        await redis_client.setex(f"summary:{session_id}", 3600, summary_text)

        # ç¬¬äºŒæ¬¡è°ƒç”¨ - åº”è¯¥è¿”å›ç¼“å­˜çš„æ€»ç»“
        result2 = await context_pruner.get_pruned_history(session_id, "user_123")
        assert result2["summary"] == summary_text
        assert result2["summary_used"] is True

    @pytest.mark.asyncio
    async def test_empty_history(self, context_pruner, redis_client):
        """æµ‹è¯•ï¼šæ— å†å²è®°å½•"""
        session_id = "test_session_empty"

        result = await context_pruner.get_pruned_history(session_id, "user_123")

        assert result["original_count"] == 0
        assert result["pruned_count"] == 0
        assert result["summary_used"] is False
        assert result["messages"] == []


class TestSummarizationWorker:
    """SummarizationWorker å•å…ƒæµ‹è¯•"""

    @pytest.fixture
    async def redis_client(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ Redis å®¢æˆ·ç«¯"""
        client = redis.from_url("redis://localhost:6379/15", decode_responses=False)
        try:
            await client.ping()
            yield client
            await client.flushdb()
        except:
            pytest.skip("Redis not available")
        finally:
            await client.close()

    @pytest.mark.asyncio
    async def test_worker_processes_task(self, redis_client):
        """æµ‹è¯•ï¼šWorker å¤„ç†æ€»ç»“ä»»åŠ¡"""
        worker = SummarizationWorker(redis_client, batch_size=1)

        # æ¨¡æ‹Ÿ LLM æœåŠ¡
        with patch("app.orchestration.summarization_worker.llm_service") as mock_llm:
            mock_llm.generate_summary = AsyncMock(return_value="è¿™æ˜¯ä¸€ä¸ªæ€»ç»“")

            # æ¨é€ä»»åŠ¡åˆ°é˜Ÿåˆ—
            task = {
                "session_id": "test_worker_session",
                "history": [
                    {"role": "user", "content": "ä½ å¥½", "timestamp": 1000},
                    {"role": "assistant", "content": "ä½ å¥½ï¼", "timestamp": 1001},
                ],
                "user_id": "user_123",
                "timestamp": time.time(),
                "priority": "high"
            }
            await redis_client.rpush("queue:summarization", json.dumps(task))

            # æ‰‹åŠ¨å¤„ç†ä¸€æ¬¡ä»»åŠ¡
            task_data = await redis_client.blpop("queue:summarization", timeout=1)
            if task_data:
                task_obj = json.loads(task_data[1])
                success = await worker._process_task(task_obj)

                assert success is True
                assert worker.processed_count == 1

                # éªŒè¯æ€»ç»“å·²ç¼“å­˜
                summary = await redis_client.get("summary:test_worker_session")
                assert summary is not None
                assert summary.decode("utf-8") == "è¿™æ˜¯ä¸€ä¸ªæ€»ç»“"


class TestOrchestratorIntegration:
    """Orchestrator é›†æˆæµ‹è¯•"""

    @pytest.fixture
    async def redis_client(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ Redis å®¢æˆ·ç«¯"""
        client = redis.from_url("redis://localhost:6379/15", decode_responses=False)
        try:
            await client.ping()
            yield client
            await client.flushdb()
        except:
            pytest.skip("Redis not available")
        finally:
            await client.close()

    @pytest.mark.asyncio
    async def test_build_conversation_context(self, redis_client):
        """æµ‹è¯•ï¼šOrchestrator æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        orchestrator = ChatOrchestrator(redis_client=redis_client)

        session_id = "test_orch_session"
        user_id = "user_123"

        # å‡†å¤‡å†å²
        history = [
            {"role": "user", "content": f"é—®é¢˜ {i}", "timestamp": 1000 + i}
            for i in range(12)
        ]
        for msg in history:
            await redis_client.rpush(f"chat:history:{session_id}", json.dumps(msg))

        # è°ƒç”¨ _build_conversation_context
        context = await orchestrator._build_conversation_context(session_id, user_id)

        # éªŒè¯
        assert context["original_count"] == 12
        assert context["pruned_count"] == 5
        assert context["summary_used"] is True
        assert len(context["messages"]) == 5

    @pytest.mark.asyncio
    async def test_build_user_context_with_cache(self, redis_client):
        """æµ‹è¯•ï¼šOrchestrator æ„å»ºç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
        from sqlalchemy.orm import sessionmaker

        # åˆ›å»ºå†…å­˜æ•°æ®åº“ç”¨äºæµ‹è¯•
        engine = create_async_engine("sqlite+aiosqlite:///:memory:")
        async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„æ•°æ®åº“æ¨¡å‹ï¼Œæµ‹è¯•æ—¶å¯ä»¥è·³è¿‡æˆ–ä½¿ç”¨ mock
        # ç®€åŒ–æµ‹è¯•ï¼šåªéªŒè¯ç¼“å­˜é€»è¾‘
        orchestrator = ChatOrchestrator(redis_client=redis_client)

        # éªŒè¯ ContextPruner å·²åˆå§‹åŒ–
        assert orchestrator.context_pruner is not None
        assert orchestrator.context_pruner.redis == redis_client


# è¿è¡Œæµ‹è¯•çš„è¾…åŠ©å‡½æ•°
async def run_all_tests():
    """æ‰‹åŠ¨è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰"""
    print("ğŸ§ª å¼€å§‹ ContextPruner æµ‹è¯•...")

    # æ£€æŸ¥ Redis
    try:
        client = redis.from_url("redis://localhost:6379/15")
        await client.ping()
        print("âœ… Redis è¿æ¥æ­£å¸¸")
    except:
        print("âŒ Redis è¿æ¥å¤±è´¥ï¼Œè·³è¿‡æµ‹è¯•")
        return

    # è¿è¡Œæµ‹è¯•
    test_pruner = TestContextPruner()
    test_worker = TestSummarizationWorker()
    test_integration = TestOrchestratorIntegration()

    # æ³¨å…¥ Redis å®¢æˆ·ç«¯
    redis_fixture = client

    try:
        # æµ‹è¯• 1: å°å†å²
        pruner = ContextPruner(redis_fixture, max_history_messages=5, summary_threshold=10)
        await test_pruner.test_small_history(pruner, redis_fixture)
        print("âœ… æµ‹è¯• 1: å°å†å² - é€šè¿‡")

        # æµ‹è¯• 2: æ»‘åŠ¨çª—å£
        await test_pruner.test_sliding_window(pruner, redis_fixture)
        print("âœ… æµ‹è¯• 2: æ»‘åŠ¨çª—å£ - é€šè¿‡")

        # æµ‹è¯• 3: æ€»ç»“è§¦å‘
        await test_pruner.test_summary_trigger(pruner, redis_fixture)
        print("âœ… æµ‹è¯• 3: æ€»ç»“è§¦å‘ - é€šè¿‡")

        # æµ‹è¯• 4: æ€»ç»“ç¼“å­˜
        await test_pruner.test_summary_cache(pruner, redis_fixture)
        print("âœ… æµ‹è¯• 4: æ€»ç»“ç¼“å­˜ - é€šè¿‡")

        # æµ‹è¯• 5: ç©ºå†å²
        await test_pruner.test_empty_history(pruner, redis_fixture)
        print("âœ… æµ‹è¯• 5: ç©ºå†å² - é€šè¿‡")

        # æµ‹è¯• 6: Worker å¤„ç†
        worker = SummarizationWorker(redis_fixture, batch_size=1)
        await test_worker.test_worker_processes_task(redis_fixture)
        print("âœ… æµ‹è¯• 6: Worker å¤„ç† - é€šè¿‡")

        # æµ‹è¯• 7: Orchestrator é›†æˆ
        await test_integration.test_build_conversation_context(redis_fixture)
        print("âœ… æµ‹è¯• 7: Orchestrator é›†æˆ - é€šè¿‡")

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await redis_fixture.flushdb()
        await redis_fixture.close()


if __name__ == "__main__":
    asyncio.run(run_all_tests())
