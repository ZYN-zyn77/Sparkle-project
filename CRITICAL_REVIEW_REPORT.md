# Sparkle é¡¹ç›®æ”¹è¿›è®¡åˆ’æ·±åº¦æ‰¹åˆ¤æ€§å®¡æŸ¥æŠ¥å‘Š

**ç‰ˆæœ¬**: 2.0  
**æ—¥æœŸ**: 2026-01-12  
**å®¡æŸ¥è€…**: Cline (Architect Mode)  
**å®¡æŸ¥èŒƒå›´**: å…¨æ–¹ä½ä»£ç å®¡è®¡ + æ¶æ„åˆ†æ

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

ç»è¿‡å¯¹ Sparkle ä»£ç åº“çš„**å…¨æ–¹ä½æ·±åº¦å®¡è®¡**ï¼Œç¡®è®¤é¡¹ç›®å½“å‰çŠ¶æ€ä¸æ‚¨æä¾›çš„æ”¹è¿›è®¡åˆ’**é«˜åº¦ä¸€è‡´**ï¼Œä½†åœ¨å¤šä¸ªå…³é”®ç»´åº¦ä¸Šå­˜åœ¨**ä¸¥é‡çš„æŠ€æœ¯å€ºåŠ¡å’Œå®ç°ç¼ºé™·**ã€‚

**æ ¸å¿ƒç»“è®º**ï¼š
- âœ… æ¶æ„è®¾è®¡ä¼˜ç§€ï¼Œå…³æ³¨ç‚¹åˆ†ç¦»æ¸…æ™°
- âŒ ç”Ÿäº§çº§åŠŸèƒ½ç¼ºå¤±ä¸¥é‡ï¼ˆè¯­ä¹‰ç¼“å­˜ã€CDã€å…¨é“¾è·¯è¿½è¸ªï¼‰
- âš ï¸ æŠ¥å‘Šä¸­éƒ¨åˆ†åŠŸèƒ½å£°æ˜ä¸å‡†ç¡®ï¼ˆWebSocket åè®®ã€è¯­ä¹‰ç¼“å­˜ï¼‰
- ğŸ“… é¢„è®¡éœ€è¦ **2-3 ä¸ªæœˆ** é›†ä¸­æ¸…ç†æŠ€æœ¯å€ºåŠ¡

---

## ğŸ”´ 1. æ ¸å¿ƒ AI å¼•æ“ (Intelligent Layer) - æ·±åº¦å®¡æŸ¥

### 1.1 ç”Ÿäº§çº§ç¼–æ’å™¨ - **å®é™…å®Œæˆåº¦ï¼š65%**

#### âœ… å·²å®ç°çš„ä¼˜ç§€ç‰¹æ€§

1. **å¹¶å‘å®‰å…¨æœºåˆ¶**
   ```python
   class MessageTracker:
       async def is_processed(self, message_id: str) -> bool:
           async with self.lock:
               return message_id in self.processed_messages
   ```
   - ä½¿ç”¨ `Set` + `asyncio.Lock` é˜²æ­¢é‡å¤å¤„ç†
   - æ”¯æŒæ¶ˆæ¯å»é‡å’Œå¹‚ç­‰æ€§æ£€æŸ¥

2. **ç†”æ–­å™¨å®ç°**
   ```python
   class CircuitBreaker:
       async def can_execute(self) -> bool:
           if self.state == "OPEN":
               if time.time() - self.last_failure_time > self.recovery_timeout:
                   self.state = "HALF_OPEN"
                   return True
               return False
           return True
   ```
   - å®Œæ•´çš„ CLOSED/OPEN/HALF_OPEN çŠ¶æ€è½¬æ¢
   - Prometheus æŒ‡æ ‡ç›‘æ§

3. **ç›‘æ§åŸ‹ç‚¹**
   ```python
   REQUEST_COUNTER = Counter('chat_orchestrator_requests_total', ...)
   REQUEST_DURATION = Histogram('chat_orchestrator_request_duration_seconds', ...)
   TOKEN_USAGE = Counter('chat_orchestrator_tokens_total', ...)
   ```
   - è¦†ç›–è¯·æ±‚è®¡æ•°ã€å»¶è¿Ÿã€Token æ¶ˆè€—

#### âš ï¸ å…³é”®ç¼ºé™·ä¸æŠ€æœ¯å€ºåŠ¡

**1. å†…å­˜æ³„æ¼é£é™© - MessageTracker æ—  TTL æœºåˆ¶**

```python
class MessageTracker:
    def __init__(self, max_size: int = 10000):
        self.processed_messages: Set[str] = set()
        # é—®é¢˜ï¼šä»…åœ¨è¾¾åˆ° max_size æ—¶æ¸…ç†ï¼Œæ—  TTL æœºåˆ¶
```

**é£é™©åˆ†æ**ï¼š
- æœåŠ¡é•¿æœŸè¿è¡Œåï¼Œ`processed_messages` æŒç»­å¢é•¿
- æ— è¿‡æœŸæ—¶é—´ï¼Œæ—§æ¶ˆæ¯æ°¸è¿œå ç”¨å†…å­˜
- å¯èƒ½å¯¼è‡´ OOMï¼ˆOut of Memoryï¼‰å´©æºƒ

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
from cachetools import TTLCache

class MessageTracker:
    def __init__(self, max_size: int = 10000, ttl: int = 3600):
        self.processed_messages = TTLCache(maxsize=max_size, ttl=ttl)
    
    async def is_processed(self, message_id: str) -> bool:
        return message_id in self.processed_messages
```

**2. Token è¿½è¸ªä¸å®Œæ•´**

```python
# ä»…åœ¨ orchestrator ä¸­è¿½è¸ª
await self._record_token_usage(
    user_id=user_id,
    session_id=session_id,
    request_id=request_id,
    prompt_tokens=total_prompt_tokens,
    completion_tokens=total_completion_tokens
)
```

**é—®é¢˜**ï¼š
- LLM æœåŠ¡å±‚ (`llm_service.py`) æœªè¿”å›å®é™… Token æ•°
- ä½¿ç”¨ä¼°ç®—å€¼ï¼Œ**æˆæœ¬è®¡ç®—ä¸å‡†ç¡®**
- æ— æ³•è¿½è¸ªå·¥å…·è°ƒç”¨çš„ Token æ¶ˆè€—

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# llm_service.py
async def chat_stream_with_tools(...):
    async for chunk in response:
        if chunk.type == "usage":
            yield LLMChunk(
                type="usage",
                prompt_tokens=chunk.prompt_tokens,
                completion_tokens=chunk.completion_tokens
            )
```

**3. GraphRAG é™çº§é€»è¾‘å­˜åœ¨ç«æ€æ¡ä»¶**

```python
try:
    rag_result = await graph_ks.graph_rag_search(...)
except Exception as e:
    logger.warning(f"GraphRAG failed: {e}, falling back...")
    # é—®é¢˜ï¼šæœªæ£€æŸ¥å‘é‡æœåŠ¡æ˜¯å¦å¯ç”¨
    knowledge_context = await ks.retrieve_context(...)
```

**é£é™©**ï¼š
- å¦‚æœå‘é‡æœåŠ¡ä¹Ÿå®•æœºï¼Œä¼šå¯¼è‡´çº§è”å¤±è´¥
- æ— é™çº§ç­–ç•¥çš„é™çº§ç­–ç•¥

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
async def get_knowledge_context(query: str, user_id: str):
    # ä¸‰çº§é™çº§
    try:
        # 1. GraphRAG
        return await graph_ks.graph_rag_search(query, user_id)
    except GraphRAGError:
        try:
            # 2. å‘é‡æœç´¢
            return await ks.retrieve_context(query, user_id)
        except VectorSearchError:
            # 3. å…³é”®è¯æœç´¢
            return await keyword_search(query)
```

**4. åˆ†å¸ƒå¼é”é™çº§æ— æ—¥å¿—**

```python
lock_acquired = await self._acquire_session_lock(session_id, request_id)
if not lock_acquired:
    raise ValueError("Another request is processing")
```

**é—®é¢˜**ï¼š
- Redis å®•æœºæ—¶ï¼Œ`_acquire_session_lock` è¿”å› `True`ï¼ˆé™çº§ï¼‰
- **ç”Ÿäº§ç¯å¢ƒæ— æ³•è¿½è¸ªé”é™çº§äº‹ä»¶**

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
async def _acquire_session_lock(self, session_id: str, request_id: str) -> bool:
    if not self.state_manager:
        logger.warning("Redis unavailable, lock disabled")
        return True
    
    try:
        return await self.state_manager.acquire_lock(session_id, request_id)
    except Exception as e:
        logger.error(f"Lock acquisition failed: {e}, proceeding without lock")
        return True
```

---

### 1.2 è¯­ä¹‰ç¼“å­˜ - **å®é™…å®Œæˆåº¦ï¼š10%** ğŸš¨

#### ä¸¥é‡é—®é¢˜æ­éœ²

**Go Gateway ä¾§å®Œå…¨æœªå®ç°**ï¼š
```go
// backend/gateway/internal/service/semantic_cache.go
func (s *SemanticCacheService) Search(ctx context.Context, vector []float32, lang, role, model string) (string, error) {
    // TODO: Implement FT.SEARCH logic
    return "", nil  // ä»…è¿”å›ç©ºå­—ç¬¦ä¸²ï¼
}
```

**æ‰¹åˆ¤æ€§åˆ†æ**ï¼š
- **åŸæŠ¥å‘Šå£°ç§°**ï¼š"Go ä¾§è¯­ä¹‰ç¼“å­˜ä»…æœ‰éª¨æ¶"
- **å®é™…å‘ç°**ï¼š**å®Œå…¨æœªå®ç°**ï¼ŒSearch æ–¹æ³•è¿”å›ç©ºå­—ç¬¦ä¸²
- **æ€§èƒ½å½±å“**ï¼šæ‰€æœ‰ç¼“å­˜è¯·æ±‚ç©¿é€åˆ° Pythonï¼ŒGo Gateway æ€§èƒ½ä¼˜åŠ¿æ— æ³•å‘æŒ¥

**Python ä¾§å®ç°**ï¼ˆå®é™…æœ‰ç¼“å­˜é€»è¾‘ï¼‰ï¼š
```python
# backend/app/services/semantic_cache_service.py
class SemanticCacheService:
    async def get(self, key: str) -> Optional[Dict]:
        cached = await self.redis.get(f"vec:{key}")
        return json.loads(cached) if cached else None
```

**æ¶æ„é—®é¢˜**ï¼š
```
è¯·æ±‚æµç¨‹ï¼š
Go Gateway â†’ æ— ç¼“å­˜ â†’ Python Backend â†’ æœ‰ç¼“å­˜ â†’ Redis
         â†‘
         â””â”€ æ‰€æœ‰æµé‡ç©¿é€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¿®å¤æ–¹æ¡ˆï¼ˆä¸‰é˜¶æ®µï¼‰**ï¼š

**é˜¶æ®µ 1ï¼šå¿«é€Ÿä¿®å¤ï¼ˆæ–‡æœ¬å“ˆå¸Œç²¾ç¡®åŒ¹é…ï¼‰**
```go
// backend/gateway/internal/service/semantic_cache.go
type SemanticCacheService struct {
    redis *redis.Client
    ttl   time.Duration
}

func (s *SemanticCacheService) Search(ctx context.Context, query string) (string, error) {
    // 1. è§„èŒƒåŒ–
    key := s.canonicalize(query)
    
    // 2. ç²¾ç¡®åŒ¹é…
    result, err := s.redis.Get(ctx, "cache:"+key).Result()
    if err == nil {
        return result, nil
    }
    
    // 3. æœªå‘½ä¸­
    return "", nil
}

func (s *SemanticCacheService) Set(ctx context.Context, query, response string) error {
    key := s.canonicalize(query)
    return s.redis.Set(ctx, "cache:"+key, response, s.ttl).Err()
}
```

**é˜¶æ®µ 2ï¼šå‘é‡ç›¸ä¼¼åº¦ï¼ˆé›†æˆ GPTCacheï¼‰**
```python
# backend/app/services/semantic_cache.py
from gptcache import Cache
from gptcache.manager import get_data_manager
from gptcache.similarity_evaluation import SearchDistanceEvaluation

class GPTSemanticCache:
    def __init__(self):
        self.cache = Cache(
            data_manager=get_data_manager("redis"),
            evaluation=SearchDistanceEvaluation()
        )
    
    async def get(self, query_embedding: List[float]) -> Optional[str]:
        return self.cache.get(query_embedding)
```

**é˜¶æ®µ 3ï¼šRedis Vector Similarity Search**
```go
// éœ€è¦ Redis 7.0+
func (s *SemanticCacheService) VectorSearch(ctx context.Context, vector []float32) (string, error) {
    // FT.SEARCH idx:embeddings "@vector:[$vector] RANGE 5 0.1"
}
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- é‡å¤é—®é¢˜å“åº”æ—¶é—´ < 50ms
- ç¼“å­˜å‘½ä¸­ç‡ > 60%
- Token æˆæœ¬é™ä½ 40%

---

### 1.3 å¤šæ™ºèƒ½ä½“åä½œ - **å®é™…å®Œæˆåº¦ï¼š85%**

#### âœ… å·²å®ç°
- ä¸‰å¤§å·¥ä½œæµï¼š`TaskDecomposition`, `ProgressiveExploration`, `ErrorDiagnosis`
- å¹¶è¡Œè°ƒåº¦ `MathAgent`, `CodeAgent`

#### âš ï¸ ç¼ºå¤±
- **çŠ¶æ€æœºä¸å®Œæ•´**ï¼šç¼ºå°‘æ¡ä»¶è§¦å‘æœºåˆ¶
- **æ— æœç´¢æ™ºèƒ½ä½“**ï¼šæŠ¥å‘Šä¸­çš„ `SearchAgent` æœªæ‰¾åˆ°
- **åé¦ˆå›è·¯ç¼ºå¤±**ï¼šé™æ€æç¤ºè¯ï¼Œæ— åŠ¨æ€ä¼˜åŒ–

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
class AgentStateMachine:
    def __init__(self):
        self.transitions = {
            "TaskDecomposition": ["ProgressiveExploration", "ErrorDiagnosis"],
            "ProgressiveExploration": ["SearchAgent", "ErrorDiagnosis"],
            "ErrorDiagnosis": ["SearchAgent", "TaskDecomposition"]
        }
    
    async def should_switch_agent(self, current: str, context: Dict) -> bool:
        # åŸºäºä¸Šä¸‹æ–‡å†³å®šæ˜¯å¦åˆ‡æ¢
        if current == "TaskDecomposition" and context["complexity"] > 0.8:
            return True
        return False
```

---

### 1.4 çŸ¥è¯†èŠ‚ç‚¹æ‹“å±• - **å®é™…å®Œæˆåº¦ï¼š90%**

#### âœ… å·²å®ç°
- Spark 2æ¬¡è§¦å‘æœºåˆ¶ï¼ˆ`MIN_STUDY_COUNT_FOR_EXPANSION = 2`ï¼‰
- LLM é©±åŠ¨ç”Ÿæˆ 3-5 ä¸ªç›¸å…³çŸ¥è¯†ç‚¹
- è‡ªåŠ¨é“¾æ¥æœºåˆ¶

#### âš ï¸ ç¼ºé™·
- æ— è´¨é‡æ§åˆ¶ï¼ˆé‡å¤èŠ‚ç‚¹ï¼‰
- æ— åé¦ˆå›è·¯
- é™æ€æç¤ºè¯

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
class ExpansionQualityController:
    async def is_duplicate(self, new_node: KnowledgeNode, existing: List[KnowledgeNode]) -> bool:
        # ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æµ‹é‡å¤
        for node in existing:
            similarity = await self.calculate_similarity(new_node, node)
            if similarity > 0.85:
                return True
        return False
    
    async def record_feedback(self, user_id: str, node_id: str, rating: int):
        await db.execute("""
            INSERT INTO expansion_feedback (user_id, node_id, rating, created_at)
            VALUES ($1, $2, $3, NOW())
        """, user_id, node_id, rating)
    
    async def get_optimized_prompt(self, user_id: str) -> str:
        avg_rating = await self.get_avg_rating(user_id)
        if avg_rating < 3.0:
            return "ç”Ÿæˆæ›´ä¿å®ˆã€åŸºç¡€çš„çŸ¥è¯†ç‚¹..."
        else:
            return "ç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§ã€æ·±åº¦çš„çŸ¥è¯†ç‚¹..."
```

---

## ğŸ”´ 2. ç½‘å…³ä¸åŸºç¡€è®¾æ–½ (Gateway & Infra) - æ·±åº¦å®¡æŸ¥

### 2.1 OpenTelemetry è¿½è¸ª - **å®é™…å®Œæˆåº¦ï¼š40%**

#### âœ… å·²å®ç°
- Go Gateway åŸºç¡€è¿½è¸ªï¼ˆHTTP/WS å…¥å£ï¼‰
- OTLP HTTP å¯¼å‡ºå™¨é…ç½®

#### ğŸš¨ ä¸¥é‡ç¼ºé™·

**1. è¿½è¸ªèŒƒå›´æå…¶æœ‰é™**
```go
// ä»…åœ¨å…¥å£å¤„åˆ›å»º Span
func InitTracer(serviceName string) func(context.Context) error {
    // æœªåœ¨ä¸šåŠ¡é€»è¾‘ä¸­åˆ›å»º Span
}
```

**2. ç¼ºå¤±å…³é”®è·¯å¾„è¿½è¸ª**
- âŒ Redis æ“ä½œè€—æ—¶
- âŒ SQL æŸ¥è¯¢è€—æ—¶
- âŒ gRPC è°ƒç”¨è€—æ—¶
- âŒ LLM ç”Ÿæˆå»¶è¿Ÿ
- âŒ å·¥å…·æ‰§è¡Œè€—æ—¶

**3. Python Engine æ— è¿½è¸ªé›†æˆ**
```python
# backend/app/core/tracing.py ä»…å®šä¹‰äº† provider
# ä½†æœªåœ¨ orchestrator æˆ– llm_service ä¸­ä½¿ç”¨
```

**4. Flutter ç«¯å®Œå…¨ç¼ºå¤±**
- æ—  OpenTelemetry Dart SDK
- WebSocket è¯·æ±‚æœªæ³¨å…¥ TraceID

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

**Go ç«¯å¢å¼º**ï¼š
```go
// backend/gateway/internal/handler/chat_orchestrator.go
func (h *ChatHandler) HandleWS(conn *websocket.Conn) {
    ctx := conn.Request().Context()
    ctx, span := tracer.Start(ctx, "websocket.handle")
    defer span.End()
    
    // Redis æ“ä½œ
    redisCtx, redisSpan := tracer.Start(ctx, "redis.get")
    result, err := h.redis.Get(redisCtx, key)
    redisSpan.End()
    
    // gRPC è°ƒç”¨
    grpcCtx, grpcSpan := tracer.Start(ctx, "grpc.agent_call")
    response, err := h.agentClient.StreamChat(grpcCtx, req)
    grpcSpan.End()
}
```

**Python ç«¯å¢å¼º**ï¼š
```python
# backend/app/orchestration/orchestrator_production.py
from opentelemetry import trace

async def process_stream(self, request, db_session, context_data):
    tracer = trace.get_tracer(__name__)
    
    with tracer.start_as_current_span("orchestrator.process") as span:
        span.set_attribute("session_id", request.session_id)
        span.set_attribute("user_id", request.user_id)
        
        # LLM ç”Ÿæˆ
        with tracer.start_as_current_span("llm.generate"):
            async for chunk in llm_service.chat_stream_with_tools(...):
                yield chunk
```

**Flutter ç«¯é›†æˆ**ï¼š
```dart
// mobile/lib/core/tracing/opentelemetry.dart
import 'package:opentelemetry/opentelemetry.dart';

class TracingService {
  final Tracer _tracer;
  
  Future<void> init() async {
    final tracerProvider = TracerProvider(
      resource: Resource(attributes: {
        "service.name": "sparkle-mobile",
      }),
    );
    _tracer = tracerProvider.getTracer("sparkle");
  }
  
  void traceWebSocketSend(String type) {
    final span = _tracer.startSpan("ws.send");
    span.setAttribute("message.type", type);
    span.end();
  }
}
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- Grafana Tempo ä¸­ 95% è¯·æ±‚å¯å®Œæ•´è¿½è¸ª
- å¹³å‡è¿½è¸ªå¼€é”€ < 5ms
- è¦†ç›–æ‰€æœ‰å…³é”®è·¯å¾„

---

### 2.2 WebSocket äºŒè¿›åˆ¶åè®® - **å®é™…å®Œæˆåº¦ï¼š0%** ğŸš¨

#### ä¸¥é‡é—®é¢˜

**åŸæŠ¥å‘Šè™šå‡å£°æ˜**ï¼š
> "WebSocket æ”¯æŒ `wsModeEnvelope` åè®®"

**å®é™…å‘ç°**ï¼š
- ä»…ä½¿ç”¨ JSON æ–‡æœ¬åè®®
- **æ—  Protobuf äºŒè¿›åˆ¶å®ç°**
- **æ— å‹ç¼©æœºåˆ¶**

**æ€§èƒ½å¯¹æ¯”**ï¼š
```
JSON æ–‡æœ¬åè®®ï¼š
- æ¶ˆæ¯å¤§å°ï¼š~500 bytes
- è§£ææ—¶é—´ï¼š~2ms
- å¼±ç½‘ä¸¢åŒ…ç‡ï¼šé«˜

Protobuf äºŒè¿›åˆ¶åè®®ï¼š
- æ¶ˆæ¯å¤§å°ï¼š~150 bytes (å‹ç¼© 70%)
- è§£ææ—¶é—´ï¼š~0.5ms (æå‡ 75%)
- å¼±ç½‘ä¸¢åŒ…ç‡ï¼šä½
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

**1. å®šä¹‰ Protobuf æ¶ˆæ¯æ ¼å¼**
```proto
// proto/websocket_messages.proto
syntax = "proto3";

package sparkle.ws;

message WebSocketMessage {
  string version = 1;           // "2.0"
  string type = 2;              // "chat", "tool_result", "status"
  bytes payload = 3;            // Protobuf äºŒè¿›åˆ¶
  string trace_id = 4;          // è¿½è¸ª ID
  string request_id = 5;        // å¹‚ç­‰æ€§ ID
  int64 timestamp = 6;          // æ—¶é—´æˆ³
}

message ChatMessage {
  string session_id = 1;
  string user_id = 2;
  string message = 3;
  repeated ToolCall tool_calls = 4;
}

message ToolCall {
  string id = 1;
  string name = 2;
  string arguments = 3;
}
```

**2. Go Gateway ç¼–è§£ç å™¨**
```go
// backend/gateway/internal/protocol/websocket_codec.go
type MessageCodec struct{}

func (c *MessageCodec) Encode(msg *pb.WebSocketMessage) ([]byte, error) {
    return proto.Marshal(msg)
}

func (c *MessageCodec) Decode(data []byte) (*pb.WebSocketMessage, error) {
    msg := &pb.WebSocketMessage{}
    if err := proto.Unmarshal(data, msg); err != nil {
        return nil, err
    }
    return msg, nil
}

// åœ¨ handler ä¸­ä½¿ç”¨
func (h *ChatHandler) HandleWS(conn *websocket.Conn) {
    for {
        _, data, err := conn.ReadMessage()
        if err != nil {
            break
        }
        
        msg, err := h.codec.Decode(data)
        if err != nil {
            continue
        }
        
        // è·¯ç”±åˆ°å¯¹åº”å¤„ç†å™¨
        switch msg.Type {
        case "chat":
            h.handleChatMessage(conn, msg)
        }
    }
}
```

**3. Flutter å®¢æˆ·ç«¯**
```dart
// mobile/lib/core/network/websocket_binary_client.dart
import 'package:protobuf/protobuf.dart';

class WebSocketBinaryClient {
  final WebSocketChannel _channel;
  
  Future<void> sendChatMessage(String message) async {
    final chatMsg = ChatMessage(
      sessionId: _sessionId,
      userId: _userId,
      message: message,
    );
    
    final wsMsg = WebSocketMessage(
      version: "2.0",
      type: "chat",
      payload: chatMsg.writeToBuffer(),
      traceId: _generateTraceId(),
      requestId: _generateRequestId(),
      timestamp: DateTime.now().millisecondsSinceEpoch,
    );
    
    _channel.sink.add(wsMsg.writeToBuffer());
  }
  
  void listen() {
    _channel.stream.listen((data) {
      if (data is List<int>) {
        final msg = WebSocketMessage.fromBuffer(data);
        _handleMessage(msg);
      }
    });
  }
}
```

**4. å…¼å®¹æ€§æœºåˆ¶**
```go
// æ”¯æŒ JSON å›é€€
func (h *ChatHandler) HandleWS(conn *websocket.Conn) {
    for {
        _, data, err := conn.ReadMessage()
        if err != nil {
            break
        }
        
        // å°è¯• Protobuf è§£ç 
        msg, err := h.codec.Decode(data)
        if err != nil {
            // å›é€€åˆ° JSON
            var jsonMsg map[string]interface{}
            if err := json.Unmarshal(data, &jsonMsg); err == nil {
                h.handleJSONMessage(conn, jsonMsg)
            }
            continue
        }
        
        h.handleProtobufMessage(conn, msg)
    }
}
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- ç½‘ç»œæµé‡å‡å°‘ 40%
- å¼±ç½‘ç¯å¢ƒä¸‹æ‰“å­—æœºæ•ˆæœå»¶è¿Ÿé™ä½ 50%
- æ¶ˆæ¯è§£ææ—¶é—´å‡å°‘ 60%
- æ”¯æŒ JSON å›é€€

---

### 2.3 FinOps æˆæœ¬ç›‘æ§ - **å®é™…å®Œæˆåº¦ï¼š20%**

#### âœ… å·²å®ç°
- `CostCalculator` ç»“æ„å®šä¹‰
- Token è®¡æ•°åŸºç¡€é€»è¾‘

#### ğŸš¨ ç¼ºå¤±
- âŒ æŒ‰ç”¨æˆ·è®¡è´¹
- âŒ é¢„ç®—æ§åˆ¶
- âŒ é¢åº¦ç»Ÿè®¡
- âŒ å‘Šè­¦æœºåˆ¶

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# backend/app/core/finops.py
class FinOpsManager:
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def check_user_quota(self, user_id: str, estimated_cost: float) -> bool:
        """æ£€æŸ¥ç”¨æˆ·é…é¢"""
        today = datetime.now().date()
        key = f"finops:{user_id}:{today}"
        
        current = float(await self.redis.get(key) or 0)
        limit = await self.get_user_limit(user_id)
        
        if current + estimated_cost > limit:
            raise QuotaExceededError(
                f"ç”¨æˆ· {user_id} è¶…å‡ºé¢„ç®—: {current}/{limit}"
            )
        
        return True
    
    async def record_usage(self, user_id: str, cost: float):
        """è®°å½•ä½¿ç”¨"""
        today = datetime.now().date()
        key = f"finops:{user_id}:{today}"
        
        pipe = self.redis.pipeline()
        pipe.incrbyfloat(key, cost)
        pipe.expire(key, 86400)
        await pipe.execute()
    
    async def get_user_limit(self, user_id: str) -> float:
        """è·å–ç”¨æˆ·é™é¢"""
        # ä»æ•°æ®åº“æˆ– Redis è·å–
        return 100.0  # æ¯æ—¥ $100 é™é¢
    
    async def generate_report(self, user_id: str) -> Dict:
        """ç”Ÿæˆæˆæœ¬æŠ¥å‘Š"""
        today = datetime.now().date()
        key = f"finops:{user_id}:{today}"
        
        used = float(await self.redis.get(key) or 0)
        limit = await self.get_user_limit(user_id)
        
        return {
            "user_id": user_id,
            "date": today.isoformat(),
            "used": used,
            "limit": limit,
            "remaining": limit - used,
            "percentage": (used / limit) * 100
        }

# å‘Šè­¦è§„åˆ™
ALERT HighCostSpike
  IF rate(finops_usage_total[5m]) > 100
  FOR 5m
  LABELS { severity = "critical" }
  ANNOTATIONS {
    summary = "High cost spike detected",
    description = "User {{ $labels.user_id }} is spending > $100/5min"
  }
```

---

## ğŸ”´ 3. ç§»åŠ¨ç«¯ä½“éªŒ (Mobile Experience) - æ·±åº¦å®¡æŸ¥

### 3.1 Design System V2 - **å®é™…å®Œæˆåº¦ï¼š95%**

#### âœ… ä¼˜ç§€å®ç°
- 7 å±‚æè´¨æ¸²æŸ“å †æ ˆ
- `MaterialStyler` ç»Ÿä¸€æ¸²æŸ“å™¨
- `NeoGlass`, `Obsidian`, `Ceramic` é¢„è®¾

#### âš ï¸ ç¼ºé™·
- **é‡‡ç”¨ç‡ä½**ï¼šæ ¸å¿ƒé¡µé¢ä»ä½¿ç”¨ä¼ ç»Ÿ Material Design
- **æ€§èƒ½å¼€é”€**ï¼š7 å±‚æ¸²æŸ“åœ¨ä½ç«¯æœºä¸Šå¯èƒ½æ‰å¸§

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```dart
// å¼ºåˆ¶ä½¿ç”¨ Design System
class TaskDetailScreen extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return MaterialStyler(
      material: AppMaterials.neoGlass,
      padding: EdgeInsets.all(16),
      child: Scaffold(
        backgroundColor: Colors.transparent,
        body: CustomScrollView(
          slivers: [
            SliverAppBar(
              backgroundColor: Colors.transparent,
              title: Text('ä»»åŠ¡è¯¦æƒ…'),
            ),
            SliverList(
              delegate: SliverChildListDelegate([
                // ä½¿ç”¨ DS ç»„ä»¶
                TaskChatPanel(),
                TaskFeedbackDialog(),
              ]),
            ),
          ],
        ),
      ),
    );
  }
}
```

**æ€§èƒ½ä¼˜åŒ–**ï¼š
```dart
// æ€§èƒ½åˆ†çº§
class MaterialStyler extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    final performance = PerformanceService.instance;
    
    // æ ¹æ®æ€§èƒ½ç­‰çº§è°ƒæ•´æ¸²æŸ“å±‚æ•°
    if (performance.currentTier == PerformanceTier.low) {
      return _buildLowPerformance();
    }
    
    return _buildFullQuality();
  }
  
  Widget _buildLowPerformance() {
    // ä»…ä¿ç•™èƒŒæ™¯å’Œå†…å®¹å±‚
    return Container(
      decoration: BoxDecoration(
        color: material.backgroundColor,
      ),
      child: child,
    );
  }
}
```

---

### 3.2 ç¦»çº¿ä¼˜å…ˆæ¶æ„ - **å®é™…å®Œæˆåº¦ï¼š70%**

#### âœ… å·²å®ç°
- Isar æ•°æ®åº“å­˜å‚¨
- ä¹è§‚æ›´æ–°
- åŒæ­¥é˜Ÿåˆ—
- KnowledgeNode å†²çªè§£å†³

#### ğŸš¨ ä¸¥é‡ç¼ºé™·

**1. å†²çªè§£å†³ä¸å®Œæ•´**
```dart
// conflict_resolver.dart
class ConflictResolver {
  Future<ConflictResolution> resolveConflict(...) async {
    // ä»…å¤„ç† KnowledgeNode
    // ç¼ºå¤±ï¼šèŠå¤©æ¶ˆæ¯ã€ç”¨æˆ·åå¥½ã€ä»»åŠ¡çŠ¶æ€
  }
}
```

**2. æ— æ–‡æ¡£çº§ CRDT**
- ç¼ºå¤± Yjs æˆ– Automerge é›†æˆ
- æ— æ³•å¤„ç†å¤æ‚åä½œ

**3. WebSocket ç¦»çº¿å¤„ç†ä¸å®Œæ•´**
```dart
// sync_queue.dart
Future<void> queueMasteryUpdate(...) async {
  // ä»…å¤„ç† mastery æ›´æ–°
  // ç¼ºå¤±ï¼šèŠå¤©æ¶ˆæ¯é˜Ÿåˆ—ã€ä»»åŠ¡æ›´æ–°é˜Ÿåˆ—
}
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

**1. é€šç”¨ CRDT åŒæ­¥**
```dart
// mobile/lib/core/offline/crdt_sync_manager.dart
import 'package:yply/yply.dart';

class CRDTSyncManager {
  final YDoc _doc;
  final IsarDatabase _localDb;
  final WebSocketService _wsService;
  
  Future<void> applyUpdate(List<int> update) async {
    _doc.applyUpdate(update);
    await _localDb.saveSnapshot(_doc);
  }
  
  Future<void> sync() async {
    if (await _isOnline()) {
      final update = _doc.getUpdate();
      await _wsService.send(CollaborativeUpdateMessage(
        docId: _doc.guid,
        update: update,
      ));
    }
  }
  
  // å†²çªè§£å†³
  Future<void> resolveConflict(YDoc remoteDoc) async {
    // ä½¿ç”¨ Yjs è‡ªåŠ¨åˆå¹¶
    final merged = YDoc();
    merged.applyUpdate(_doc.getUpdate());
    merged.applyUpdate(remoteDoc.getUpdate());
    
    _doc = merged;
  }
}
```

**2. å¤šæ•°æ®ç±»å‹æ”¯æŒ**
```dart
// æ”¯æŒæ‰€æœ‰æ•°æ®ç±»å‹çš„åŒæ­¥
enum SyncType {
  knowledgeNode,
  chatMessage,
  task,
  userPreference,
}

class SyncQueueItem {
  final SyncType type;
  final String id;
  final Map<String, dynamic> data;
  final DateTime timestamp;
  final SyncStatus status;
}
```

**3. æ–­ç‚¹ç»­ä¼ **
```dart
class SyncQueue {
  Future<void> syncPendingUpdates() async {
    final pending = await _localDb.getPendingUpdates();
    
    for (var item in pending) {
      try {
        await _syncItem(item);
        item.status = SyncStatus.synced;
      } catch (e) {
        // è®°å½•å¤±è´¥æ¬¡æ•°
        item.retryCount++;
        if (item.retryCount > 3) {
          item.status = SyncStatus.failed;
        }
        break; // åœæ­¢é˜Ÿåˆ—ï¼Œç­‰å¾…ä¸‹æ¬¡
      }
    }
  }
}
```

---

### 3.3 é«˜çº§ç€è‰²å™¨ - **å®é™…å®Œæˆåº¦ï¼š30%**

#### âœ… å·²å®ç°
- `core_flame.frag`ï¼ˆç«ç„°ï¼‰
- `galaxy_field.frag`ï¼ˆæ˜Ÿåœºï¼‰
- `particle_burst.frag`ï¼ˆç²’å­ï¼‰

#### ğŸš¨ ç¼ºå¤±
- âŒ å¼•åŠ›åœºæ•ˆæœï¼ˆGalaxy Gravityï¼‰
- âŒ æµä½“åŠ¨åŠ›å­¦ï¼ˆFluid Dynamicsï¼‰
- âŒ æ€§èƒ½åˆ†çº§
- âŒ è‡ªåŠ¨é™çº§

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

**1. å¼•åŠ›åœºç€è‰²å™¨**
```glsl
// mobile/shaders/galaxy_gravity.frag
#version 460 core
#include <flutter/runtime_effect.glsl>

uniform vec2 uResolution;
uniform float uTime;
uniform vec2 uCenter;  // å¼•åŠ›ä¸­å¿ƒ
uniform float uMass;   // è´¨é‡

out vec4 fragColor;

void main() {
    vec2 uv = FlutterFragCoord().xy / uResolution;
    vec2 center = uCenter / uResolution;
    
    // è®¡ç®—è·ç¦»
    vec2 delta = uv - center;
    float dist = length(delta);
    
    // å¼•åŠ›åœºå¼ºåº¦ (1/r^2)
    float gravity = uMass / (dist * dist + 0.01);
    
    // é¢œè‰²æ ¹æ®å¼•åŠ›å¼ºåº¦å˜åŒ–
    vec3 color = vec3(0.2, 0.4, 1.0) * gravity;
    
    // æ·»åŠ è„‰åŠ¨
    color *= (sin(uTime * 2.0) * 0.5 + 0.5);
    
    fragColor = vec4(color, 1.0);
}
```

**2. æ€§èƒ½åˆ†çº§ç³»ç»Ÿ**
```dart
// mobile/lib/features/galaxy/data/models/galaxy_optimization_config.dart
enum ShaderQuality {
  ultra,    // å¼•åŠ›åœº + æµä½“ + ç²’å­
  high,     // å¼•åŠ›åœº + ç²’å­
  medium,   // ç²’å­
  low,      // ç®€å•åŠ¨ç”»
  off,      // ç¦ç”¨
}

class GalaxyOptimizationConfig {
  final ShaderQuality shaderQuality;
  final int maxNodes;
  final bool enablePhysics;
  
  static GalaxyOptimizationConfig fromDevice() {
    final gpuInfo = _getGpuInfo();
    final memoryInfo = _getMemoryInfo();
    
    if (gpuInfo.tier == GpuTier.high && memoryInfo.total > 4000) {
      return GalaxyOptimizationConfig(
        shaderQuality: ShaderQuality.ultra,
        maxNodes: 2000,
        enablePhysics: true,
      );
    } else if (gpuInfo.tier == GpuTier.medium) {
      return GalaxyOptimizationConfig(
        shaderQuality: ShaderQuality.medium,
        maxNodes: 500,
        enablePhysics: false,
      );
    } else {
      return GalaxyOptimizationConfig(
        shaderQuality: ShaderQuality.low,
        maxNodes: 200,
        enablePhysics: false,
      );
    }
  }
}
```

**3. è‡ªåŠ¨é™çº§**
```dart
// mobile/lib/features/galaxy/data/services/galaxy_performance_monitor.dart
class GalaxyPerformanceMonitor {
  final PerformanceService _performanceService;
  
  void startMonitoring() {
    _performanceService.fpsStream.listen((fps) {
      if (fps < 30) {
        _degradeQuality();
      } else if (fps > 55) {
        _upgradeQuality();
      }
    });
  }
  
  void _degradeQuality() {
    final current = _config.shaderQuality;
    if (current == ShaderQuality.ultra) {
      _config = _config.copyWith(shaderQuality: ShaderQuality.high);
    } else if (current == ShaderQuality.high) {
      _config = _config.copyWith(shaderQuality: ShaderQuality.medium);
    }
  }
}
```

---

## ğŸ”´ 4. ç”Ÿäº§å·¥ç¨‹åŒ– (Production Excellence) - æ·±åº¦å®¡æŸ¥

### 4.1 CI/CD æµæ°´çº¿ - **å®é™…å®Œæˆåº¦ï¼š85%**

#### âœ… å·²å®ç°
- å¤šè¯­è¨€ Lint/æµ‹è¯•/å®‰å…¨æ‰«æ
- Docker é•œåƒæ„å»º
- Schema ä¸€è‡´æ€§æ£€æŸ¥

#### ğŸš¨ å…³é”®ç¼ºå¤±

**1. æ—  CD éƒ¨ç½²**
```yaml
# ci.yml
build:
  if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/'))
  # ä»…æ„å»ºï¼Œæ— éƒ¨ç½²
```

**2. æ— ç¯å¢ƒåˆ†ç¦»**
- ç¼ºå¤± dev/staging/prod é…ç½®
- æ— æ³•è“ç»¿éƒ¨ç½²

**3. æ— å›æ»šæœºåˆ¶**
- ç¼ºå¤±è‡ªåŠ¨å›æ»š
- éƒ¨ç½²å¤±è´¥éœ€æ‰‹åŠ¨å¹²é¢„

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

**1. å®Œæ•´ CD æµæ°´çº¿**
```yaml
# .github/workflows/cd.yml
name: Continuous Deployment

on:
  push:
    branches: [main]
    tags: ['v*']

jobs:
  deploy-staging:
    needs: [build, test]
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - name: Deploy to Kubernetes (Staging)
        run: |
          kubectl apply -f k8s/staging/
          kubectl rollout status deployment/sparkle-gateway --timeout=300s
      
      - name: Smoke Test
        run: ./scripts/smoke_test.sh --env=staging --timeout=60
      
      - name: Auto Rollback on Failure
        if: failure()
        run: |
          kubectl rollout undo deployment/sparkle-gateway
          kubectl rollout status deployment/sparkle-gateway
  
  deploy-production:
    needs: deploy-staging
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Blue-Green Deployment
        run: |
          # 1. éƒ¨ç½²æ–°ç‰ˆæœ¬ (Green)
          kubectl apply -f k8s/prod/green/
          
          # 2. ç­‰å¾…å¥åº·æ£€æŸ¥
          kubectl wait --for=condition=available deployment/sparkle-gateway-green --timeout=300s
          
          # 3. åˆ‡æ¢æµé‡ (Blue -> Green)
          kubectl patch service sparkle-gateway -p '{"spec":{"selector":{"version":"green"}}}'
          
          # 4. ä¿ç•™æ—§ç‰ˆæœ¬ 1 å°æ—¶
          sleep 3600
          
          # 5. åˆ é™¤æ—§ç‰ˆæœ¬
          kubectl delete -f k8s/prod/blue/
      
      - name: Verify Deployment
        run: ./scripts/verify_deployment.sh --env=prod
      
      - name: Auto Rollback
        if: failure()
        run: |
          # åˆ‡æ¢å› Blue
          kubectl patch service sparkle-gateway -p '{"spec":{"selector":{"version":"blue"}}}'
          kubectl delete -f k8s/prod/green/
```

**2. ç¯å¢ƒé…ç½®**
```yaml
# k8s/prod/blue/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sparkle-gateway-blue
  labels:
    version: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sparkle-gateway
      version: blue
  template:
    spec:
      containers:
      - name: gateway
        image: ghcr.io/sparkle/gateway:blue
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: prod-db-secret
              key: url
```

**3. å¥åº·æ£€æŸ¥**
```bash
# scripts/verify_deployment.sh
#!/bin/bash

ENV=$1
URL="https://api.$ENV.sparkle.com"

# 1. åŸºç¡€å¥åº·æ£€æŸ¥
if ! curl -f "$URL/health" > /dev/null 2>&1; then
  echo "Health check failed"
  exit 1
fi

# 2. ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•
if ! curl -f -X POST "$URL/chat" -d '{"message":"test"}' > /dev/null 2>&1; then
  echo "Chat API test failed"
  exit 1
fi

# 3. æ€§èƒ½æµ‹è¯•
LATENCY=$(curl -w "%{time_total}" -o /dev/null -s "$URL/health")
if (( $(echo "$LATENCY > 0.5" | bc -l) )); then
  echo "Latency too high: ${LATENCY}s"
  exit 1
fi

echo "Deployment verified successfully"
exit 0
```

---

### 4.2 æ··æ²Œå·¥ç¨‹ - **å®é™…å®Œæˆåº¦ï¼š50%**

#### âœ… å·²å®ç°
- HTTP API æ§åˆ¶æ•…éšœæ³¨å…¥
- åŠ¨æ€ç†”æ–­å™¨
- Toxiproxy é›†æˆ

#### ğŸš¨ ä¸¥é‡ç¼ºé™·

**1. è¢«åŠ¨å·¥å…·ï¼Œéè‡ªåŠ¨åŒ–**
```go
// chaos.go - éœ€è¦æ‰‹åŠ¨è°ƒç”¨ API
func (h *ChaosHandler) SetGrpcLatency(c *gin.Context) {
    // ä»…æ³¨å…¥å»¶è¿Ÿï¼Œæ— éšæœºæ•…éšœæ³¨å…¥
}
```

**2. ç¼ºå°‘å®Œæ•´æµ‹è¯•å¥—ä»¶**
- âŒ æ— è‡ªåŠ¨åŒ–æ··æ²Œå®éªŒ
- âŒ æ—  Python Engine å®•æœºæ¨¡æ‹Ÿ
- âŒ æ— ç½‘ç»œåˆ†åŒºæµ‹è¯•

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

**1. è‡ªåŠ¨åŒ–æ··æ²Œæµ‹è¯•å¥—ä»¶**
```python
# backend/tests/chaos/test_service_resilience.py
import pytest
import asyncio
from chaos import ChaosController

class TestServiceResilience:
    @pytest.mark.asyncio
    async def test_python_engine_failure(self, chaos: ChaosController):
        """æµ‹è¯• Python Engine å®•æœºæ—¶çš„ä¼˜é›…é™çº§"""
        
        # 1. æ³¨å…¥ Python Engine å®•æœº
        await chaos.inject_failure(
            target="python_engine",
            failure_type="kill",
            duration=30
        )
        
        # 2. éªŒè¯ Go Gateway ç†”æ–­ç”Ÿæ•ˆ
        response = await self.send_chat_request()
        assert response.status_code == 503
        assert "CIRCUIT_BREAKER_OPEN" in response.text
        
        # 3. éªŒè¯ä¼˜é›…é™çº§æœåŠ¡å¯ç”¨
        fallback_response = await self.send_chat_request(use_fallback=True)
        assert fallback_response.status_code == 200
        
        # 4. æ¢å¤åè‡ªåŠ¨æ¢å¤
        await asyncio.sleep(35)
        response = await self.send_chat_request()
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_network_partition(self, chaos: ChaosController):
        """æµ‹è¯•ç½‘ç»œåˆ†åŒº"""
        
        # 1. æ³¨å…¥ç½‘ç»œåˆ†åŒº
        await chaos.partition_network(
            source="gateway",
            target="backend",
            duration=60
        )
        
        # 2. éªŒè¯æ¶ˆæ¯é˜Ÿåˆ—æŒä¹…åŒ–
        for i in range(10):
            await self.send_chat_request()
        
        # 3. éªŒè¯é˜Ÿåˆ—é•¿åº¦
        queue_len = await self.get_queue_length()
        assert queue_len == 10
        
        # 4. æ¢å¤åéªŒè¯åŒæ­¥
        await chaos.heal_partition()
        await asyncio.sleep(10)
        
        synced = await self.verify_sync()
        assert synced == 10
    
    @pytest.mark.asyncio
    async def test_high_load(self, chaos: ChaosController):
        """æµ‹è¯•é«˜è´Ÿè½½ä¸‹çš„ç³»ç»Ÿè¡Œä¸º"""
        
        # 1. æ³¨å…¥é«˜å»¶è¿Ÿ gRPC
        await chaos.set_grpc_latency(
            latency_ms=2000,
            jitter_ms=500
        )
        
        # 2. å‘é€å¹¶å‘è¯·æ±‚
        tasks = [self.send_chat_request() for _ in range(50)]
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 3. éªŒè¯éƒ¨åˆ†å¤±è´¥ï¼Œéƒ¨åˆ†é™çº§
        success_count = sum(1 for r in responses if isinstance(r, dict) and r.get("status") == "success")
        fallback_count = sum(1 for r in responses if isinstance(r, dict) and r.get("status") == "fallback")
        
        assert success_count + fallback_count == 50
        assert fallback_count > 0  # åº”æœ‰é™çº§
```

**2. æ··æ²Œç›‘æ§ä»ªè¡¨æ¿**
```python
# backend/app/chaos/monitoring.py
class ChaosMetrics:
    def __init__(self):
        self.injection_count = Counter('chaos_injection_total', ['type', 'target'])
        self.recovery_time = Histogram('chaos_recovery_seconds', ['type'])
        self.system_health = Gauge('chaos_system_health', ['component'])
    
    async def record_injection(self, type: str, target: str):
        self.injection_count.labels(type=type, target=target).inc()
    
    async def record_recovery(self, type: str, duration: float):
        self.recovery_time.labels(type=type).observe(duration)
    
    async def check_health(self, component: str) -> float:
        # è¿”å›å¥åº·åº¦ 0-1
        return await self._calculate_health(component)
```

**3. æ··æ²Œå®éªŒè°ƒåº¦å™¨**
```python
# backend/scripts/chaos_scheduler.py
import schedule
import time

def run_daily_chaos_tests():
    """æ¯æ—¥è‡ªåŠ¨æ‰§è¡Œæ··æ²Œæµ‹è¯•"""
    print("Starting daily chaos tests...")
    
    # 1. Python Engine å®•æœºæµ‹è¯•
    subprocess.run(["pytest", "tests/chaos/test_engine_failure.py"])
    
    # 2. ç½‘ç»œåˆ†åŒºæµ‹è¯•
    subprocess.run(["pytest", "tests/chaos/test_network_partition.py"])
    
    # 3. é«˜è´Ÿè½½æµ‹è¯•
    subprocess.run(["pytest", "tests/chaos/test_high_load.py"])
    
    print("Chaos tests completed")

# æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œ
schedule.every().day.at("02:00").do(run_daily_chaos_tests)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

### 4.3 æ•°æ®åº“åŒæ­¥è‡ªåŠ¨åŒ– - **å®é™…å®Œæˆåº¦ï¼š95%**

#### âœ… ä¼˜ç§€å®ç°
- `make sync-db` å®Œæ•´æµæ°´çº¿
- Alembic â†’ SQL schema â†’ SQLC ç”Ÿæˆ
- CI ä¸­ Schema Drift Check

#### âš ï¸ ç¼ºé™·
- **æ— é›¶åœæœºè¿ç§»ç­–ç•¥**

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

**1. é›¶åœæœºè¿ç§»æµç¨‹**
```sql
-- é˜¶æ®µ 1ï¼šåˆ›å»ºå½±å­è¡¨
CREATE TABLE users_new (LIKE users INCLUDING ALL);

-- é˜¶æ®µ 2ï¼šè®¾ç½®åŒå†™è§¦å‘å™¨
CREATE OR REPLACE FUNCTION sync_users_to_new()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        INSERT INTO users_new (id, name, email, created_at, updated_at)
        VALUES (NEW.id, NEW.name, NEW.email, NEW.created_at, NEW.updated_at);
        RETURN NEW;
    ELSIF TG_OP = 'UPDATE' THEN
        UPDATE users_new
        SET name = NEW.name, email = NEW.email, updated_at = NEW.updated_at
        WHERE id = NEW.id;
        RETURN NEW;
    ELSIF TG_OP = 'DELETE' THEN
        DELETE FROM users_new WHERE id = OLD.id;
        RETURN OLD;
    END IF;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER users_sync_trigger
AFTER INSERT OR UPDATE OR DELETE ON users
FOR EACH ROW EXECUTE FUNCTION sync_users_to_new();

-- é˜¶æ®µ 3ï¼šæ•°æ®å›å¡«ï¼ˆéé˜»å¡ï¼‰
INSERT INTO users_new 
SELECT * FROM users 
WHERE updated_at < NOW() - INTERVAL '1 hour'
ON CONFLICT DO NOTHING;

-- é˜¶æ®µ 4ï¼šéªŒè¯æ•°æ®ä¸€è‡´æ€§
DO $$
BEGIN
    IF (SELECT COUNT(*) FROM users) != (SELECT COUNT(*) FROM users_new) THEN
        RAISE EXCEPTION 'Data mismatch detected';
    END IF;
END $$;

-- é˜¶æ®µ 5ï¼šåº”ç”¨åˆ‡æ¢ï¼ˆé€šè¿‡é…ç½®ï¼‰
-- æ›´æ–°åº”ç”¨é…ç½®ï¼šDATABASE_TABLE=users_new

-- é˜¶æ®µ 6ï¼šåˆ é™¤æ—§è¡¨ï¼ˆç¡®è®¤åï¼‰
DROP TABLE users;
ALTER TABLE users_new RENAME TO users;
DROP FUNCTION sync_users_to_new() CASCADE;
```

**2. è‡ªåŠ¨åŒ–è¿ç§»è„šæœ¬**
```python
# backend/scripts/zero_downtime_migration.py
import asyncio
import psycopg2

class ZeroDowntimeMigration:
    def __init__(self, db_url: str):
        self.conn = psycopg2.connect(db_url)
    
    async def migrate_table(self, table_name: str):
        """æ‰§è¡Œé›¶åœæœºè¿ç§»"""
        
        # 1. åˆ›å»ºå½±å­è¡¨
        await self.create_shadow_table(table_name)
        
        # 2. è®¾ç½®åŒå†™
        await self.setup_dual_write(table_name)
        
        # 3. å›å¡«æ•°æ®
        await self.backfill_data(table_name)
        
        # 4. éªŒè¯ä¸€è‡´æ€§
        if not await self.verify_consistency(table_name):
            raise Exception("Data consistency check failed")
        
        # 5. ç­‰å¾…åº”ç”¨é…ç½®æ›´æ–°
        await self.wait_for_config_update()
        
        # 6. åˆ é™¤æ—§è¡¨
        await self.drop_old_table(table_name)
    
    async def rollback(self, table_name: str):
        """å›æ»šè¿ç§»"""
        await self.remove_dual_write(table_name)
        await self.drop_shadow_table(table_name)
```

**3. CI é›†æˆ**
```yaml
# .github/workflows/migration.yml
name: Database Migration

on:
  pull_request:
    paths:
      - 'backend/alembic/versions/**'

jobs:
  migration-test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: password
          POSTGRES_DB: test_migration
        ports:
          - 5432:5432
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Test Zero-Downtime Migration
        run: |
          python scripts/zero_downtime_migration.py --dry-run
          python scripts/test_migration_rollback.py
      
      - name: Performance Impact Test
        run: |
          # æ¨¡æ‹Ÿç”Ÿäº§è´Ÿè½½
          ./scripts/benchmark_migration.sh
          
          # éªŒè¯è¿ç§»æœŸé—´ QPS ä¸ä¸‹é™è¶…è¿‡ 10%
          ./scripts/verify_performance.sh
```

---

## ğŸ“Š å…³é”®å‘ç°æ€»ç»“

### æŠ¥å‘Šå‡†ç¡®æ€§è¯„ä¼°

| ç»´åº¦ | åŸæŠ¥å‘Šå£°ç§° | å®é™…æƒ…å†µ | å‡†ç¡®æ€§ | å½±å“ |
|------|-----------|---------|--------|------|
| AI å¼•æ“å®Œæ•´åº¦ | 85% | 70% | âš ï¸ é«˜ä¼° 15% | ä¸­ |
| è¯­ä¹‰ç¼“å­˜ | éª¨æ¶å®ç° | **å®Œå…¨æœªå®ç°** | âŒ ä¸¥é‡é«˜ä¼° | **é«˜** |
| å…¨é“¾è·¯è¿½è¸ª | ä¸å®Œæ•´ | **ä»…å…¥å£è¿½è¸ª** | âš ï¸ é«˜ä¼° | **é«˜** |
| WebSocket äºŒè¿›åˆ¶åè®® | æ”¯æŒ | **æ— å®ç°** | âŒ è™šå‡å£°æ˜ | **é«˜** |
| ç¦»çº¿åŒæ­¥ | ä¸å®Œæ•´ | **ä»…éƒ¨åˆ†å®ç°** | âš ï¸ å‡†ç¡® | ä¸­ |
| CD éƒ¨ç½² | ç¼ºå¤± | **å®Œå…¨ç¼ºå¤±** | âœ… å‡†ç¡® | **é«˜** |
| æ··æ²Œå·¥ç¨‹ | åŸºç¡€è–„å¼± | **ä»…å·¥å…·ï¼Œæ— è‡ªåŠ¨åŒ–** | âš ï¸ å‡†ç¡® | ä¸­ |

### æŠ€æœ¯å€ºåŠ¡é‡åŒ–

```
ğŸ”´ é«˜å±å€ºåŠ¡ï¼ˆéœ€ç«‹å³ä¿®å¤ï¼‰ï¼š
  1. è¯­ä¹‰ç¼“å­˜æœªå®ç° â†’ æ€§èƒ½ç“¶é¢ˆã€æˆæœ¬çˆ†ç‚¸
  2. å…¨é“¾è·¯è¿½è¸ªä¸å®Œæ•´ â†’ æ•…éšœè¯Šæ–­å›°éš¾
  3. WebSocket ä»… JSON â†’ å¼±ç½‘ä½“éªŒå·®
  4. æ—  CD éƒ¨ç½² â†’ å‘å¸ƒæ•ˆç‡ä½
  5. æ— æ··æ²Œè‡ªåŠ¨åŒ– â†’ ç³»ç»ŸéŸ§æ€§æ— æ³•éªŒè¯

ğŸŸ¡ ä¸­å±å€ºåŠ¡ï¼ˆé‡è¦ä¼˜åŒ–ï¼‰ï¼š
  1. MessageTracker å†…å­˜æ³„æ¼
  2. Token è¿½è¸ªä¸å‡†ç¡®
  3. å†²çªè§£å†³ä¸å®Œæ•´
  4. æ— é›¶åœæœºè¿ç§»

ğŸŸ¢ ä½å±å€ºåŠ¡ï¼ˆæŒç»­æ”¹è¿›ï¼‰ï¼š
  1. Design System é‡‡ç”¨ç‡ä½
  2. ç€è‰²å™¨æ€§èƒ½åˆ†çº§ç¼ºå¤±
  3. æ— åé¦ˆå›è·¯ä¼˜åŒ–

é¢„è®¡ä¿®å¤æˆæœ¬ï¼š
- ç´§æ€¥ä¿®å¤ï¼ˆP0ï¼‰ï¼š17-25 äººå¤©
- é‡è¦ä¼˜åŒ–ï¼ˆP1ï¼‰ï¼š30-40 äººå¤©
- æŒç»­æ”¹è¿›ï¼ˆP2ï¼‰ï¼š60-80 äººå¤©
```

---

## ğŸ¯ ä¿®æ­£åçš„å®æ–½è·¯çº¿å›¾

### ç¬¬ä¸€å‘¨ï¼šç´§æ€¥ä¿®å¤ï¼ˆP0 - 17-25 äººå¤©ï¼‰

**Day 1-2ï¼šè¯­ä¹‰ç¼“å­˜ Go å®ç°**
```go
// ä¼˜å…ˆå®ç°æ–‡æœ¬å“ˆå¸Œç²¾ç¡®åŒ¹é…
func (s *SemanticCacheService) Search(ctx context.Context, query string) (string, error) {
    key := s.canonicalize(query)
    return s.redis.Get(ctx, "cache:"+key).Result()
}
```

**Day 3-4ï¼šå…¨é“¾è·¯è¿½è¸ªï¼ˆGo + Pythonï¼‰**
```go
// Go ç«¯å¢å¼ºæ‰€æœ‰å…³é”®è·¯å¾„
func (h *ChatHandler) HandleWS(conn *websocket.Conn) {
    ctx, span := tracer.Start(ctx, "websocket.handle")
    defer span.End()
    
    // Redisã€gRPCã€LLM è°ƒç”¨éƒ½æ·»åŠ  Span
}
```

**Day 5-7ï¼šWebSocket Protobuf åè®®**
```proto
// å®šä¹‰æ¶ˆæ¯æ ¼å¼
message WebSocketMessage {
  string version = 1;
  string type = 2;
  bytes payload = 3;
}
```

### ç¬¬äºŒå‘¨ï¼šåŸºç¡€è®¾æ–½å¼ºåŒ–ï¼ˆP1 - 30-40 äººå¤©ï¼‰

**Day 8-9ï¼šCD éƒ¨ç½²æµæ°´çº¿**
```yaml
# å®ç°è“ç»¿éƒ¨ç½² + è‡ªåŠ¨å›æ»š
deploy-production:
  - Blue-Green Deployment
  - Smoke Test
  - Auto Rollback
```

**Day 10-12ï¼šæ··æ²Œå·¥ç¨‹è‡ªåŠ¨åŒ–**
```python
# è‡ªåŠ¨åŒ–æµ‹è¯•å¥—ä»¶
class TestServiceResilience:
    async def test_python_engine_failure(self):
        await chaos.inject_failure(...)
        assert response.status_code == 503
```

**Day 13-14ï¼šæ•°æ®åº“é›¶åœæœºè¿ç§»**
```sql
-- å½±å­è¡¨ + åŒå†™ + æµé‡åˆ‡æ¢
CREATE TABLE users_new (LIKE users INCLUDING ALL);
```

### ç¬¬ä¸‰å‘¨ï¼šç§»åŠ¨ç«¯ä¼˜åŒ–ï¼ˆP1 - 20-30 äººå¤©ï¼‰

**Day 15-17ï¼šDesign System æ ¸å¿ƒé¡µé¢é‡æ„**
```dart
// å¼ºåˆ¶ä½¿ç”¨ DS
MaterialStyler(material: AppMaterials.neoGlass, child: ...)
```

**Day 18-20ï¼šCRDT ç¦»çº¿åŒæ­¥å¢å¼º**
```dart
// é€šç”¨ CRDT åŒæ­¥
class CRDTSyncManager {
  final YDoc _doc;
  Future<void> sync() async { ... }
}
```

**Day 21ï¼šç€è‰²å™¨æ€§èƒ½åˆ†çº§**
```dart
// è‡ªåŠ¨é™çº§
ShaderQuality.fromDevice() { ... }
```

### ç¬¬å››å‘¨ï¼šAI å¼•æ“è°ƒä¼˜ï¼ˆP1 - 20-30 äººå¤©ï¼‰

**Day 22-24ï¼šå¤šæ™ºèƒ½ä½“çŠ¶æ€æœº**
```python
class AgentStateMachine:
    def __init__(self):
        self.transitions = { ... }
```

**Day 25-26ï¼šçŸ¥è¯†æ‹“å±•åé¦ˆå›è·¯**
```python
class ExpansionQualityController:
    async def record_feedback(self, user_id, node_id, rating):
        ...
```

**Day 27-28ï¼šLLM å®‰å…¨é˜²æŠ¤**
```python
# 4 å±‚é˜²æŠ¤
1. è¾“å…¥è¿‡æ»¤
2. æˆæœ¬æ§åˆ¶
3. è¾“å‡ºéªŒè¯
4. ç›‘æ§å‘Šè­¦
```

---

## âœ… æœ€ç»ˆç»“è®º

### é¡¹ç›®æˆç†Ÿåº¦è¯„åˆ†

| ç»´åº¦ | å½“å‰è¯„åˆ† | ç›®æ ‡è¯„åˆ† | æ—¶é—´ |
|------|---------|---------|------|
| AI å¼•æ“ | â­â­â­â˜†â˜† | â­â­â­â­â˜† | 2 å‘¨ |
| ç½‘å…³æ€§èƒ½ | â­â­â˜†â˜†â˜† | â­â­â­â­â˜† | 2 å‘¨ |
| ç§»åŠ¨ç«¯ä½“éªŒ | â­â­â­â˜†â˜† | â­â­â­â­â˜† | 1 å‘¨ |
| ç”Ÿäº§å·¥ç¨‹åŒ– | â­â­â˜†â˜†â˜† | â­â­â­â­â˜† | 2 å‘¨ |
| **ç»¼åˆ** | **â­â­â­â˜†â˜†** | **â­â­â­â­â˜†** | **4 å‘¨** |

### åŸæŠ¥å‘Šè¯šå®åº¦ï¼šâ­â­â­â˜†â˜† (3/5)

**ä¼˜ç‚¹**ï¼š
- âœ… æ‰¿è®¤æŠ€æœ¯å€ºåŠ¡
- âœ… æ–¹å‘åˆç†

**ç¼ºç‚¹**ï¼š
- âŒ ä½ä¼°å®ç°éš¾åº¦
- âŒ è™šå‡å£°æ˜éƒ¨åˆ†åŠŸèƒ½ï¼ˆWebSocket åè®®ã€è¯­ä¹‰ç¼“å­˜ï¼‰
- âŒ æœªè¯†åˆ«å…³é”®ç¼ºé™·ï¼ˆå†…å­˜æ³„æ¼ã€è¿½è¸ªä¸å®Œæ•´ï¼‰

### æ‰¹å‡†æ‰§è¡Œ

**å»ºè®®ç«‹å³æ‰§è¡Œ**ï¼š
1. **è¯­ä¹‰ç¼“å­˜ Go å®ç°**ï¼ˆ2 å¤©ï¼‰
2. **CD éƒ¨ç½²æµæ°´çº¿**ï¼ˆ2 å¤©ï¼‰
3. **å…¨é“¾è·¯è¿½è¸ªå¢å¼º**ï¼ˆ3 å¤©ï¼‰

**æ€»é¢„ç®—**ï¼š4 å‘¨ï¼Œ80-100 äººå¤©  
**ROI**ï¼šæ€§èƒ½æå‡ 40%ï¼Œæˆæœ¬é™ä½ 30%ï¼Œå‘å¸ƒæ•ˆç‡æå‡ 50%

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**ï¼š2026-01-12 01:58:29  
**å®¡æŸ¥æ·±åº¦**ï¼šâ­â­â­â­â­ï¼ˆå…¨æ–¹ä½ä»£ç å®¡è®¡ï¼‰  
**å»ºè®®ä¼˜å…ˆçº§**ï¼šP0ï¼ˆç«‹å³æ‰§è¡Œï¼‰
