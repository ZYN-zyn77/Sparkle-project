# Sparkleå¤šAgentåä½œç³»ç»Ÿ - å…¨é¢æ”¹è¿›æ–¹æ¡ˆæŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

åŸºäºå¯¹å½“å‰Sparkleå¤šAgentåä½œç³»ç»Ÿv4.0çš„æ·±å…¥åˆ†æï¼Œæˆ‘è¯†åˆ«å‡ºäº†**12ä¸ªå…³é”®æ”¹è¿›é¢†åŸŸ**ï¼Œæ¶µç›–æ¶æ„ä¼˜åŒ–ã€æ€§èƒ½æå‡ã€å¯è§‚æµ‹æ€§å¢å¼ºå’Œç”Ÿäº§çº§ç‰¹æ€§ã€‚æœ¬æŠ¥å‘Šæä¾›åˆ†å±‚æ¬¡çš„æ”¹è¿›æ–¹æ¡ˆï¼Œä»P0ï¼ˆç«‹å³å®æ–½ï¼‰åˆ°P3ï¼ˆæœªæ¥æ‰©å±•ï¼‰ã€‚

**å½“å‰ç³»ç»ŸçŠ¶æ€**: âœ… 100%å®Œæˆv4.0æ¶æ„å‡çº§  
**æ”¹è¿›å‘¨æœŸ**: 8å‘¨  
**é¢„æœŸæ”¶ç›Š**: è·¯ç”±å‡†ç¡®ç‡85%+ï¼Œå»¶è¿Ÿé™ä½60%+ï¼Œè°ƒè¯•æ•ˆç‡æå‡70%

---

## ğŸ¯ å½“å‰ç³»ç»ŸçŠ¶æ€è¯„ä¼°

### âœ… å·²å®ç°çš„æ ¸å¿ƒä¼˜åŠ¿

1. **æ¶æ„æ­£ç¡®æ€§**: "å“‘ç½‘å…³+èƒ–æ ¸å¿ƒ"å®Œç¾è½åœ°
   - Goç½‘å…³ä»…åšåè®®è½¬æ¢å’Œäº‹ä»¶è½¬å‘
   - Pythonæ ¸å¿ƒæ‰¿æ‹…æ‰€æœ‰ä¸šåŠ¡é€»è¾‘å’ŒçŠ¶æ€ç®¡ç†
   - é¿å…äº†åŒçŠ¶æ€æœºè„‘è£‚é£é™©

2. **Statechartså¼•æ“**: æ”¯æŒå±‚æ¬¡åŒ–çŠ¶æ€ã€å¹¶è¡Œæ‰§è¡Œã€æ¡ä»¶è·¯ç”±
   - å‚è€ƒLangGraph Pregelæ¨¡å¼
   - å®Œæ•´çš„äº‹ä»¶é©±åŠ¨æ¶æ„
   - Redisæ£€æŸ¥ç‚¹æŒä¹…åŒ–

3. **æ™ºèƒ½è·¯ç”±**: NetworkXå›¾ç®—æ³• + è´å¶æ–¯å­¦ä¹ 
   - æœ€çŸ­è·¯å¾„è®¡ç®—
   - åŠ¨æ€æƒé‡æ›´æ–°
   - åŸºç¡€å­¦ä¹ èƒ½åŠ›

4. **å¯è§†åŒ–åŸºç¡€**: Mermaid.jsç”Ÿæˆå™¨
   - å®æ—¶çŠ¶æ€é«˜äº®
   - åŸºç¡€è°ƒè¯•æ”¯æŒ

5. **ç”Ÿäº§ç‰¹æ€§**: 
   - åˆ†å¸ƒå¼é”
   - å¹‚ç­‰æ€§ä¿è¯
   - ä¼šè¯çŠ¶æ€ç®¡ç†

### âš ï¸ å…³é”®æ”¹è¿›æœºä¼š

| é—®é¢˜ | å½±å“ | ä¼˜å…ˆçº§ | é¢„æœŸæ”¶ç›Š |
|------|------|--------|----------|
| å­¦ä¹ çŠ¶æ€æ— æŒä¹…åŒ– | é‡å¯ä¸¢å¤±ç»éªŒ | P0 | æŒç»­å­¦ä¹ èƒ½åŠ› |
| è¯­ä¹‰è·¯ç”±å ä½ç¬¦ | è·¯ç”±å‡†ç¡®æ€§ä½ | P0 | å‡†ç¡®ç‡+30% |
| ç›‘æ§æŒ‡æ ‡ä¸è¶³ | æ— æ³•é‡åŒ–æ•ˆæœ | P0 | å¯è§‚æµ‹æ€§æå‡ |
| å¯è§†åŒ–éå®æ—¶ | è°ƒè¯•ä½“éªŒå·® | P1 | è°ƒè¯•æ•ˆç‡+50% |
| æ— æ¢ç´¢æœºåˆ¶ | å±€éƒ¨æœ€ä¼˜é£é™© | P1 | å‘ç°æ›´å¥½è·¯å¾„ |
| é‡å¤è®¡ç®—æ— ç¼“å­˜ | æ€§èƒ½ç“¶é¢ˆ | P1 | å»¶è¿Ÿ-60% |
| æ— A/Bæµ‹è¯• | æ— æ³•ç§‘å­¦è¯„ä¼° | P2 | æ•°æ®é©±åŠ¨ä¼˜åŒ– |
| æ‰§è¡Œä¸å¯å›æ”¾ | é—®é¢˜éš¾å¤ç° | P2 | å®šä½æ•ˆç‡+70% |
| å•ç»´åº¦å­¦ä¹  | å†³ç­–ä¸å…¨é¢ | P2 | ç»¼åˆè¯„åˆ† |
| ç´§è€¦åˆæ¶æ„ | æ‰©å±•å›°éš¾ | P3 | ç‹¬ç«‹æ‰©å±• |
| è°ƒè¯•å·¥å…·ç®€é™‹ | å¼€å‘æ•ˆç‡ä½ | P3 | å¼€å‘ä½“éªŒæå‡ |
| äººå·¥è°ƒä¼˜æˆæœ¬é«˜ | è¿ç»´è´Ÿæ‹…é‡ | P3 | è‡ªåŠ¨ä¼˜åŒ– |

---

## ğŸ“Š å®Œæ•´æ”¹è¿›æ–¹æ¡ˆ

### ğŸ”§ P0 - ç«‹å³å®æ–½ï¼ˆç”Ÿäº§å¿…éœ€ï¼‰

#### 1. æŒä¹…åŒ–è´å¶æ–¯å­¦ä¹ å™¨

**é—®é¢˜**: å­¦ä¹ çŠ¶æ€ä»…å­˜å†…å­˜ï¼Œé‡å¯ä¸¢å¤±æ‰€æœ‰ç»éªŒ

**å½“å‰å®ç°**:
```python
# backend/app/learning/bayesian_learner.py
class BayesianLearner:
    def __init__(self):
        self.stats: Dict[str, RouteStats] = {}  # ä»…å†…å­˜å­˜å‚¨
```

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/learning/persistent_bayesian_learner.py
import json
from typing import Dict, Optional
from loguru import logger

class PersistentBayesianLearner(BayesianLearner):
    """
    æ”¯æŒRedisæŒä¹…åŒ–çš„è´å¶æ–¯å­¦ä¹ å™¨
    """
    def __init__(self, redis_client, user_id: str, ttl: int = 86400 * 7):
        super().__init__()
        self.redis = redis_client
        self.user_id = user_id
        self.ttl = ttl  # 7å¤©è¿‡æœŸ
        self._loaded = False
    
    async def _load_from_redis(self):
        """ä»RedisåŠ è½½å­¦ä¹ å†å²ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._loaded:
            return
        
        try:
            data = await self.redis.get(f"learner:{self.user_id}")
            if data:
                loaded_stats = json.loads(data)
                # ååºåˆ—åŒ–ä¸ºRouteStatså¯¹è±¡
                for key, stats_data in loaded_stats.items():
                    self.stats[key] = RouteStats(
                        alpha=stats_data['alpha'],
                        beta=stats_data['beta']
                    )
                logger.info(f"Loaded {len(self.stats)} routes for user {self.user_id}")
            self._loaded = True
        except Exception as e:
            logger.error(f"Failed to load learner state: {e}")
    
    async def _save_to_redis(self):
        """æŒä¹…åŒ–åˆ°Redis"""
        if not self.stats:
            return
        
        try:
            # åºåˆ—åŒ–RouteStats
            serializable_stats = {
                key: {'alpha': stats.alpha, 'beta': stats.beta}
                for key, stats in self.stats.items()
            }
            
            await self.redis.setex(
                f"learner:{self.user_id}",
                self.ttl,
                json.dumps(serializable_stats)
            )
            logger.debug(f"Saved {len(self.stats)} routes for user {self.user_id}")
        except Exception as e:
            logger.error(f"Failed to save learner state: {e}")
    
    async def update(self, source: str, target: str, success: bool):
        """é‡å†™updateï¼Œè‡ªåŠ¨æŒä¹…åŒ–"""
        # å…ˆç¡®ä¿å·²åŠ è½½
        await self._load_from_redis()
        
        # æ‰§è¡Œçˆ¶ç±»æ›´æ–°
        super().update(source, target, success)
        
        # å¼‚æ­¥æŒä¹…åŒ–ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        asyncio.create_task(self._save_to_redis())
    
    async def get_probability(self, source: str, target: str) -> float:
        """è·å–æ¦‚ç‡ï¼ˆç¡®ä¿å·²åŠ è½½ï¼‰"""
        await self._load_from_redis()
        return super().get_probability(source, target)
    
    async def get_stats(self) -> Dict:
        """è·å–å®Œæ•´ç»Ÿè®¡ä¿¡æ¯"""
        await self._load_from_redis()
        return {
            key: {'alpha': stats.alpha, 'beta': stats.beta, 'mean': stats.mean}
            for key, stats in self.stats.items()
        }

# å·¥å‚å‡½æ•°
async def create_learner(redis_client, user_id: str) -> PersistentBayesianLearner:
    """åˆ›å»ºæŒä¹…åŒ–å­¦ä¹ å™¨"""
    learner = PersistentBayesianLearner(redis_client, user_id)
    await learner._load_from_redis()
    return learner
```

**é›†æˆåˆ°RouterNode**:
```python
# backend/app/routing/router_node.py
class RouterNode:
    def __init__(self, routes: List[str], redis_client=None, user_id: str = None):
        self.routes = routes
        self.graph_router = GraphBasedRouter()
        
        # ä½¿ç”¨æŒä¹…åŒ–å­¦ä¹ å™¨
        if redis_client and user_id:
            from app.learning.persistent_bayesian_learner import create_learner
            self.learner = await create_learner(redis_client, user_id)
        else:
            # é™çº§åˆ°å†…å­˜ç‰ˆæœ¬
            self.learner = BayesianLearner()
    
    async def __call__(self, state: WorkflowState) -> WorkflowState:
        # ... åŸæœ‰é€»è¾‘ ...
        
        # è·¯ç”±å†³ç­–
        next_route = self.graph_router.find_route(current_node, target_capability)
        
        # æ¦‚ç‡æ£€æŸ¥ï¼ˆç°åœ¨ä¼šä½¿ç”¨æŒä¹…åŒ–æ•°æ®ï¼‰
        if next_route:
            prob = await self.learner.get_probability(current_node, next_route)
            if prob < 0.3:
                logger.warning(f"Low probability route {current_node}->{next_route} ({prob:.2f})")
        
        # ... åç»­é€»è¾‘ ...
```

**æ•°æ®è¿ç§»è„šæœ¬**:
```python
# backend/scripts/migrate_learner_data.py
async def migrate_learner_data():
    """ä»å†…å­˜å­¦ä¹ å™¨è¿ç§»åˆ°æŒä¹…åŒ–"""
    redis = await get_redis_client()
    
    # è¯»å–æ—§æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
    old_data = {}  # å‡è®¾ä»å¤‡ä»½è¯»å–
    
    for user_id, routes in old_data.items():
        learner = PersistentBayesianLearner(redis, user_id)
        for route, stats in routes.items():
            learner.stats[route] = RouteStats(**stats)
        await learner._save_to_redis()
```

**å®æ–½æ­¥éª¤**:
1. âœ… åˆ›å»ºæŒä¹…åŒ–å­¦ä¹ å™¨ç±»
2. âœ… ä¿®æ”¹RouterNodeæ³¨å…¥æŒä¹…åŒ–å®ä¾‹
3. âœ… æ·»åŠ Redisæ•°æ®è¿ç§»è„šæœ¬
4. âœ… é…ç½®TTLå’Œæ¸…ç†ç­–ç•¥
5. âœ… æ·»åŠ å•å…ƒæµ‹è¯•

**é¢„æœŸæ•ˆæœ**: å­¦ä¹ æˆæœæŒä¹…åŒ–ï¼Œç³»ç»ŸæŒç»­è¿›åŒ–ï¼Œé‡å¯ä¸ä¸¢å¤±ç»éªŒ

---

#### 2. è¯­ä¹‰è·¯ç”±å¢å¼º

**é—®é¢˜**: å½“å‰ä»…åŸºäºå…³é”®è¯åŒ¹é…ï¼Œè·¯ç”±å‡†ç¡®æ€§å—é™

**å½“å‰å®ç°**:
```python
# backend/app/routing/router_node.py
def _extract_capability(self, text: str) -> str:
    """Extract required capability from text."""
    return text  # å ä½ç¬¦ï¼
```

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/routing/semantic_router.py
from typing import Optional, List, Dict
from loguru import logger

class SemanticRouter:
    """
    åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ™ºèƒ½è·¯ç”±
    """
    def __init__(self, embedding_service, knowledge_graph=None):
        self.embedding = embedding_service
        self.kg = knowledge_graph
        # é¢„å®šä¹‰èƒ½åŠ›æ˜ å°„
        self.capability_map = {
            'math': ['æ•°å­¦', 'è®¡ç®—', 'å…¬å¼', 'æ–¹ç¨‹', 'ç®—æœ¯'],
            'code': ['ä»£ç ', 'ç¼–ç¨‹', 'python', 'javascript', 'å¼€å‘'],
            'knowledge': ['æœç´¢', 'æŸ¥è¯¢', 'çŸ¥è¯†', 'ä¿¡æ¯', 'èµ„æ–™'],
            'planning': ['è®¡åˆ’', 'è§„åˆ’', 'å®‰æ’', 'ä»»åŠ¡åˆ†è§£'],
            'reasoning': ['æ¨ç†', 'é€»è¾‘', 'åˆ†æ', 'æ€è€ƒ'],
            'writing': ['å†™ä½œ', 'åˆ›ä½œ', 'æ–‡ç« ', 'æ–‡æ¡ˆ'],
            'translation': ['ç¿»è¯‘', 'è¯­è¨€', 'å¤šè¯­è¨€'],
            'data_analysis': ['åˆ†æ', 'ç»Ÿè®¡', 'æ•°æ®', 'å›¾è¡¨']
        }
    
    async def route(self, query: str, context: Dict) -> Optional[str]:
        """
        åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦è·¯ç”±
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ç›®æ ‡Agentåç§°ï¼Œå¦‚æœä¸ç¡®å®šåˆ™è¿”å›None
        """
        try:
            # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vec = await self.embedding.embed(query)
            
            # 2. è®¡ç®—ä¸å„èƒ½åŠ›çš„ç›¸ä¼¼åº¦
            similarities = {}
            for capability, keywords in self.capability_map.items():
                # å…³é”®è¯åŒ¹é…ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
                keyword_score = sum(1 for kw in keywords if kw in query) / len(keywords)
                
                # è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆæ·±åº¦åŒ¹é…ï¼‰
                if self.kg:
                    # ä»çŸ¥è¯†å›¾è°±æ£€ç´¢
                    semantic_score = await self._kg_similarity(query_vec, capability)
                else:
                    # åŸºäºå…³é”®è¯çš„è¯­ä¹‰æ¨æ–­
                    semantic_score = keyword_score
                
                # ç»¼åˆè¯„åˆ†
                similarities[capability] = {
                    'keyword': keyword_score,
                    'semantic': semantic_score,
                    'combined': keyword_score * 0.3 + semantic_score * 0.7
                }
            
            # 3. é€‰æ‹©æœ€ä¼˜èƒ½åŠ›
            best_capability = None
            best_score = 0
            
            for capability, scores in similarities.items():
                if scores['combined'] > best_score and scores['combined'] > 0.6:
                    best_score = scores['combined']
                    best_capability = capability
            
            if best_capability:
                logger.info(f"Semantic routing: '{query}' -> {best_capability} (score: {best_score:.2f})")
                return best_capability
            
            return None
            
        except Exception as e:
            logger.error(f"Semantic routing failed: {e}")
            return None
    
    async def _kg_similarity(self, query_vec: List[float], capability: str) -> float:
        """ä»çŸ¥è¯†å›¾è°±è®¡ç®—ç›¸ä¼¼åº¦"""
        if not self.kg:
            return 0.0
        
        # æŸ¥è¯¢çŸ¥è¯†å›¾è°±ä¸­è¯¥èƒ½åŠ›çš„ç›¸å…³æ¦‚å¿µ
        concepts = await self.kg.get_related_concepts(capability)
        if not concepts:
            return 0.0
        
        # è®¡ç®—å¹³å‡ç›¸ä¼¼åº¦
        similarities = []
        for concept in concepts:
            concept_vec = await self.embedding.embed(concept)
            sim = self._cosine_similarity(query_vec, concept_vec)
            similarities.append(sim)
        
        return sum(similarities) / len(similarities) if similarities else 0.0
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        import numpy as np
        return float(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))

# æ··åˆè·¯ç”±å™¨
class HybridRouter:
    """
    æ··åˆè·¯ç”±ï¼šè§„åˆ™ + è¯­ä¹‰ + å›¾ç®—æ³•
    """
    def __init__(self, graph_router, semantic_router, user_preferences=None):
        self.graph = graph_router
        self.semantic = semantic_router
        self.user_pref = user_preferences or {}
    
    async def find_route(self, current: str, query: str, context: Dict) -> Optional[str]:
        """
        å¤šç­–ç•¥è·¯ç”±å†³ç­–
        
        ä¼˜å…ˆçº§:
        1. è§„åˆ™è·¯ç”±ï¼ˆç¡®å®šæ€§åœºæ™¯ï¼‰
        2. è¯­ä¹‰è·¯ç”±ï¼ˆå¤æ‚æ„å›¾ï¼‰
        3. å›¾è·¯ç”±ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
        4. é»˜è®¤è·¯ç”±ï¼ˆå…œåº•ï¼‰
        """
        # 1. è§„åˆ™ä¼˜å…ˆï¼ˆç¡¬ç¼–ç çš„ç¡®å®šæ€§è§„åˆ™ï¼‰
        rule_result = self._apply_rules(query, context)
        if rule_result:
            logger.info(f"Rule-based routing: {rule_result}")
            return rule_result
        
        # 2. è¯­ä¹‰è·¯ç”±ï¼ˆç†è§£ç”¨æˆ·æ„å›¾ï¼‰
        semantic_result = await self.semantic.route(query, context)
        if semantic_result:
            # éªŒè¯ç›®æ ‡èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
            if semantic_result in self.graph.graph.nodes():
                logger.info(f"Semantic routing: {semantic_result}")
                return semantic_result
        
        # 3. å›¾è·¯ç”±ï¼ˆåŸºäºå†å²æ€§èƒ½ï¼‰
        capability = self._extract_capability(query)
        if capability:
            graph_result = self.graph.find_route(current, capability)
            if graph_result:
                logger.info(f"Graph routing: {graph_result}")
                return graph_result
        
        # 4. é»˜è®¤è·¯ç”±ï¼ˆè¿”å›åˆ°orchestratorï¼‰
        logger.warning(f"No route found, defaulting to orchestrator")
        return "orchestrator"
    
    def _apply_rules(self, query: str, context: Dict) -> Optional[str]:
        """ç¡¬ç¼–ç è§„åˆ™"""
        query_lower = query.lower()
        
        # ç´§æ€¥/é”™è¯¯åœºæ™¯
        if any(word in query_lower for word in ['error', 'bug', 'å¤±è´¥', 'é”™è¯¯']):
            return "debug_agent" if "debug_agent" in self.graph.graph.nodes() else None
        
        # ç®€å•æ•°å­¦è®¡ç®—
        if any(word in query_lower for word in ['calculate', 'è®¡ç®—', 'ç­‰äº', '+', '-', '*', '/']):
            return "math_agent" if "math_agent" in self.graph.graph.nodes() else None
        
        # ä»£ç ç›¸å…³
        if any(word in query_lower for word in ['code', 'python', 'javascript', 'ç¼–ç¨‹', 'ä»£ç ']):
            return "code_agent" if "code_agent" in self.graph.graph.nodes() else None
        
        return None
    
    def _extract_capability(self, text: str) -> str:
        """ä»æ–‡æœ¬æå–èƒ½åŠ›å…³é”®è¯"""
        text_lower = text.lower()
        
        for capability, keywords in self.semantic.capability_map.items():
            if any(kw in text_lower for kw in keywords):
                return capability
        
        return ""
```

**é›†æˆåˆ°RouterNode**:
```python
# backend/app/routing/router_node.py
class RouterNode:
    def __init__(self, routes: List[str], redis_client=None, user_id: str = None):
        self.routes = routes
        
        # åˆå§‹åŒ–å›¾è·¯ç”±å™¨
        self.graph_router = GraphBasedRouter()
        
        # åˆå§‹åŒ–è¯­ä¹‰è·¯ç”±å™¨ï¼ˆéœ€è¦embeddingæœåŠ¡ï¼‰
        from app.services.embedding_service import embedding_service
        from app.services.knowledge_service import knowledge_service
        
        self.semantic_router = SemanticRouter(
            embedding=embedding_service,
            knowledge_graph=knowledge_service
        )
        
        # æ··åˆè·¯ç”±å™¨
        self.hybrid_router = HybridRouter(
            graph_router=self.graph_router,
            semantic_router=self.semantic_router
        )
        
        # æŒä¹…åŒ–å­¦ä¹ å™¨
        if redis_client and user_id:
            from app.learning.persistent_bayesian_learner import create_learner
            self.learner = await create_learner(redis_client, user_id)
        else:
            self.learner = BayesianLearner()
    
    async def __call__(self, state: WorkflowState) -> WorkflowState:
        # 1. è·å–ä¸Šä¸‹æ–‡
        last_msg = state.messages[-1]['content'] if state.messages else ""
        current_node = state.context_data.get("current_node", "orchestrator")
        user_id = state.context_data.get("user_id")
        
        # 2. ä½¿ç”¨æ··åˆè·¯ç”±ï¼ˆæ›¿ä»£åŸæ¥çš„ç®€å•è·¯ç”±ï¼‰
        next_route = await self.hybrid_router.find_route(
            current=current_node,
            query=last_msg,
            context=state.context_data
        )
        
        # 3. å­¦ä¹ éªŒè¯
        if next_route:
            prob = await self.learner.get_probability(current_node, next_route)
            if prob < 0.3:
                logger.warning(
                    f"Low probability route {current_node}->{next_route} ({prob:.2f}), "
                    f"considering fallback"
                )
                # å¯ä»¥é€‰æ‹©fallbackç­–ç•¥
                # next_route = self._fallback_route(current_node, last_msg)
        
        # 4. è®°å½•å†³ç­–
        state.context_data['router_decision'] = next_route
        state.context_data['router_confidence'] = prob if next_route else 0.0
        
        logger.info(f"ğŸ§­ Router selected: {next_route} (confidence: {prob:.2f})")
        
        return state
    
    def condition(self, state: WorkflowState) -> str:
        """æ¡ä»¶è¾¹å‡½æ•°"""
        return state.context_data.get('router_decision', "__end__")
```

**é…ç½®å’Œä¾èµ–**:
```python
# backend/app/services/embedding_service.py
class EmbeddingService:
    """åµŒå…¥æœåŠ¡ï¼ˆå·²æœ‰æˆ–éœ€è¦å®ç°ï¼‰"""
    async def embed(self, text: str) -> List[float]:
        # è°ƒç”¨LLM APIç”ŸæˆåµŒå…¥å‘é‡
        # æˆ–ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        pass

# backend/app/services/knowledge_service.py
class KnowledgeService:
    """çŸ¥è¯†å›¾è°±æœåŠ¡"""
    async def get_related_concepts(self, capability: str) -> List[str]:
        # ä»pgvectoræˆ–çŸ¥è¯†å›¾è°±æŸ¥è¯¢
        pass
    
    async def search_capabilities(self, query_vec: List[float]) -> List[Dict]:
        # è¯­ä¹‰æœç´¢
        pass
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°è¯­ä¹‰è·¯ç”±å™¨æ ¸å¿ƒé€»è¾‘
2. âœ… å®ç°æ··åˆè·¯ç”±å™¨
3. âœ… é›†æˆembeddingæœåŠ¡
4. âœ… æ›´æ–°RouterNodeä½¿ç”¨æ··åˆè·¯ç”±
5. âœ… æ·»åŠ é…ç½®å¼€å…³ï¼ˆå¯å›é€€åˆ°æ—§ç‰ˆæœ¬ï¼‰

**é¢„æœŸæ•ˆæœ**: 
- è·¯ç”±å‡†ç¡®ç‡æå‡30-40%
- å¤æ‚æ„å›¾ç†è§£èƒ½åŠ›å¢å¼º
- æ”¯æŒå¤šç­–ç•¥å†³ç­–

---

#### 3. ä¸šåŠ¡ç›‘æ§æŒ‡æ ‡

**é—®é¢˜**: ç¼ºå°‘å…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼Œæ— æ³•é‡åŒ–æ”¹è¿›æ•ˆæœ

**å½“å‰å®ç°**:
```python
# backend/app/core/metrics.py
# ä»…æœ‰åŸºç¡€è¯·æ±‚æŒ‡æ ‡ï¼Œç¼ºå°‘ä¸šåŠ¡æŒ‡æ ‡
```

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/core/business_metrics.py
from prometheus_client import Counter, Histogram, Gauge, Summary
from functools import wraps
import time

# ========== è·¯ç”±å†³ç­–æŒ‡æ ‡ ==========
ROUTING_DECISIONS = Counter(
    'sparkle_routing_decisions_total',
    'Total routing decisions by method',
    ['source', 'target', 'method']  # method: graph/semantic/rule/hybrid
)

ROUTING_SUCCESS = Counter(
    'sparkle_routing_success_total',
    'Successful routing executions',
    ['source', 'target']
)

ROUTING_FAILURE = Counter(
    'sparkle_routing_failure_total',
    'Failed routing executions',
    ['source', 'target', 'reason']
)

ROUTING_LATENCY = Histogram(
    'sparkle_routing_latency_seconds',
    'Routing decision latency',
    ['method']
)

ROUTING_CONFIDENCE = Histogram(
    'sparkle_routing_confidence',
    'Routing confidence distribution',
    ['method']
)

# ========== å­¦ä¹ æ•ˆæœæŒ‡æ ‡ ==========
LEARNING_UPDATES = Counter(
    'sparkle_learning_updates_total',
    'Bayesian learning updates',
    ['source', 'target', 'outcome']  # outcome: success/failure
)

PROBABILITY_DISTRIBUTION = Gauge(
    'sparkle_route_probability',
    'Current probability of route',
    ['source', 'target']
)

LEARNER_STATE_SIZE = Gauge(
    'sparkle_learner_state_size',
    'Number of routes in learner',
    ['user_id']
)

# ========== åä½œæˆåŠŸç‡æŒ‡æ ‡ ==========
COLLABORATION_SUCCESS = Counter(
    'sparkle_collaboration_success_total',
    'Successful multi-agent collaborations',
    ['workflow_type', 'agents_used', 'outcome']
)

COLLABORATION_LATENCY = Histogram(
    'sparkle_collaboration_latency_seconds',
    'Full collaboration workflow latency',
    ['workflow_type']
)

AGENT_INTERACTION_COUNT = Counter(
    'sparkle_agent_interactions_total',
    'Number of agent-to-agent interactions',
    ['from_agent', 'to_agent', 'type']
)

# ========== ç³»ç»Ÿå¥åº·æŒ‡æ ‡ ==========
ACTIVE_LEARNERS = Gauge(
    'sparkle_active_learners_total',
    'Number of active Bayesian learners'
)

ACTIVE_SESSIONS = Gauge(
    'sparkle_active_sessions_total',
    'Number of active chat sessions'
)

CACHE_EFFECTIVENESS = Counter(
    'sparkle_cache_effectiveness',
    'Cache hit/miss for routing',
    ['cache_type', 'result']  # result: hit/miss
)

# ========== æ€§èƒ½æŒ‡æ ‡ ==========
STATE_SIZE = Gauge(
    'sparkle_workflow_state_size_bytes',
    'Size of workflow state in memory',
    ['session_id']
)

GRAPH_COMPLEXITY = Gauge(
    'sparkle_graph_complexity',
    'Number of nodes and edges in graph',
    ['graph_name']
)

# ========== è£…é¥°å™¨å’Œå·¥å…·å‡½æ•° ==========
def track_routing_decision(method: str):
    """è·¯ç”±å†³ç­–è¿½è¸ªè£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            source = kwargs.get('source', 'unknown')
            target = kwargs.get('target', 'unknown')
            
            try:
                result = await func(*args, **kwargs)
                latency = time.time() - start_time
                
                # è®°å½•æˆåŠŸ
                if result:
                    ROUTING_SUCCESS.labels(source=source, target=target).inc()
                    ROUTING_CONFIDENCE.labels(method=method).observe(
                        kwargs.get('confidence', 0.5)
                    )
                
                # è®°å½•å»¶è¿Ÿ
                ROUTING_LATENCY.labels(method=method).observe(latency)
                
                # è®°å½•å†³ç­–
                ROUTING_DECISIONS.labels(source=source, target=target, method=method).inc()
                
                return result
                
            except Exception as e:
                # è®°å½•å¤±è´¥
                ROUTING_FAILURE.labels(
                    source=source, 
                    target=target, 
                    reason=str(e)
                ).inc()
                raise
        
        return wrapper
    return decorator

def track_learning_update(source: str, target: str, success: bool):
    """å­¦ä¹ æ›´æ–°è¿½è¸ª"""
    outcome = "success" if success else "failure"
    LEARNING_UPDATES.labels(source=source, target=target, outcome=outcome).inc()

def track_collaboration(workflow_type: str, agents: List[str]):
    """åä½œè¿‡ç¨‹è¿½è¸ª"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            
            try:
                result = await func(*args, **kwargs)
                latency = time.time() - start_time
                
                agents_used = ",".join(sorted(agents))
                outcome = "success" if result else "failure"
                
                COLLABORATION_SUCCESS.labels(
                    workflow_type=workflow_type,
                    agents_used=agents_used,
                    outcome=outcome
                ).inc()
                
                COLLABORATION_LATENCY.labels(workflow_type=workflow_type).observe(latency)
                
                return result
                
            except Exception as e:
                COLLABORATION_SUCCESS.labels(
                    workflow_type=workflow_type,
                    agents_used=",".join(sorted(agents)),
                    outcome="error"
                ).inc()
                raise
        
        return wrapper
    return decorator

# ========== ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§ç±» ==========
class BusinessMetricsCollector:
    """ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self._cache = {}
    
    def update_route_probability(self, source: str, target: str, probability: float):
        """æ›´æ–°è·¯ç”±æ¦‚ç‡æŒ‡æ ‡"""
        PROBABILITY_DISTRIBUTION.labels(source=source, target=target).set(probability)
    
    def update_learner_state_size(self, user_id: str, size: int):
        """æ›´æ–°å­¦ä¹ å™¨çŠ¶æ€å¤§å°"""
        LEARNER_STATE_SIZE.labels(user_id=user_id).set(size)
    
    def record_cache_hit(self, cache_type: str, hit: bool):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        result = "hit" if hit else "miss"
        CACHE_EFFECTIVENESS.labels(cache_type=cache_type, result=result).inc()
    
    def update_graph_complexity(self, graph_name: str, nodes: int, edges: int):
        """æ›´æ–°å›¾å¤æ‚åº¦"""
        GRAPH_COMPLEXITY.labels(graph_name=graph_name).set(nodes + edges)
    
    def record_agent_interaction(self, from_agent: str, to_agent: str, interaction_type: str):
        """è®°å½•Agentäº¤äº’"""
        AGENT_INTERACTION_COUNT.labels(
            from_agent=from_agent,
            to_agent=to_agent,
            type=interaction_type
        ).inc()
    
    def update_state_size(self, session_id: str, state: WorkflowState):
        """æ›´æ–°çŠ¶æ€å¤§å°"""
        import sys
        size = sys.getsizeof(state.messages) + sys.getsizeof(state.context_data)
        STATE_SIZE.labels(session_id=session_id).set(size)

# å…¨å±€å®ä¾‹
metrics_collector = BusinessMetricsCollector()
```

**åœ¨å…³é”®èŠ‚ç‚¹åŸ‹ç‚¹**:
```python
# backend/app/routing/router_node.py
from app.core.business_metrics import track_routing_decision, metrics_collector

class RouterNode:
    # ... __init__ ...
    
    @track_routing_decision(method="hybrid")
    async def find_route_with_metrics(self, current: str, query: str, context: Dict) -> str:
        """å¸¦æŒ‡æ ‡è¿½è¸ªçš„è·¯ç”±"""
        route = await self.hybrid_router.find_route(current, query, context)
        
        if route:
            # æ›´æ–°æ¦‚ç‡æŒ‡æ ‡
            prob = await self.learner.get_probability(current, route)
            metrics_collector.update_route_probability(current, route, prob)
            
            # è®°å½•å­¦ä¹ æ›´æ–°ï¼ˆåœ¨æ‰§è¡Œåï¼‰
            # è¿™é‡Œåªè®°å½•å†³ç­–ï¼Œå®é™…æˆåŠŸ/å¤±è´¥åœ¨æ‰§è¡Œåæ›´æ–°
            
            # è®°å½•ç¼“å­˜æ•ˆæœ
            if self.hybrid_router.graph.cache:
                hit = await self.hybrid_router.graph.cache.get_route(current, route)
                metrics_collector.record_cache_hit("route", hit is not None)
        
        return route

# backend/app/orchestration/orchestrator.py
from app.core.business_metrics import track_collaboration

class ChatOrchestrator:
    # ... å…¶ä»–æ–¹æ³• ...
    
    @track_collaboration(workflow_type="standard_chat", agents=["context_builder", "retrieval", "generation"])
    async def process_stream(self, request, db_session, context_data):
        """å¸¦åä½œæŒ‡æ ‡è¿½è¸ªçš„å¤„ç†æµç¨‹"""
        # ... åŸæœ‰é€»è¾‘ ...
        pass
```

**Grafanaä»ªè¡¨æ¿é…ç½®**:
```yaml
# monitoring/grafana-dashboards/business-metrics.yml
dashboard:
  title: "Sparkle Business Metrics"
  panels:
    - title: "Routing Success Rate"
      type: stat
      targets:
        - expr: 'rate(sparkle_routing_success_total[5m]) / rate(sparkle_routing_decisions_total[5m])'
    
    - title: "Routing Latency by Method"
      type: graph
      targets:
        - expr: 'histogram_quantile(0.95, rate(sparkle_routing_latency_seconds_bucket[5m]))'
          legend: "p95 latency"
    
    - title: "Learning Progress"
      type: graph
      targets:
        - expr: 'sparkle_route_probability'
          legend: "{{source}} -> {{target}}"
    
    - title: "Collaboration Success Rate"
      type: stat
      targets:
        - expr: 'rate(sparkle_collaboration_success_total{outcome="success"}[5m]) / rate(sparkle_collaboration_success_total[5m])'
    
    - title: "Cache Effectiveness"
      type: piechart
      targets:
        - expr: 'sum by (result) (sparkle_cache_effectiveness)'
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®šä¹‰ä¸šåŠ¡æŒ‡æ ‡
2. âœ… å®ç°è¿½è¸ªè£…é¥°å™¨
3. âœ… åœ¨å…³é”®èŠ‚ç‚¹åŸ‹ç‚¹
4. âœ… é…ç½®Prometheus scraping
5. âœ… åˆ›å»ºGrafanaä»ªè¡¨æ¿
6. âœ… æ·»åŠ å‘Šè­¦è§„åˆ™

**é¢„æœŸæ•ˆæœ**: 
- å¯è§‚æµ‹æ€§è¾¾åˆ°ç”Ÿäº§çº§æ ‡å‡†
- å¯é‡åŒ–æ¯ä¸ªæ”¹è¿›çš„æ•ˆæœ
- æ”¯æŒæ•°æ®é©±åŠ¨å†³ç­–

---

### ğŸš€ P1 - 1-2å‘¨å†…ï¼ˆä½“éªŒæå‡ï¼‰

#### 4. å®æ—¶å¯è§†åŒ–å¢å¼º

**é—®é¢˜**: é™æ€ç”Ÿæˆï¼Œæ— WebSocketå®æ—¶æ›´æ–°

**å½“å‰å®ç°**:
```python
# backend/app/visualization/state_visualizer.py
class StateVisualizer:
    def generate_mermaid(self, graph, current_state=None) -> str:
        # é™æ€ç”Ÿæˆï¼Œæ— å®æ—¶æ›´æ–°
        pass
```

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/visualization/realtime_visualizer.py
from typing import Optional, Callable
from loguru import logger
import asyncio
import json

class RealtimeVisualizer(StateVisualizer):
    """
    æ”¯æŒWebSocketå®æ—¶æ›´æ–°çš„å¯è§†åŒ–å™¨
    """
    
    def __init__(self, websocket_manager):
        super().__init__()
        self.ws = websocket_manager
        self.event_buffer = {}  # äº‹ä»¶ç¼“å†²åŒº
        self.subscribers = {}   # è®¢é˜…è€…æ˜ å°„
    
    async def subscribe(self, session_id: str, websocket):
        """è®¢é˜…ä¼šè¯çš„å¯è§†åŒ–æµ"""
        self.subscribers[session_id] = websocket
        logger.info(f"Client subscribed to session {session_id}")
        
        # å‘é€å½“å‰çŠ¶æ€
        current_state = await self._get_current_state(session_id)
        if current_state:
            await self._send_update(session_id, {
                "type": "initial_state",
                "mermaid": self.generate_mermaid(current_state.graph, current_state.state),
                "state": self._serialize_state(current_state.state)
            })
    
    async def unsubscribe(self, session_id: str):
        """å–æ¶ˆè®¢é˜…"""
        if session_id in self.subscribers:
            del self.subscribers[session_id]
            logger.info(f"Client unsubscribed from session {session_id}")
    
    async def on_graph_event(self, event: GraphEvent):
        """ç›‘å¬å›¾äº‹ä»¶ï¼Œå®æ—¶æ¨é€"""
        session_id = event.state.context_data.get("session_id")
        if not session_id:
            return
        
        # ç”Ÿæˆå¯è§†åŒ–
        mermaid = self.generate_mermaid(event.state)
        
        # æ ¹æ®äº‹ä»¶ç±»å‹æ·»åŠ åŠ¨æ€æ ·å¼
        styled_mermaid = self._apply_event_styles(mermaid, event)
        
        # å‡†å¤‡æ›´æ–°æ•°æ®
        update_data = {
            "type": "graph_update",
            "event": event.type.value,
            "node": event.node_id,
            "timestamp": event.timestamp,
            "mermaid": styled_mermaid,
            "state_snapshot": self._serialize_state(event.state),
            "details": event.details
        }
        
        # å‘é€ç»™è®¢é˜…è€…
        await self._send_update(session_id, update_data)
        
        # ç¼“å†²äº‹ä»¶ç”¨äºå›æ”¾
        await self._buffer_event(session_id, update_data)
    
    def _apply_event_styles(self, mermaid: str, event: GraphEvent) -> str:
        """æ ¹æ®äº‹ä»¶åŠ¨æ€æ·»åŠ æ ·å¼"""
        styles = []
        classes = []
        
        if event.type == GraphEventType.NODE_START:
            styles.append("    classDef executing fill:#FFA500,stroke:#333,stroke-width:2px;")
            classes.append(f"    class {event.node_id} executing;")
        
        elif event.type == GraphEventType.NODE_END:
            styles.append("    classDef completed fill:#32CD32,stroke:#333,stroke-width:2px;")
            classes.append(f"    class {event.node_id} completed;")
        
        elif event.type == GraphEventType.ERROR:
            styles.append("    classDef error fill:#FF4444,stroke:#333,stroke-width:2px;")
            classes.append(f"    class {event.node_id} error;")
        
        elif event.type == GraphEventType.EDGE_TRAVERSAL:
            # é«˜äº®è¾¹
            if "->" in event.node_id:
                from_node, to_node = event.node_id.split("->")
                styles.append("    classDef active_edge stroke:#00FF00,stroke-width:3px;")
                classes.append(f"    class {from_node},{to_node} active_edge;")
        
        # åˆå¹¶æ ·å¼
        if styles or classes:
            mermaid += "\n" + "\n".join(styles + classes)
        
        return mermaid
    
    async def _send_update(self, session_id: str, data: dict):
        """å‘é€æ›´æ–°åˆ°WebSocket"""
        if session_id not in self.subscribers:
            return
        
        try:
            websocket = self.subscribers[session_id]
            await websocket.send_json(data)
        except Exception as e:
            logger.error(f"Failed to send update to {session_id}: {e}")
            await self.unsubscribe(session_id)
    
    async def _buffer_event(self, session_id: str, event: dict):
        """ç¼“å†²äº‹ä»¶ç”¨äºå›æ”¾"""
        if session_id not in self.event_buffer:
            self.event_buffer[session_id] = []
        
        self.event_buffer[session_id].append(event)
        
        # é™åˆ¶ç¼“å†²åŒºå¤§å°
        if len(self.event_buffer[session_id]) > 1000:
            self.event_buffer[session_id] = self.event_buffer[session_id][-500:]
    
    async def get_event_history(self, session_id: str, limit: int = 100):
        """è·å–äº‹ä»¶å†å²"""
        if session_id not in self.event_buffer:
            return []
        
        return self.event_buffer[session_id][-limit:]
    
    async def _get_current_state(self, session_id: str):
        """è·å–å½“å‰çŠ¶æ€ï¼ˆä»checkpointerï¼‰"""
        # è¿™é‡Œéœ€è¦è®¿é—®checkpointer
        return None
    
    def _serialize_state(self, state) -> dict:
        """åºåˆ—åŒ–çŠ¶æ€ç”¨äºä¼ è¾“"""
        return {
            "messages_count": len(state.messages),
            "context_keys": list(state.context_data.keys()),
            "errors": state.errors,
            "next_step": state.next_step,
            "trace_id": state.trace_id
        }

# WebSocketç®¡ç†å™¨
class WebSocketManager:
    """WebSocketè¿æ¥ç®¡ç†"""
    
    def __init__(self):
        self.connections: Dict[str, WebSocket] = {}
        self.visualizer = RealtimeVisualizer(self)
    
    async def connect(self, session_id: str, websocket):
        """å»ºç«‹è¿æ¥"""
        self.connections[session_id] = websocket
        await self.visualizer.subscribe(session_id, websocket)
        
        # å‘é€æ¬¢è¿æ¶ˆæ¯
        await websocket.send_json({
            "type": "connected",
            "message": "Real-time visualization stream started",
            "session_id": session_id
        })
    
    async def disconnect(self, session_id: str):
        """æ–­å¼€è¿æ¥"""
        if session_id in self.connections:
            del self.connections[session_id]
        await self.visualizer.unsubscribe(session_id)
    
    async def broadcast(self, session_id: str, data: dict):
        """å¹¿æ’­åˆ°ç‰¹å®šä¼šè¯"""
        if session_id in self.connections:
            try:
                await self.connections[session_id].send_json(data)
            except:
                await self.disconnect(session_id)
    
    def get_visualizer(self) -> RealtimeVisualizer:
        return self.visualizer

# WebSocketç«¯ç‚¹
from fastapi import WebSocket, WebSocketDisconnect

@app.websocket("/ws/visualize/{session_id}")
async def websocket_visualize(websocket: WebSocket, session_id: str):
    """å¯è§†åŒ–WebSocketç«¯ç‚¹"""
    await websocket.accept()
    
    ws_manager = get_websocket_manager()  # è·å–å…¨å±€å®ä¾‹
    
    try:
        await ws_manager.connect(session_id, websocket)
        
        # ä¿æŒè¿æ¥
        while True:
            # æ¥æ”¶å¿ƒè·³æˆ–å®¢æˆ·ç«¯æ¶ˆæ¯
            data = await websocket.receive_text()
            if data == "ping":
                await websocket.send_text("pong")
    
    except WebSocketDisconnect:
        await ws_manager.disconnect(session_id)
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        await ws_manager.disconnect(session_id)
```

**é›†æˆåˆ°Orchestrator**:
```python
# backend/app/orchestration/orchestrator.py
class ChatOrchestrator:
    def __init__(self, db_session=None, redis_client=None):
        # ... åŸæœ‰åˆå§‹åŒ– ...
        
        # æ·»åŠ WebSocketç®¡ç†å™¨
        from app.visualization.realtime_visualizer import WebSocketManager
        self.ws_manager = WebSocketManager()
        
        # å°†å¯è§†åŒ–å™¨æ³¨å…¥åˆ°graph
        if hasattr(self, 'graph'):
            self.graph.on_event = self.ws_manager.get_visualizer().on_graph_event
    
    async def process_stream(self, request, db_session, context_data):
        """å¤„ç†æµç¨‹ï¼ˆè‡ªåŠ¨è§¦å‘å®æ—¶æ›´æ–°ï¼‰"""
        # ... åŸæœ‰é€»è¾‘ ...
        
        # ç¡®ä¿äº‹ä»¶ç›‘å¬å™¨å·²è®¾ç½®
        self.graph.on_event = self.ws_manager.get_visualizer().on_graph_event
        
        # ... æ‰§è¡Œgraph.invoke ...
```

**å‰ç«¯WebSocketå®¢æˆ·ç«¯**:
```javascript
// frontend/visualizer_client.js
class RealtimeVisualizer {
    constructor(sessionId, containerId) {
        this.sessionId = sessionId;
        this.container = document.getElementById(containerId);
        this.ws = null;
        this.isConnected = false;
    }
    
    connect() {
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const wsUrl = `${protocol}//${window.location.host}/ws/visualize/${this.sessionId}`;
        
        this.ws = new WebSocket(wsUrl);
        
        this.ws.onopen = () => {
            console.log('Connected to visualization stream');
            this.isConnected = true;
            this._showStatus('Connected', 'success');
        };
        
        this.ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            this._handleUpdate(data);
        };
        
        this.ws.onerror = (error) => {
            console.error('WebSocket error:', error);
            this._showStatus('Connection error', 'error');
        };
        
        this.ws.onclose = () => {
            console.log('Disconnected from visualization stream');
            this.isConnected = false;
            this._showStatus('Disconnected', 'warning');
            // è‡ªåŠ¨é‡è¿
            setTimeout(() => this.connect(), 3000);
        };
        
        // å‘é€å¿ƒè·³
        this.heartbeat = setInterval(() => {
            if (this.isConnected) {
                this.ws.send('ping');
            }
        }, 30000);
    }
    
    _handleUpdate(data) {
        switch(data.type) {
            case 'connected':
                this._showStatus(data.message, 'success');
                break;
                
            case 'initial_state':
            case 'graph_update':
                this._updateGraph(data.mermaid);
                this._updateEventLog(data);
                this._updateStateInspector(data.state_snapshot);
                break;
                
            case 'error':
                this._showStatus(data.message, 'error');
                break;
        }
    }
    
    _updateGraph(mermaidCode) {
        // ä½¿ç”¨Mermaid.jsæ¸²æŸ“
        mermaid.render('graph', mermaidCode, (svg) => {
            this.container.innerHTML = svg;
            
            // æ·»åŠ ç‚¹å‡»äº‹ä»¶
            this.container.querySelectorAll('g.node').forEach(node => {
                node.style.cursor = 'pointer';
                node.addEventListener('click', (e) => {
                    const nodeId = e.target.textContent || e.target.parentElement.textContent;
                    this._inspectNode(nodeId);
                });
            });
        });
    }
    
    _updateEventLog(data) {
        const logContainer = document.getElementById('event-log');
        if (!logContainer) return;
        
        const entry = document.createElement('div');
        entry.className = `event-entry event-${data.event.toLowerCase()}`;
        entry.innerHTML = `
            <span class="timestamp">${new Date(data.timestamp * 1000).toLocaleTimeString()}</span>
            <span class="event">${data.event}</span>
            <span class="node">${data.node}</span>
            ${data.details ? `<span class="details">${data.details}</span>` : ''}
        `;
        
        logContainer.appendChild(entry);
        logContainer.scrollTop = logContainer.scrollHeight;
    }
    
    _updateStateInspector(state) {
        const inspector = document.getElementById('state-inspector');
        if (!inspector) return;
        
        inspector.innerHTML = `
            <div class="state-section">
                <h4>Messages</h4>
                <p>${state.messages_count} messages</p>
            </div>
            <div class="state-section">
                <h4>Context</h4>
                <ul>${state.context_keys.map(k => `<li>${k}</li>`).join('')}</ul>
            </div>
            ${state.errors.length > 0 ? `
                <div class="state-section error">
                    <h4>Errors</h4>
                    <ul>${state.errors.map(e => `<li>${e}</li>`).join('')}</ul>
                </div>
            ` : ''}
        `;
    }
    
    _inspectNode(nodeId) {
        // å‘é€èŠ‚ç‚¹æ£€æŸ¥è¯·æ±‚
        this.ws.send(JSON.stringify({
            type: 'inspect_node',
            node_id: nodeId
        }));
        
        // æ˜¾ç¤ºæ¨¡æ€æ¡†
        this._showNodeModal(nodeId);
    }
    
    _showStatus(message, type) {
        const status = document.getElementById('connection-status');
        if (status) {
            status.textContent = message;
            status.className = `status-${type}`;
        }
    }
    
    _showNodeModal(nodeId) {
        // å®ç°èŠ‚ç‚¹è¯¦æƒ…æ¨¡æ€æ¡†
        console.log(`Inspecting node: ${nodeId}`);
    }
    
    disconnect() {
        if (this.ws) {
            this.ws.close();
        }
        if (this.heartbeat) {
            clearInterval(this.heartbeat);
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
const visualizer = new RealtimeVisualizer('session-123', 'graph-container');
visualizer.connect();
```

**é›†æˆåˆ°ç°æœ‰Orchestrator**:
```python
# backend/app/orchestration/orchestrator.py
class ChatOrchestrator:
    def __init__(self, db_session=None, redis_client=None):
        # ... åŸæœ‰ä»£ç  ...
        
        # åˆå§‹åŒ–WebSocketç®¡ç†å™¨
        from app.visualization.realtime_visualizer import WebSocketManager
        self.ws_manager = WebSocketManager()
        
        # æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
        self.graph.on_event = self.ws_manager.get_visualizer().on_graph_event
    
    async def process_stream(self, request, db_session, context_data):
        """å¤„ç†æµç¨‹"""
        # ... åŸæœ‰é€»è¾‘ ...
        
        # ç¡®ä¿äº‹ä»¶ç›‘å¬å™¨å·²è®¾ç½®ï¼ˆåœ¨graph.invokeä¹‹å‰ï¼‰
        self.graph.on_event = self.ws_manager.get_visualizer().on_graph_event
        
        # æ‰§è¡Œgraph
        graph_task = asyncio.create_task(self.graph.invoke(state))
        
        # ... åç»­é€»è¾‘ ...
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°WebSocketç®¡ç†å™¨
2. âœ… å®ç°å®æ—¶å¯è§†åŒ–å™¨
3. âœ… åˆ›å»ºWebSocketç«¯ç‚¹
4. âœ… é›†æˆåˆ°orchestrator
5. âœ… å¼€å‘å‰ç«¯å®¢æˆ·ç«¯
6. âœ… æ·»åŠ çŠ¶æ€æ£€æŸ¥åŠŸèƒ½

**é¢„æœŸæ•ˆæœ**: 
- è°ƒè¯•æ•ˆç‡æå‡50%
- å®æ—¶è§‚å¯Ÿæ‰§è¡Œè¿‡ç¨‹
- äº¤äº’å¼çŠ¶æ€æ£€æŸ¥

---

#### 5. æ¢ç´¢-åˆ©ç”¨ç­–ç•¥

**é—®é¢˜**: ä»…ä½¿ç”¨æ¦‚ç‡å‡å€¼ï¼Œæ— æ¢ç´¢æœºåˆ¶ï¼Œå¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜

**å½“å‰å®ç°**:
```python
# backend/app/routing/router_node.py
# ä»…ä½¿ç”¨ get_probability() çš„å‡å€¼
prob = self.learner.get_probability(source, target)
if prob < 0.3:
    # ç®€å•è­¦å‘Šï¼Œæ— ä¸»åŠ¨æ¢ç´¢
    pass
```

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/routing/exploration_router.py
import random
from typing import List, Dict
from loguru import logger

class ExplorationRouter:
    """
    æ”¯æŒæ¢ç´¢-åˆ©ç”¨å¹³è¡¡çš„è·¯ç”±
    """
    def __init__(self, learner, epsilon: float = 0.1, adaptive: bool = True):
        """
        Args:
            learner: è´å¶æ–¯å­¦ä¹ å™¨
            epsilon: åˆå§‹æ¢ç´¢ç‡
            adaptive: æ˜¯å¦è‡ªé€‚åº”è°ƒæ•´æ¢ç´¢ç‡
        """
        self.learner = learner
        self.epsilon = epsilon
        self.adaptive = adaptive
        self.attempts: Dict[str, int] = {}  # è®°å½•æ¯ä¸ªç”¨æˆ·çš„å°è¯•æ¬¡æ•°
    
    async def select_route(self, source: str, targets: List[str], user_id: str = None) -> str:
        """
        Îµ-è´ªå©ªç­–ç•¥é€‰æ‹©è·¯ç”±
        
        ç­–ç•¥:
        - Îµæ¦‚ç‡éšæœºæ¢ç´¢ï¼ˆå°è¯•æ–°è·¯å¾„ï¼‰
        - 1-Îµæ¦‚ç‡åˆ©ç”¨ï¼ˆé€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼‰
        """
        if not targets:
            return None
        
        # æ¢ç´¢ç‡è°ƒæ•´
        current_epsilon = self._get_adaptive_epsilon(user_id) if self.adaptive else self.epsilon
        
        # æ¢ç´¢ vs åˆ©ç”¨
        if random.random() < current_epsilon:
            # æ¢ç´¢ï¼šéšæœºé€‰æ‹©
            selected = random.choice(targets)
            logger.info(f"ğŸ” Exploration: randomly selected {selected} (Îµ={current_epsilon:.2f})")
            return selected
        else:
            # åˆ©ç”¨ï¼šé€‰æ‹©æœ€ä¼˜
            scores = {}
            for target in targets:
                prob = await self.learner.get_probability(source, target)
                scores[target] = prob
            
            selected = max(scores, key=scores.get)
            logger.info(f"ğŸ¯ Exploitation: selected {selected} (score={scores[selected]:.2f})")
            return selected
    
    def _get_adaptive_epsilon(self, user_id: str) -> float:
        """
        è‡ªé€‚åº”æ¢ç´¢ç‡
        
        éšç€å­¦ä¹ è¿›å±•é™ä½æ¢ç´¢ç‡:
        - åˆå§‹: 0.3 (30%æ¢ç´¢)
        - 100æ¬¡å°è¯•å: 0.1 (10%æ¢ç´¢)
        - 200æ¬¡å°è¯•å: 0.05 (5%æ¢ç´¢)
        """
        if not user_id:
            return self.epsilon
        
        attempts = self.attempts.get(user_id, 0)
        self.attempts[user_id] = attempts + 1
        
        # æŒ‡æ•°è¡°å‡
        decay_rate = 0.99  # æ¯æ¬¡å°è¯•è¡°å‡1%
        base_epsilon = 0.3
        
        epsilon = base_epsilon * (decay_rate ** attempts)
        return max(0.05, epsilon)  # æœ€å°5%

# Thompsoné‡‡æ ·å®ç°
class ThompsonSamplingRouter:
    """
    Thompsoné‡‡æ ·ï¼šä»åéªŒåˆ†å¸ƒé‡‡æ ·
    
    ä¼˜ç‚¹:
    - è‡ªåŠ¨å¹³è¡¡æ¢ç´¢-åˆ©ç”¨
    - ç†è®ºä¸Šæœ‰æœ€ä¼˜ä¿è¯
    - é€‚åˆå¤šè‡‚è€è™æœºé—®é¢˜
    """
    
    def __init__(self, learner):
        self.learner = learner
    
    async def select_route(self, source: str, targets: List[str]) -> str:
        """
        ä»Betaåˆ†å¸ƒé‡‡æ ·ï¼Œé€‰æ‹©é‡‡æ ·å€¼æœ€å¤§çš„
        """
        if not targets:
            return None
        
        samples = {}
        for target in targets:
            stats = self.learner.stats.get(f"{source}->{target}")
            if stats:
                # Betaåˆ†å¸ƒé‡‡æ ·
                import random
                sample = random.betavariate(stats.alpha, stats.beta)
                samples[target] = sample
            else:
                # æœªæ¢ç´¢çš„è·¯å¾„ï¼Œç»™äºˆé«˜æ¢ç´¢å€¼
                samples[target] = random.random()
        
        selected = max(samples, key=samples.get)
        logger.info(f"ğŸ² Thompson Sampling: selected {selected} (samples={samples})")
        return selected

# UCB (Upper Confidence Bound) å®ç°
class UCBRouter:
    """
    UCB1ç®—æ³•ï¼šç½®ä¿¡ä¸Šç•Œ
    
    å…¬å¼: score = mean + sqrt(2 * ln(total_attempts) / attempts)
    """
    
    def __init__(self, learner):
        self.learner = learner
        self.total_attempts = 0
    
    async def select_route(self, source: str, targets: List[str]) -> str:
        """
        UCB1é€‰æ‹©
        """
        if not targets:
            return None
        
        self.total_attempts += 1
        
        scores = {}
        for target in targets:
            stats = self.learner.stats.get(f"{source}->{target}")
            if stats:
                attempts = stats.alpha + stats.beta - 2  # æ€»å°è¯•æ¬¡æ•°
                if attempts > 0:
                    mean = stats.mean
                    exploration = (2 * (self.total_attempts / attempts)) ** 0.5
                    scores[target] = mean + exploration
                else:
                    scores[target] = float('inf')  # æœªæ¢ç´¢ï¼Œä¼˜å…ˆå°è¯•
            else:
                scores[target] = float('inf')
        
        selected = max(scores, key=scores.get)
        logger.info(f"ğŸ“Š UCB: selected {selected} (scores={scores})")
        return selected

# æ··åˆç­–ç•¥è·¯ç”±å™¨
class HybridExplorationRouter:
    """
    æ··åˆç­–ç•¥ï¼šæ ¹æ®åœºæ™¯é€‰æ‹©æœ€ä½³æ¢ç´¢æ–¹å¼
    """
    
    def __init__(self, learner, user_id: str = None):
        self.learner = learner
        self.user_id = user_id
        
        # åˆå§‹åŒ–å„ç­–ç•¥
        self.epsilon_greedy = ExplorationRouter(learner, epsilon=0.1, adaptive=True)
        self.thompson = ThompsonSamplingRouter(learner)
        self.ucb = UCBRouter(learner)
    
    async def select_route(self, source: str, targets: List[str], context: Dict = None) -> str:
        """
        æ™ºèƒ½é€‰æ‹©ç­–ç•¥
        
        ç­–ç•¥é€‰æ‹©é€»è¾‘:
        - å°‘é‡å°è¯• (< 10): Thompsoné‡‡æ ·ï¼ˆå¿«é€Ÿæ¢ç´¢ï¼‰
        - ä¸­ç­‰å°è¯• (10-50): UCBï¼ˆå¹³è¡¡ï¼‰
        - å¤§é‡å°è¯• (> 50): Îµ-è´ªå©ªï¼ˆç¨³å®šï¼‰
        """
        if not targets:
            return None
        
        # è·å–å°è¯•æ¬¡æ•°
        attempts = 0
        if self.user_id:
            attempts = self._get_user_attempts(self.user_id)
        
        # ç­–ç•¥é€‰æ‹©
        if attempts < 10:
            # æ—©æœŸï¼šå¿«é€Ÿæ¢ç´¢
            selected = await self.thompson.select_route(source, targets)
            strategy = "thompson"
        elif attempts < 50:
            # ä¸­æœŸï¼šå¹³è¡¡
            selected = await self.ucb.select_route(source, targets)
            strategy = "ucb"
        else:
            # åæœŸï¼šç¨³å®šåˆ©ç”¨
            selected = await self.epsilon_greedy.select_route(source, targets, self.user_id)
            strategy = "epsilon_greedy"
        
        logger.info(f"Strategy: {strategy}, Attempts: {attempts}, Selected: {selected}")
        return selected
    
    def _get_user_attempts(self, user_id: str) -> int:
        """è·å–ç”¨æˆ·æ€»å°è¯•æ¬¡æ•°"""
        total = 0
        for stats in self.learner.stats.values():
            total += int(stats.alpha + stats.beta - 2)
        return total

# é›†æˆåˆ°RouterNode
# backend/app/routing/router_node.py
class RouterNode:
    def __init__(self, routes: List[str], redis_client=None, user_id: str = None):
        # ... åŸæœ‰åˆå§‹åŒ– ...
        
        # æ·»åŠ æ¢ç´¢è·¯ç”±å™¨
        from app.routing.exploration_router import HybridExplorationRouter
        
        if redis_client and user_id:
            from app.learning.persistent_bayesian_learner import create_learner
            self.learner = await create_learner(redis_client, user_id)
            self.exploration_router = HybridExplorationRouter(self.learner, user_id)
        else:
            self.learner = BayesianLearner()
            self.exploration_router = HybridExplorationRouter(self.learner)
    
    async def __call__(self, state: WorkflowState) -> WorkflowState:
        # ... åŸæœ‰é€»è¾‘ ...
        
        # 1. è·å–å€™é€‰è·¯ç”±
        candidates = self._get_candidate_routes(current_node, target_capability)
        
        if len(candidates) > 1:
            # 2. ä½¿ç”¨æ¢ç´¢ç­–ç•¥é€‰æ‹©
            next_route = await self.exploration_router.select_route(
                source=current_node,
                targets=candidates,
                context=state.context_data
            )
        elif len(candidates) == 1:
            next_route = candidates[0]
        else:
            next_route = "__end__"
        
        # 3. è®°å½•é€‰æ‹©
        state.context_data['router_decision'] = next_route
        state.context_data['router_strategy'] = self.exploration_router.__class__.__name__
        
        # 4. åç»­æ‰§è¡Œå’Œå­¦ä¹ æ›´æ–°...
        
        return state
    
    def _get_candidate_routes(self, current: str, capability: str) -> List[str]:
        """è·å–å€™é€‰è·¯ç”±åˆ—è¡¨"""
        # ä»å›¾ä¸­æ‰¾åˆ°æ‰€æœ‰å¯èƒ½çš„ä¸‹ä¸€è·³
        candidates = []
        
        # ç›´æ¥é‚»å±…
        if current in self.graph_router.graph:
            candidates.extend(list(self.graph_router.graph.neighbors(current)))
        
        # åŸºäºèƒ½åŠ›çš„æ˜ å°„
        target_node = self.graph_router._map_capability_to_node(capability)
        if target_node and target_node != current:
            candidates.append(target_node)
        
        # å»é‡
        return list(set(candidates))
```

**A/Bæµ‹è¯•æ¡†æ¶**:
```python
# backend/app/learning/ab_test_framework.py
class ABTestFramework:
    """A/Bæµ‹è¯•æ¡†æ¶"""
    
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def create_experiment(self, name: str, variants: List[str], traffic_split: Dict[str, float]):
        """åˆ›å»ºå®éªŒ"""
        exp_id = f"exp:{name}"
        config = {
            'variants': variants,
            'traffic_split': traffic_split,
            'start_time': datetime.now().isoformat(),
            'status': 'running'
        }
        await self.redis.set(exp_id, json.dumps(config))
        return exp_id
    
    async def assign_variant(self, user_id: str, exp_id: str) -> str:
        """åˆ†é…ç”¨æˆ·åˆ°å®éªŒç»„"""
        config = await self._get_config(exp_id)
        if not config:
            return 'control'
        
        # åŸºäºç”¨æˆ·IDå“ˆå¸Œï¼Œä¿è¯ä¸€è‡´æ€§
        hash_val = hash(f"{user_id}:{exp_id}") % 100
        total = 0
        for variant, weight in config['traffic_split'].items():
            total += weight * 100
            if hash_val < total:
                return variant
        
        return 'control'
    
    async def record_outcome(self, exp_id: str, variant: str, metrics: Dict):
        """è®°å½•å®éªŒç»“æœ"""
        key = f"exp_results:{exp_id}:{variant}"
        await self.redis.lpush(key, json.dumps({
            **metrics,
            'timestamp': datetime.now().isoformat()
        }))
        await self.redis.expire(key, 86400 * 7)  # 7å¤©è¿‡æœŸ
    
    async def get_stats(self, exp_id: str) -> Dict:
        """è·å–ç»Ÿè®¡ç»“æœ"""
        config = await self._get_config(exp_id)
        if not config:
            return {}
        
        results = {}
        for variant in config['variants']:
            key = f"exp_results:{exp_id}:{variant}"
            data = await self.redis.lrange(key, 0, -1)
            
            if data:
                metrics = [json.loads(d) for d in data]
                results[variant] = {
                    'count': len(metrics),
                    'avg_success': sum(m.get('success', 0) for m in metrics) / len(metrics),
                    'avg_latency': sum(m.get('latency', 0) for m in metrics) / len(metrics),
                    'avg_confidence': sum(m.get('confidence', 0) for m in metrics) / len(metrics)
                }
        
        return results
    
    async def _get_config(self, exp_id: str):
        data = await self.redis.get(exp_id)
        return json.loads(data) if data else None

# ä½¿ç”¨ç¤ºä¾‹
async def run_exploration_experiment():
    """è¿è¡Œæ¢ç´¢ç­–ç•¥A/Bæµ‹è¯•"""
    framework = ABTestFramework(redis)
    
    # åˆ›å»ºå®éªŒï¼šæ¯”è¾ƒä¸‰ç§æ¢ç´¢ç­–ç•¥
    exp_id = await framework.create_experiment(
        "exploration_comparison",
        variants=['epsilon_greedy', 'thompson', 'ucb'],
        traffic_split={'epsilon_greedy': 0.33, 'thompson': 0.33, 'ucb': 0.34}
    )
    
    # åœ¨RouterNodeä¸­ä½¿ç”¨
    user_id = "user-123"
    variant = await framework.assign_variant(user_id, exp_id)
    
    # æ‰§è¡Œå¹¶è®°å½•
    start = time.time()
    
    if variant == 'epsilon_greedy':
        router = ExplorationRouter(learner, epsilon=0.1, adaptive=True)
    elif variant == 'thompson':
        router = ThompsonSamplingRouter(learner)
    else:
        router = UCBRouter(learner)
    
    route = await router.select_route(source, targets)
    latency = time.time() - start
    
    # è®°å½•ç»“æœ
    await framework.record_outcome(exp_id, variant, {
        'success': route is not None,
        'latency': latency,
        'confidence': await learner.get_probability(source, route) if route else 0
    })
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°Îµ-è´ªå©ªç­–ç•¥
2. âœ… å®ç°Thompsoné‡‡æ ·
3. âœ… å®ç°UCBç®—æ³•
4. âœ… åˆ›å»ºæ··åˆç­–ç•¥è·¯ç”±å™¨
5. âœ… é›†æˆåˆ°RouterNode
6. âœ… æ·»åŠ A/Bæµ‹è¯•æ¡†æ¶
7. âœ… é…ç½®å®éªŒå’Œç›‘æ§

**é¢„æœŸæ•ˆæœ**: 
- é¿å…å±€éƒ¨æœ€ä¼˜
- å‘ç°æ›´å¥½è·¯å¾„
- è‡ªé€‚åº”æ¢ç´¢ç‡

---

#### 6. æ€§èƒ½ä¼˜åŒ–å±‚

**é—®é¢˜**: é‡å¤è®¡ç®—ï¼Œæ— ç¼“å­˜ï¼Œæ€§èƒ½ç“¶é¢ˆ

**å½“å‰å®ç°**:
```python
# backend/app/routing/graph_router.py
class GraphBasedRouter:
    def find_route(self, current_node: str, target_capability: str) -> Optional[str]:
        # æ¯æ¬¡éƒ½é‡æ–°è®¡ç®—æœ€çŸ­è·¯å¾„
        try:
            path = nx.shortest_path(self.graph, source=current_node, target=target_node, weight="weight")
            # ...
        except:
            return None
```

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/routing/route_cache.py
import json
from typing import Optional, Dict
from loguru import logger

class RouteCache:
    """
    å¤šçº§ç¼“å­˜ç³»ç»Ÿï¼šL1(å†…å­˜) + L2(Redis)
    """
    
    def __init__(self, redis_client, ttl: int = 300):
        self.redis = redis_client
        self.ttl = ttl
        self.local_cache: Dict[str, str] = {}  # L1: å†…å­˜ç¼“å­˜
        self.local_ttl: Dict[str, float] = {}  # L1è¿‡æœŸæ—¶é—´
    
    async def get_route(self, source: str, target: str) -> Optional[str]:
        """å¤šçº§ç¼“å­˜æŸ¥è¯¢"""
        cache_key = f"route:{source}->{target}"
        
        # L1: æœ¬åœ°å†…å­˜ç¼“å­˜ï¼ˆæœ€å¿«ï¼‰
        if cache_key in self.local_cache:
            if self._is_local_cache_valid(cache_key):
                logger.debug(f"L1 Cache HIT: {cache_key}")
                return self.local_cache[cache_key]
            else:
                # è¿‡æœŸï¼Œåˆ é™¤
                del self.local_cache[cache_key]
                del self.local_ttl[cache_key]
        
        # L2: Redisç¼“å­˜
        try:
            cached = await self.redis.get(cache_key)
            if cached:
                # å›å¡«L1
                self.local_cache[cache_key] = cached
                self.local_ttl[cache_key] = time.time() + 60  # L1ç¼“å­˜60ç§’
                logger.debug(f"L2 Cache HIT: {cache_key}")
                return cached
            else:
                logger.debug(f"Cache MISS: {cache_key}")
                return None
        except Exception as e:
            logger.error(f"Redis cache error: {e}")
            return None
    
    async def set_route(self, source: str, target: str, route: str, ttl: Optional[int] = None):
        """è®¾ç½®ç¼“å­˜"""
        cache_key = f"route:{source}->{target}"
        ttl = ttl or self.ttl
        
        # L1: å†…å­˜ç¼“å­˜
        self.local_cache[cache_key] = route
        self.local_ttl[cache_key] = time.time() + 60  # L1å›ºå®š60ç§’
        
        # L2: Redisç¼“å­˜
        try:
            await self.redis.setex(cache_key, ttl, route)
            logger.debug(f"Cache SET: {cache_key}, TTL: {ttl}s")
        except Exception as e:
            logger.error(f"Failed to set Redis cache: {e}")
    
    def invalidate(self, source: str, target: str):
        """å¤±æ•ˆç¼“å­˜"""
        cache_key = f"route:{source}->{target}"
        
        # å¤±æ•ˆL1
        self.local_cache.pop(cache_key, None)
        self.local_ttl.pop(cache_key, None)
        
        # å¼‚æ­¥å¤±æ•ˆL2
        asyncio.create_task(self._invalidate_redis(cache_key))
    
    async def _invalidate_redis(self, cache_key: str):
        """å¼‚æ­¥å¤±æ•ˆRedis"""
        try:
            await self.redis.delete(cache_key)
        except Exception as e:
            logger.error(f"Failed to invalidate Redis cache: {e}")
    
    def _is_local_cache_valid(self, cache_key: str) -> bool:
        """æ£€æŸ¥L1ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key not in self.local_ttl:
            return False
        return time.time() < self.local_ttl[cache_key]
    
    def clear_local(self):
        """æ¸…ç©ºæœ¬åœ°ç¼“å­˜"""
        self.local_cache.clear()
        self.local_ttl.clear()
        logger.info("Local cache cleared")
    
    async def get_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return {
            "local_size": len(self.local_cache),
            "local_hit_rate": getattr(self, '_local_hits', 0) / max(getattr(self, '_total_requests', 1), 1),
            "redis_hit_rate": getattr(self, '_redis_hits', 0) / max(getattr(self, '_total_requests', 1), 1)
        }

# é¢„è®¡ç®—è·¯ç”±å™¨
class PrecomputedRouter:
    """
    é¢„è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹å¯¹çš„æœ€ä¼˜è·¯å¾„
    """
    
    def __init__(self, graph_router, cache: RouteCache):
        self.graph = graph_router
        self.cache = cache
        self.precomputed = False
    
    async def find_route(self, source: str, target: str) -> Optional[str]:
        """å¸¦ç¼“å­˜çš„è·¯ç”±æŸ¥è¯¢"""
        # 1. æŸ¥ç¼“å­˜
        cached = await self.cache.get_route(source, target)
        if cached:
            return cached
        
        # 2. è®¡ç®—
        route = self._compute_route(source, target)
        
        # 3. å­˜ç¼“å­˜
        if route:
            await self.cache.set_route(source, target, route)
        
        return route
    
    def _compute_route(self, source: str, target: str) -> Optional[str]:
        """è®¡ç®—è·¯ç”±ï¼ˆä½¿ç”¨å›¾ç®—æ³•ï¼‰"""
        try:
            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
            if source not in self.graph.graph or target not in self.graph.graph:
                return None
            
            # è®¡ç®—æœ€çŸ­è·¯å¾„
            path = nx.shortest_path(
                self.graph.graph,
                source=source,
                target=target,
                weight="weight"
            )
            
            if len(path) > 1:
                return path[1]  # è¿”å›ä¸‹ä¸€è·³
            else:
                return None
                
        except nx.NetworkXNoPath:
            return None
        except Exception as e:
            logger.error(f"Route computation error: {e}")
            return None
    
    async def precompute_all(self):
        """é¢„è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹å¯¹"""
        nodes = list(self.graph.graph.nodes())
        total = len(nodes) * (len(nodes) - 1)
        
        logger.info(f"Precomputing {total} routes...")
        
        count = 0
        for source in nodes:
            for target in nodes:
                if source != target:
                    route = self._compute_route(source, target)
                    if route:
                        await self.cache.set_route(source, target, route, ttl=3600)  # 1å°æ—¶
                    count += 1
                    
                    if count % 100 == 0:
                        logger.info(f"Precomputed {count}/{total} routes")
        
        self.precomputed = True
        logger.info("Precomputation complete")
    
    async def update_route(self, source: str, target: str, new_route: str):
        """æ›´æ–°è·¯ç”±å¹¶å¤±æ•ˆç›¸å…³ç¼“å­˜"""
        # æ›´æ–°ç¼“å­˜
        await self.cache.set_route(source, target, new_route)
        
        # å¤±æ•ˆåå‘ç¼“å­˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self.cache.invalidate(target, source)
        
        # è®°å½•æ›´æ–°
        logger.info(f"Route updated: {source} -> {target} = {new_route}")

# ç¼“å­˜è£…é¥°å™¨
def cache_route(cache: RouteCache):
    """è·¯ç”±ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(self, source: str, target: str, *args, **kwargs):
            # å°è¯•ç¼“å­˜
            cached = await cache.get_route(source, target)
            if cached:
                cache._local_hits = getattr(cache, '_local_hits', 0) + 1
                return cached
            
            cache._total_requests = getattr(cache, '_total_requests', 0) + 1
            
            # æ‰§è¡Œè®¡ç®—
            result = await func(self, source, target, *args, **kwargs)
            
            # å­˜å…¥ç¼“å­˜
            if result:
                await cache.set_route(source, target, result)
            
            return result
        return wrapper
    return decorator

# é›†æˆåˆ°GraphRouter
# backend/app/routing/graph_router.py
class GraphBasedRouter:
    def __init__(self, redis_client=None):
        self.graph = nx.DiGraph()
        self._initialize_graph()
        
        # æ·»åŠ ç¼“å­˜
        if redis_client:
            self.cache = RouteCache(redis_client)
            self.precomputed_router = PrecomputedRouter(self, self.cache)
        else:
            self.cache = None
            self.precomputed_router = None
    
    async def find_route(self, current_node: str, target_capability: str) -> Optional[str]:
        """å¢å¼ºçš„è·¯ç”±æ–¹æ³•"""
        # æ˜ å°„ç›®æ ‡èŠ‚ç‚¹
        target_node = self._map_capability_to_node(target_capability)
        if not target_node:
            return None
        
        if current_node == target_node:
            return None
        
        # ä½¿ç”¨é¢„è®¡ç®—è·¯ç”±å™¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.precomputed_router:
            return await self.precomputed_router.find_route(current_node, target_node)
        
        # å›é€€åˆ°åŸå§‹æ–¹æ³•
        return self._original_find_route(current_node, target_node)
    
    def _original_find_route(self, current_node: str, target_node: str) -> Optional[str]:
        """åŸå§‹è·¯ç”±é€»è¾‘"""
        try:
            path = nx.shortest_path(self.graph, source=current_node, target=target_node, weight="weight")
            if len(path) > 1:
                return path[1]
        except nx.NetworkXNoPath:
            logger.warning(f"No path from {current_node} to {target_node}")
        return None
    
    async def update_weight(self, u: str, v: str, success: bool, latency: float):
        """æ›´æ–°æƒé‡å¹¶å¤±æ•ˆç¼“å­˜"""
        # åŸæœ‰æƒé‡æ›´æ–°é€»è¾‘
        if self.graph.has_edge(u, v):
            current_weight = self.graph[u][v]['weight']
            if success:
                new_weight = current_weight * 0.95
            else:
                new_weight = current_weight * 1.2
            
            self.graph[u][v]['weight'] = max(0.1, min(new_weight, 10.0))
            
            # å¤±æ•ˆç¼“å­˜
            if self.cache:
                self.cache.invalidate(u, v)
            
            logger.info(f"Updated weight {u}->{v}: {current_weight:.2f} -> {new_weight:.2f}")
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°å¤šçº§ç¼“å­˜ç³»ç»Ÿ
2. âœ… å®ç°é¢„è®¡ç®—è·¯ç”±å™¨
3. âœ… é›†æˆåˆ°GraphRouter
4. âœ… æ·»åŠ ç¼“å­˜è£…é¥°å™¨
5. âœ… å®ç°ç¼“å­˜å¤±æ•ˆç­–ç•¥
6. âœ… æ·»åŠ ç¼“å­˜ç»Ÿè®¡

**é¢„æœŸæ•ˆæœ**: 
- è·¯ç”±å»¶è¿Ÿé™ä½60-80%
- å‡å°‘é‡å¤è®¡ç®—
- æå‡ç³»ç»Ÿååé‡

---

### ğŸ¨ P2 - 2-4å‘¨å†…ï¼ˆé«˜çº§åŠŸèƒ½ï¼‰

#### 7. A/Bæµ‹è¯•æ¡†æ¶

**é—®é¢˜**: æ— æ³•ç§‘å­¦è¯„ä¼°æ”¹è¿›æ•ˆæœ

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/learning/ab_test_framework.py
from typing import List, Dict, Optional
from datetime import datetime
import json
import asyncio
from loguru import logger

class ABTestFramework:
    """
    A/Bæµ‹è¯•æ¡†æ¶ï¼šæ”¯æŒå¤šå˜é‡å®éªŒå’Œç»Ÿè®¡åˆ†æ
    """
    
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def create_experiment(
        self, 
        name: str, 
        variants: List[str], 
        traffic_split: Dict[str, float],
        metrics: List[str] = None
    ) -> str:
        """
        åˆ›å»ºA/Bæµ‹è¯•
        
        Args:
            name: å®éªŒåç§°
            variants: å˜ä½“åˆ—è¡¨
            traffic_split: æµé‡åˆ†é…ï¼Œå¦‚ {'control': 0.5, 'treatment': 0.5}
            metrics: è¦è¿½è¸ªçš„æŒ‡æ ‡ï¼Œå¦‚ ['success_rate', 'latency']
        
        Returns:
            å®éªŒID
        """
        exp_id = f"exp:{name}:{datetime.now().strftime('%Y%m%d')}"
        
        config = {
            'name': name,
            'variants': variants,
            'traffic_split': traffic_split,
            'metrics': metrics or ['success_rate', 'latency'],
            'start_time': datetime.now().isoformat(),
            'status': 'running',
            'min_sample_size': 100,  # æœ€å°æ ·æœ¬é‡
            'confidence_level': 0.95   # ç½®ä¿¡åº¦
        }
        
        await self.redis.set(exp_id, json.dumps(config))
        logger.info(f"Created experiment {exp_id}")
        return exp_id
    
    async def assign_variant(self, user_id: str, exp_id: str) -> str:
        """
        åˆ†é…ç”¨æˆ·åˆ°å®éªŒç»„ï¼ˆä¿è¯ä¸€è‡´æ€§ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            exp_id: å®éªŒID
        
        Returns:
            åˆ†é…çš„å˜ä½“
        """
        config = await self._get_config(exp_id)
        if not config:
            return 'control'
        
        # åŸºäºç”¨æˆ·IDå“ˆå¸Œï¼Œä¿è¯åŒä¸€ç”¨æˆ·å§‹ç»ˆåˆ†é…åˆ°åŒä¸€ç»„
        hash_val = hash(f"{user_id}:{exp_id}") % 10000
        total = 0
        
        for variant, weight in config['traffic_split'].items():
            total += weight * 100
            if hash_val < total:
                return variant
        
        return 'control'
    
    async def record_outcome(self, exp_id: str, variant: str, user_id: str, metrics: Dict):
        """
        è®°å½•å®éªŒç»“æœ
        
        Args:
            exp_id: å®éªŒID
            variant: å˜ä½“
            user_id: ç”¨æˆ·ID
            metrics: æŒ‡æ ‡æ•°æ®
        """
        config = await self._get_config(exp_id)
        if not config or config['status'] != 'running':
            return
        
        # è®°å½•å•æ¬¡å®éªŒç»“æœ
        result_key = f"exp_result:{exp_id}:{variant}:{user_id}"
        result_data = {
            **metrics,
            'timestamp': datetime.now().isoformat(),
            'variant': variant
        }
        
        # ä½¿ç”¨Redisåˆ—è¡¨ä¿å­˜å†å²
        await self.redis.lpush(result_key, json.dumps(result_data))
        await self.redis.expire(result_key, 86400 * 7)  # 7å¤©è¿‡æœŸ
        
        # æ›´æ–°èšåˆç»Ÿè®¡
        await self._update_aggregate_stats(exp_id, variant, metrics)
        
        logger.debug(f"Recorded outcome for {exp_id}:{variant}:{user_id}")
    
    async def get_stats(self, exp_id: str) -> Optional[Dict]:
        """
        è·å–å®éªŒç»Ÿè®¡ç»“æœ
        
        Returns:
            {
                'variant1': {
                    'count': 100,
                    'success_rate': 0.85,
                    'avg_latency': 0.5,
                    'confidence_interval': [0.80, 0.90]
                },
                ...
            }
        """
        config = await self._get_config(exp_id)
        if not config:
            return None
        
        results = {}
        
        for variant in config['variants']:
            # è·å–èšåˆæ•°æ®
            agg_key = f"exp_agg:{exp_id}:{variant}"
            data = await self.redis.hgetall(agg_key)
            
            if data:
                count = int(data.get('count', 0))
                if count == 0:
                    continue
                
                # è®¡ç®—ç»Ÿè®¡é‡
                success_count = int(data.get('success_count', 0))
                total_latency = float(data.get('total_latency', 0))
                total_confidence = float(data.get('total_confidence', 0))
                
                success_rate = success_count / count if count > 0 else 0
                avg_latency = total_latency / count if count > 0 else 0
                avg_confidence = total_confidence / count if count > 0 else 0
                
                # è®¡ç®—ç½®ä¿¡åŒºé—´ï¼ˆç®€åŒ–ç‰ˆï¼‰
                ci = self._calculate_confidence_interval(success_count, count, config['confidence_level'])
                
                results[variant] = {
                    'count': count,
                    'success_rate': success_rate,
                    'avg_latency': avg_latency,
                    'avg_confidence': avg_confidence,
                    'confidence_interval': ci,
                    'is_significant': self._check_significance(results, variant, config)
                }
        
        return results
    
    async def get_recommendation(self, exp_id: str) -> Optional[Dict]:
        """
        è·å–å®éªŒæ¨èï¼ˆåŸºäºç»Ÿè®¡æ˜¾è‘—æ€§ï¼‰
        
        Returns:
            æ¨èçš„å˜ä½“å’Œç†ç”±
        """
        stats = await self.get_stats(exp_id)
        if not stats or len(stats) < 2:
            return None
        
        config = await self._get_config(exp_id)
        
        # æ‰¾åˆ°æœ€ä½³å˜ä½“
        best_variant = None
        best_score = -1
        
        for variant, data in stats.items():
            if data['count'] >= config['min_sample_size']:
                # ç»¼åˆè¯„åˆ†ï¼šæˆåŠŸç‡ * æƒé‡ - å»¶è¿Ÿ * æƒé‡
                score = data['success_rate'] * 0.7 - data['avg_latency'] * 0.3
                if score > best_score:
                    best_score = score
                    best_variant = variant
        
        if not best_variant:
            return {
                'status': 'insufficient_data',
                'message': f"éœ€è¦è‡³å°‘ {config['min_sample_size']} ä¸ªæ ·æœ¬"
            }
        
        # æ£€æŸ¥æ˜¯å¦æ˜¾è‘—
        is_significant = stats[best_variant]['is_significant']
        
        return {
            'status': 'ready' if is_significant else 'collecting',
            'recommended_variant': best_variant,
            'confidence': stats[best_variant]['confidence_interval'],
            'message': self._generate_recommendation_message(stats, best_variant, is_significant)
        }
    
    async def _update_aggregate_stats(self, exp_id: str, variant: str, metrics: Dict):
        """æ›´æ–°èšåˆç»Ÿè®¡ï¼ˆåŸå­æ“ä½œï¼‰"""
        agg_key = f"exp_agg:{exp_id}:{variant}"
        
        # ä½¿ç”¨Luaè„šæœ¬ä¿è¯åŸå­æ€§
        lua_script = """
        local key = KEYS[1]
        local success = tonumber(ARGV[1])
        local latency = tonumber(ARGV[2])
        local confidence = tonumber(ARGV[3])
        
        redis.call('HINCRBY', key, 'count', 1)
        if success > 0 then
            redis.call('HINCRBY', key, 'success_count', 1)
        end
        redis.call('HINCRBYFLOAT', key, 'total_latency', latency)
        redis.call('HINCRBYFLOAT', key, 'total_confidence', confidence)
        
        return redis.call('HGETALL', key)
        """
        
        success = 1 if metrics.get('success', False) else 0
        latency = metrics.get('latency', 0)
        confidence = metrics.get('confidence', 0)
        
        await self.redis.eval(
            lua_script,
            1,
            agg_key,
            success,
            latency,
            confidence
        )
    
    def _calculate_confidence_interval(self, successes: int, total: int, confidence: float):
        """è®¡ç®—ç½®ä¿¡åŒºé—´ï¼ˆWaldåŒºé—´ï¼‰"""
        if total == 0:
            return [0, 0]
        
        p = successes / total
        z = 1.96 if confidence == 0.95 else 2.58  # 95% or 99%
        
        # æ ‡å‡†è¯¯å·®
        se = (p * (1 - p) / total) ** 0.5
        
        # ç½®ä¿¡åŒºé—´
        lower = max(0, p - z * se)
        upper = min(1, p + z * se)
        
        return [round(lower, 3), round(upper, 3)]
    
    def _check_significance(self, stats: Dict, variant: str, config: Dict) -> bool:
        """æ£€æŸ¥ç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆç®€åŒ–ç‰ˆå¡æ–¹æ£€éªŒï¼‰"""
        if len(stats) != 2:
            return False
        
        # è·å–å¯¹ç…§ç»„å’Œå®éªŒç»„
        variants = list(stats.keys())
        control = stats[variants[0]]
        treatment = stats[variants[1]]
        
        if treatment['count'] < config['min_sample_size']:
            return False
        
        # ç®€å•çš„æ˜¾è‘—æ€§æ£€æŸ¥ï¼šç½®ä¿¡åŒºé—´ä¸é‡å 
        control_ci = control['confidence_interval']
        treatment_ci = treatment['confidence_interval']
        
        return not (treatment_ci[0] > control_ci[1] or treatment_ci[1] < control_ci[0])
    
    def _generate_recommendation_message(self, stats: Dict, best_variant: str, is_significant: bool):
        """ç”Ÿæˆæ¨èæ¶ˆæ¯"""
        if is_significant:
            best = stats[best_variant]
            return (
                f"æ¨èä½¿ç”¨ '{best_variant}'ï¼ŒæˆåŠŸç‡ {best['success_rate']:.1%}ï¼Œ"
                f"ç½®ä¿¡åŒºé—´ [{best['confidence_interval'][0]}, {best['confidence_interval'][1]}]"
            )
        else:
            return f"ç»§ç»­æ”¶é›†æ•°æ®ä¸­ï¼Œå½“å‰ '{best_variant}' è¡¨ç°æœ€ä½³ä½†å°šæœªè¾¾åˆ°ç»Ÿè®¡æ˜¾è‘—æ€§"
    
    async def _get_config(self, exp_id: str):
        data = await self.redis.get(exp_id)
        return json.loads(data) if data else None
    
    async def stop_experiment(self, exp_id: str):
        """åœæ­¢å®éªŒ"""
        config = await self._get_config(exp_id)
        if config:
            config['status'] = 'stopped'
            config['end_time'] = datetime.now().isoformat()
            await self.redis.set(exp_id, json.dumps(config))
            logger.info(f"Stopped experiment {exp_id}")

# å®éªŒç®¡ç†å™¨
class ExperimentManager:
    """å®éªŒç®¡ç†å™¨ï¼Œç®€åŒ–ä½¿ç”¨"""
    
    def __init__(self, redis_client):
        self.framework = ABTestFramework(redis_client)
        self.active_experiments = {}
    
    async def register_experiment(self, name: str, variants: List[str], metrics: List[str] = None):
        """æ³¨å†Œå®éªŒ"""
        exp_id = await self.framework.create_experiment(name, variants, metrics=metrics)
        self.active_experiments[name] = exp_id
        return exp_id
    
    async def run_experiment(self, exp_name: str, user_id: str, func, *args, **kwargs):
        """
        è¿è¡Œå®éªŒ
        
        Args:
            exp_name: å®éªŒåç§°
            user_id: ç”¨æˆ·ID
            func: å®éªŒå‡½æ•°ï¼Œæ¥å—variantå‚æ•°
            *args, **kwargs: ä¼ é€’ç»™funcçš„å‚æ•°
        
        Returns:
            å‡½æ•°è¿”å›å€¼
        """
        if exp_name not in self.active_experiments:
            raise ValueError(f"Experiment {exp_name} not registered")
        
        exp_id = self.active_experiments[exp_name]
        
        # åˆ†é…å˜ä½“
        variant = await self.framework.assign_variant(user_id, exp_id)
        
        # æ‰§è¡Œå®éªŒ
        start_time = time.time()
        try:
            result = await func(variant, *args, **kwargs)
            success = True
        except Exception as e:
            result = None
            success = False
            logger.error(f"Experiment error: {e}")
        
        latency = time.time() - start_time
        
        # è®°å½•ç»“æœ
        metrics = {
            'success': success,
            'latency': latency,
            'confidence': 0.5  # å¯ä»¥ä»funcè¿”å›
        }
        
        await self.framework.record_outcome(exp_id, variant, user_id, metrics)
        
        return result

# ä½¿ç”¨ç¤ºä¾‹
async def demo_ab_test():
    """æ¼”ç¤ºA/Bæµ‹è¯•ä½¿ç”¨"""
    redis = await get_redis_client()
    manager = ExperimentManager(redis)
    
    # 1. æ³¨å†Œå®éªŒ
    await manager.register_experiment(
        "routing_strategy",
        variants=['graph', 'semantic', 'hybrid'],
        metrics=['success_rate', 'latency', 'user_satisfaction']
    )
    
    # 2. åœ¨ä¸šåŠ¡ä»£ç ä¸­ä½¿ç”¨
    async def execute_routing(variant: str, source: str, query: str):
        """å®éªŒå‡½æ•°ï¼šä¸åŒè·¯ç”±ç­–ç•¥"""
        if variant == 'graph':
            router = GraphBasedRouter()
        elif variant == 'semantic':
            router = SemanticRouter(embedding_service)
        else:
            router = HybridRouter(graph_router, semantic_router)
        
        return await router.find_route(source, query)
    
    # 3. æ‰§è¡Œå®éªŒ
    result = await manager.run_experiment(
        'routing_strategy',
        user_id='user-123',
        func=execute_routing,
        source='orchestrator',
        query='è®¡ç®—åœ†çš„é¢ç§¯'
    )
    
    # 4. æŸ¥çœ‹ç»“æœ
    stats = await manager.framework.get_stats(
        manager.active_experiments['routing_strategy']
    )
    
    recommendation = await manager.framework.get_recommendation(
        manager.active_experiments['routing_strategy']
    )
    
    print(f"å®éªŒç»“æœ: {stats}")
    print(f"æ¨è: {recommendation}")

# é›†æˆåˆ°RouterNode
# backend/app/routing/router_node.py
class RouterNode:
    def __init__(self, routes: List[str], redis_client=None, user_id: str = None):
        # ... åŸæœ‰åˆå§‹åŒ– ...
        
        # æ·»åŠ å®éªŒç®¡ç†å™¨
        if redis_client:
            from app.learning.ab_test_framework import ExperimentManager
            self.experiment_manager = ExperimentManager(redis_client)
            
            # æ³¨å†Œå®éªŒ
            asyncio.create_task(
                self.experiment_manager.register_experiment(
                    "router_comparison",
                    variants=['graph', 'semantic', 'hybrid']
                )
            )
    
    async def __call__(self, state: WorkflowState) -> WorkflowState:
        # ... åŸæœ‰é€»è¾‘ ...
        
        if hasattr(self, 'experiment_manager'):
            # ä½¿ç”¨å®éªŒæ¡†æ¶
            async def routing_func(variant: str, current: str, query: str, context: Dict):
                if variant == 'graph':
                    return await self.graph_router.find_route(current, query)
                elif variant == 'semantic':
                    return await self.semantic_router.route(query, context)
                else:
                    return await self.hybrid_router.find_route(current, query, context)
            
            next_route = await self.experiment_manager.run_experiment(
                'router_comparison',
                user_id=state.context_data.get('user_id', 'anonymous'),
                func=routing_func,
                current=current_node,
                query=last_msg,
                context=state.context_data
            )
        else:
            # å›é€€åˆ°åŸæœ‰é€»è¾‘
            next_route = await self.hybrid_router.find_route(current_node, last_msg, state.context_data)
        
        # ... åç»­é€»è¾‘ ...
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°ABTestFrameworkæ ¸å¿ƒ
2. âœ… å®ç°ç»Ÿè®¡åˆ†æå’Œæ˜¾è‘—æ€§æ£€éªŒ
3. âœ… åˆ›å»ºå®éªŒç®¡ç†å™¨
4. âœ… é›†æˆåˆ°RouterNode
5. âœ… æ·»åŠ æ¨èç³»ç»Ÿ
6. âœ… å¼€å‘å¯è§†åŒ–ä»ªè¡¨æ¿

**é¢„æœŸæ•ˆæœ**: 
- æ•°æ®é©±åŠ¨çš„ä¼˜åŒ–å†³ç­–
- ç§‘å­¦è¯„ä¼°æ”¹è¿›æ•ˆæœ
- è‡ªåŠ¨æ¨èæœ€ä½³æ–¹æ¡ˆ

---

#### 8. æ‰§è¡Œè¿½è¸ªä¸å›æ”¾

**é—®é¢˜**: è°ƒè¯•å›°éš¾ï¼Œæ— æ³•å¤ç°é—®é¢˜

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/visualization/execution_tracer.py
from typing import List, Dict, Optional
from datetime import datetime
import json
import asyncio
from loguru import logger

class ExecutionTracer:
    """
    æ‰§è¡Œè¿½è¸ªå™¨ï¼šè®°å½•å’Œå›æ”¾å®Œæ•´çš„æ‰§è¡Œè¿‡ç¨‹
    """
    
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def record_event(self, session_id: str, event: GraphEvent):
        """
        è®°å½•æ‰§è¡Œäº‹ä»¶
        
        Args:
            session_id: ä¼šè¯ID
            event: å›¾äº‹ä»¶
        """
        trace_key = f"trace:{session_id}:{event.timestamp}"
        
        # åºåˆ—åŒ–äº‹ä»¶
        event_data = {
            'type': event.type.value,
            'node': event.node_id,
            'details': event.details,
            'timestamp': event.timestamp,
            'state': self._serialize_state(event.state)
        }
        
        # å­˜å‚¨åˆ°Redisåˆ—è¡¨ï¼ˆä¿æŒé¡ºåºï¼‰
        await self.redis.lpush(trace_key, json.dumps(event_data))
        await self.redis.expire(trace_key, 86400)  # 24å°æ—¶è¿‡æœŸ
        
        # åŒæ—¶ç»´æŠ¤ä¸€ä¸ªç´¢å¼•åˆ—è¡¨ï¼Œæ–¹ä¾¿æŸ¥è¯¢
        index_key = f"trace_index:{session_id}"
        await self.redis.zadd(index_key, {trace_key: event.timestamp})
        await self.redis.expire(index_key, 86400)
    
    async def replay(self, session_id: str, start_time: float = None, end_time: float = None) -> List[Dict]:
        """
        å›æ”¾æ‰§è¡Œè¿‡ç¨‹
        
        Args:
            session_id: ä¼šè¯ID
            start_time: å¼€å§‹æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
            end_time: ç»“æŸæ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            äº‹ä»¶åˆ—è¡¨
        """
        index_key = f"trace_index:{session_id}"
        
        # è·å–æ‰€æœ‰trace keys
        if start_time or end_time:
            # èŒƒå›´æŸ¥è¯¢
            min_score = start_time or 0
            max_score = end_time or float('inf')
            trace_keys = await self.redis.zrangebyscore(index_key, min_score, max_score)
        else:
            # è·å–æ‰€æœ‰
            trace_keys = await self.redis.zrange(index_key, 0, -1)
        
        if not trace_keys:
            return []
        
        # è·å–äº‹ä»¶æ•°æ®
        events = []
        for trace_key in trace_keys:
            data = await self.redis.get(trace_key)
            if data:
                events.append(json.loads(data))
        
        # æŒ‰æ—¶é—´æ’åº
        events.sort(key=lambda x: x['timestamp'])
        
        return events
    
    async def replay_with_visualization(self, session_id: str) -> str:
        """
        ç”Ÿæˆå¯æ‰§è¡Œçš„å¯è§†åŒ–å›æ”¾
        
        Returns:
            Mermaidåºåˆ—å›¾ä»£ç 
        """
        events = await self.replay(session_id)
        
        if not events:
            return "No execution trace found"
        
        # ç”ŸæˆMermaidåºåˆ—å›¾
        lines = ["sequenceDiagram"]
        
        for event in events:
            node = event['node']
            event_type = event['type']
            timestamp = datetime.fromtimestamp(event['timestamp']).strftime('%H:%M:%S.%f')[:-3]
            
            # æ ¹æ®äº‹ä»¶ç±»å‹é€‰æ‹©ç®­å¤´æ ·å¼
            if event_type == 'NODE_START':
                lines.append(f"    Participant {node}")
                lines.append(f"    {node}->>System: Start ({timestamp})")
            elif event_type == 'NODE_END':
                lines.append(f"    System-->>{node}: End ({timestamp})")
            elif event_type == 'ERROR':
                lines.append(f"    System-->>{node}: Error ({timestamp})")
            elif event_type == 'EDGE_TRAVERSAL':
                lines.append(f"    Note over {node}: Transition ({timestamp})")
        
        return "\n".join(lines)
    
    async def get_execution_summary(self, session_id: str) -> Optional[Dict]:
        """
        è·å–æ‰§è¡Œæ‘˜è¦
        
        Returns:
            æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
        """
        events = await self.replay(session_id)
        
        if not events:
            return None
        
        # ç»Ÿè®¡
        node_count = {}
        error_count = 0
        total_latency = 0
        
        for i, event in enumerate(events):
            node = event['node']
            node_count[node] = node_count.get(node, 0) + 1
            
            if event['type'] == 'ERROR':
                error_count += 1
            
            # è®¡ç®—å»¶è¿Ÿ
            if i > 0:
                latency = event['timestamp'] - events[i-1]['timestamp']
                total_latency += latency
        
        return {
            'total_events': len(events),
            'nodes_visited': node_count,
            'error_count': error_count,
            'total_latency': total_latency,
            'avg_latency': total_latency / len(events) if events else 0,
            'execution_path': list(node_count.keys())
        }
    
    async def export_trace(self, session_id: str, format: str = 'json') -> str:
        """
        å¯¼å‡ºè¿½è¸ªæ•°æ®
        
        Args:
            format: 'json' æˆ– 'yaml'
        
        Returns:
            å¯¼å‡ºçš„å­—ç¬¦ä¸²
        """
        events = await self.replay(session_id)
        summary = await self.get_execution_summary(session_id)
        
        export_data = {
            'session_id': session_id,
            'export_time': datetime.now().isoformat(),
            'summary': summary,
            'events': events
        }
        
        if format == 'json':
            return json.dumps(export_data, indent=2, ensure_ascii=False)
        elif format == 'yaml':
            return self._to_yaml(export_data)
        else:
            raise ValueError(f"Unsupported format: {format}")
    
    async def import_trace(self, session_id: str, data: str, format: str = 'json'):
        """
        å¯¼å…¥è¿½è¸ªæ•°æ®ï¼ˆç”¨äºå¤ç°é—®é¢˜ï¼‰
        """
        if format == 'json':
            imported = json.loads(data)
        else:
            raise ValueError(f"Unsupported format: {format}")
        
        # æ¸…é™¤ç°æœ‰æ•°æ®
        await self.clear_trace(session_id)
        
        # é‡æ–°å¯¼å…¥
        for event in imported['events']:
            trace_key = f"trace:{session_id}:{event['timestamp']}"
            await self.redis.lpush(trace_key, json.dumps(event))
            await self.redis.expire(trace_key, 86400)
        
        index_key = f"trace_index:{session_id}"
        for event in imported['events']:
            await self.redis.zadd(index_key, {trace_key: event['timestamp']})
        
        logger.info(f"Imported {len(imported['events'])} events for session {session_id}")
    
    async def clear_trace(self, session_id: str):
        """æ¸…é™¤è¿½è¸ªæ•°æ®"""
        index_key = f"trace_index:{session_id}"
        trace_keys = await self.redis.zrange(index_key, 0, -1)
        
        if trace_keys:
            await self.redis.delete(*trace_keys)
            await self.redis.delete(index_key)
        
        logger.info(f"Cleared trace for session {session_id}")
    
    def _serialize_state(self, state) -> Dict:
        """åºåˆ—åŒ–çŠ¶æ€"""
        return {
            'messages': len(state.messages),
            'context_keys': list(state.context_data.keys()),
            'errors': state.errors,
            'next_step': state.next_step,
            'trace_id': state.trace_id
        }
    
    def _to_yaml(self, data: Dict) -> str:
        """è½¬æ¢ä¸ºYAMLï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        import yaml
        return yaml.dump(data, default_flow_style=False, allow_unicode=True)

# è°ƒè¯•æ§åˆ¶å°
class DebugConsole:
    """
    è°ƒè¯•æ§åˆ¶å°ï¼šæä¾›äº¤äº’å¼è°ƒè¯•åŠŸèƒ½
    """
    
    def __init__(self, tracer: ExecutionTracer, visualizer):
        self.tracer = tracer
        self.visualizer = visualizer
    
    async def get_debug_dashboard(self, session_id: str) -> Dict:
        """
        è·å–å®Œæ•´çš„è°ƒè¯•é¢æ¿æ•°æ®
        
        Returns:
            åŒ…å«æ‰€æœ‰è°ƒè¯•ä¿¡æ¯çš„å­—å…¸
        """
        # æ‰§è¡Œè¿½è¸ª
        events = await self.tracer.replay(session_id)
        summary = await self.tracer.get_execution_summary(session_id)
        
        # ç”Ÿæˆå¯è§†åŒ–
        mermaid = await self.tracer.replay_with_visualization(session_id)
        
        # çŠ¶æ€æ£€æŸ¥
        state_inspection = await self._inspect_current_state(session_id)
        
        # æ€§èƒ½æŒ‡æ ‡
        performance = await self._get_performance_metrics(session_id)
        
        # ç”Ÿæˆå»ºè®®
        recommendations = await self._generate_recommendations(session_id, events, summary)
        
        return {
            'session_id': session_id,
            'execution_trace': events,
            'summary': summary,
            'visualization': mermaid,
            'state_inspection': state_inspection,
            'performance': performance,
            'recommendations': recommendations,
            'export_commands': self._get_export_commands(session_id)
        }
    
    async def _inspect_current_state(self, session_id: str) -> Dict:
        """æ£€æŸ¥å½“å‰çŠ¶æ€"""
        # ä»checkpointeråŠ è½½
        from app.checkpoint.redis_checkpointer import RedisCheckpointer
        from app.services.redis_service import get_redis_client
        
        redis = await get_redis_client()
        checkpointer = RedisCheckpointer(redis)
        
        state = await checkpointer.load(session_id)
        
        if not state:
            return {'error': 'No state found'}
        
        return {
            'messages_count': len(state.messages),
            'last_message': state.messages[-1] if state.messages else None,
            'context_keys': list(state.context_data.keys()),
            'errors': state.errors,
            'next_step': state.next_step,
            'trace_id': state.trace_id
        }
    
    async def _get_performance_metrics(self, session_id: str) -> Dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        events = await self.tracer.replay(session_id)
        
        if not events:
            return {}
        
        # è®¡ç®—å„é˜¶æ®µè€—æ—¶
        stage_times = {}
        current_stage = None
        stage_start = None
        
        for event in events:
            if event['type'] == 'NODE_START':
                current_stage = event['node']
                stage_start = event['timestamp']
            elif event['type'] == 'NODE_END' and current_stage:
                latency = event['timestamp'] - stage_start
                stage_times[current_stage] = latency
                current_stage = None
        
        return {
            'total_latency': events[-1]['timestamp'] - events[0]['timestamp'],
            'stage_times': stage_times,
            'event_count': len(events),
            'bottlenecks': sorted(stage_times.items(), key=lambda x: x[1], reverse=True)[:3]
        }
    
    async def _generate_recommendations(self, session_id: str, events: List[Dict], summary: Dict) -> List[Dict]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if not events or not summary:
            return recommendations
        
        # 1. æ€§èƒ½ç“¶é¢ˆæ£€æµ‹
        if summary['total_latency'] > 5.0:
            recommendations.append({
                'type': 'performance',
                'priority': 'high',
                'message': f"æ‰§è¡Œæ—¶é—´è¿‡é•¿ ({summary['total_latency']:.2f}s)",
                'suggestion': 'è€ƒè™‘æ·»åŠ ç¼“å­˜æˆ–ä¼˜åŒ–LLMè°ƒç”¨'
            })
        
        # 2. é”™è¯¯æ£€æµ‹
        if summary['error_count'] > 0:
            recommendations.append({
                'type': 'reliability',
                'priority': 'high',
                'message': f"æ£€æµ‹åˆ° {summary['error_count']} ä¸ªé”™è¯¯",
                'suggestion': 'æŸ¥çœ‹é”™è¯¯è¯¦æƒ…ï¼Œè€ƒè™‘æ·»åŠ é”™è¯¯å¤„ç†'
            })
        
        # 3. è·¯ç”±æ•ˆç‡æ£€æµ‹
        nodes_visited = summary.get('nodes_visited', {})
        if len(nodes_visited) > 5:
            recommendations.append({
                'type': 'efficiency',
                'priority': 'medium',
                'message': f"è®¿é—®äº† {len(nodes_visited)} ä¸ªèŠ‚ç‚¹",
                'suggestion': 'è€ƒè™‘ç®€åŒ–å·¥ä½œæµæˆ–ä¼˜åŒ–è·¯ç”±ç­–ç•¥'
            })
        
        # 4. æ¢ç´¢ä¸è¶³æ£€æµ‹
        if len(events) < 3:
            recommendations.append({
                'type': 'exploration',
                'priority': 'low',
                'message': 'æ‰§è¡Œè·¯å¾„è¾ƒçŸ­',
                'suggestion': 'å¯èƒ½éœ€è¦æ›´å¤šæ¢ç´¢æ¥æ‰¾åˆ°æœ€ä¼˜è·¯å¾„'
            })
        
        return recommendations
    
    def _get_export_commands(self, session_id: str) -> Dict:
        """è·å–å¯¼å‡ºå‘½ä»¤"""
        return {
            'export_json': f"curl http://localhost:8000/api/trace/{session_id}/export?format=json",
            'export_yaml': f"curl http://localhost:8000/api/trace/{session_id}/export?format=yaml",
            'import': f"curl -X POST http://localhost:8000/api/trace/{session_id}/import -d @trace.json",
            'visualize': f"open http://localhost:8000/visualize/{session_id}"
        }

# é›†æˆåˆ°Orchestrator
# backend/app/orchestration/orchestrator.py
class ChatOrchestrator:
    def __init__(self, db_session=None, redis_client=None):
        # ... åŸæœ‰åˆå§‹åŒ– ...
        
        # æ·»åŠ è¿½è¸ªå™¨
        if redis_client:
            from app.visualization.execution_tracer import ExecutionTracer, DebugConsole
            from app.visualization.realtime_visualizer import RealtimeVisualizer
            
            self.tracer = ExecutionTracer(redis_client)
            self.debug_console = DebugConsole(
                self.tracer,
                self.ws_manager.get_visualizer()
            )
            
            # æ³¨å†Œè¿½è¸ªå™¨åˆ°graph
            self.graph.on_event = self._chain_event_handlers(
                self.ws_manager.get_visualizer().on_graph_event,
                self.tracer.record_event
            )
    
    def _chain_event_handlers(self, *handlers):
        """é“¾å¼äº‹ä»¶å¤„ç†å™¨"""
        async def chained(event):
            for handler in handlers:
                await handler(event)
        return chained
    
    async def process_stream(self, request, db_session, context_data):
        """å¤„ç†æµç¨‹ï¼ˆè‡ªåŠ¨è¿½è¸ªï¼‰"""
        # ... åŸæœ‰é€»è¾‘ ...
        
        # ç¡®ä¿äº‹ä»¶å¤„ç†å™¨å·²è®¾ç½®
        self.graph.on_event = self._chain_event_handlers(
            self.ws_manager.get_visualizer().on_graph_event,
            self.tracer.record_event
        )
        
        # ... æ‰§è¡Œgraph ...
        
        # åœ¨finallyå—ä¸­è®°å½•æœ€ç»ˆçŠ¶æ€
        try:
            # ... æ‰§è¡Œ ...
        finally:
            # è®°å½•æ‰§è¡Œæ‘˜è¦
            summary = await self.tracer.get_execution_summary(request.session_id)
            logger.info(f"Execution summary: {summary}")

# APIç«¯ç‚¹
from fastapi import APIRouter, HTTPException

trace_router = APIRouter(prefix="/api/trace")

@trace_router.get("/{session_id}")
async def get_trace(session_id: str):
    """è·å–è¿½è¸ªæ•°æ®"""
    tracer = get_tracer()
    events = await tracer.replay(session_id)
    return {"events": events}

@trace_router.get("/{session_id}/export")
async def export_trace(session_id: str, format: str = "json"):
    """å¯¼å‡ºè¿½è¸ª"""
    tracer = get_tracer()
    try:
        data = await tracer.export_trace(session_id, format)
        return {"data": data}
    except Exception as e:
        raise HTTPException(status_code=404, detail=str(e))

@trace_router.post("/{session_id}/import")
async def import_trace(session_id: str, data: Dict):
    """å¯¼å…¥è¿½è¸ª"""
    tracer = get_tracer()
    await tracer.import_trace(session_id, json.dumps(data))
    return {"status": "success"}

@trace_router.get("/{session_id}/debug")
async def get_debug_dashboard(session_id: str):
    """è·å–è°ƒè¯•é¢æ¿"""
    debug_console = get_debug_console()
    dashboard = await debug_console.get_debug_dashboard(session_id)
    return dashboard

@trace_router.delete("/{session_id}")
async def clear_trace(session_id: str):
    """æ¸…é™¤è¿½è¸ª"""
    tracer = get_tracer()
    await tracer.clear_trace(session_id)
    return {"status": "cleared"}

@trace_router.get("/{session_id}/visualize")
async def visualize_trace(session_id: str):
    """ç”Ÿæˆå¯è§†åŒ–"""
    tracer = get_tracer()
    mermaid = await tracer.replay_with_visualization(session_id)
    return {"mermaid": mermaid}
```

**å‰ç«¯è°ƒè¯•ç•Œé¢**:
```javascript
// frontend/debug_console.js
class DebugConsole {
    constructor(sessionId) {
        this.sessionId = sessionId;
        this.apiBase = '/api/trace';
    }
    
    async loadDashboard() {
        const response = await fetch(`${this.apiBase}/${this.sessionId}/debug`);
        const data = await response.json();
        
        this.renderExecutionTrace(data.execution_trace);
        this.renderSummary(data.summary);
        this.renderVisualization(data.visualization);
        this.renderRecommendations(data.recommendations);
        this.renderExportCommands(data.export_commands);
    }
    
    renderExecutionTrace(events) {
        const container = document.getElementById('trace-container');
        container.innerHTML = events.map(event => `
            <div class="trace-event event-${event.type.toLowerCase()}">
                <span class="timestamp">${new Date(event.timestamp * 1000).toLocaleTimeString()}</span>
                <span class="type">${event.type}</span>
                <span class="node">${event.node}</span>
                ${event.details ? `<span class="details">${event.details}</span>` : ''}
            </div>
        `).join('');
    }
    
    renderVisualization(mermaidCode) {
        mermaid.render('trace-graph', mermaidCode, (svg) => {
            document.getElementById('visualization-container').innerHTML = svg;
        });
    }
    
    renderRecommendations(recommendations) {
        const container = document.getElementById('recommendations-container');
        container.innerHTML = recommendations.map(rec => `
            <div class="recommendation priority-${rec.priority}">
                <h4>${rec.type} (${rec.priority})</h4>
                <p>${rec.message}</p>
                <div class="suggestion">${rec.suggestion}</div>
            </div>
        `).join('');
    }
    
    async exportData(format) {
        const response = await fetch(`${this.apiBase}/${this.sessionId}/export?format=${format}`);
        const data = await response.json();
        
        // ä¸‹è½½æ–‡ä»¶
        const blob = new Blob([data.data], { type: 'text/plain' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `trace_${this.sessionId}.${format}`;
        a.click();
    }
    
    async importData(file) {
        const text = await file.text();
        const data = JSON.parse(text);
        
        await fetch(`${this.apiBase}/${this.sessionId}/import`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(data)
        });
        
        this.loadDashboard();
    }
}
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°ExecutionTracer
2. âœ… å®ç°DebugConsole
3. âœ… é›†æˆåˆ°Orchestrator
4. âœ… åˆ›å»ºAPIç«¯ç‚¹
5. âœ… å¼€å‘å‰ç«¯è°ƒè¯•ç•Œé¢
6. âœ… æ·»åŠ å¯¼å‡º/å¯¼å…¥åŠŸèƒ½

**é¢„æœŸæ•ˆæœ**: 
- é—®é¢˜å®šä½æ•ˆç‡æå‡70%
- æ”¯æŒé—®é¢˜å¤ç°
- äº¤äº’å¼è°ƒè¯•

---

#### 9. å¤šç»´åº¦å­¦ä¹ ç³»ç»Ÿ

**é—®é¢˜**: ä»…å­¦ä¹ æˆåŠŸç‡ï¼Œå¿½ç•¥å»¶è¿Ÿã€æˆæœ¬ã€ç”¨æˆ·æ»¡æ„åº¦

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/learning/multi_dimensional_learner.py
from typing import Dict, List
from dataclasses import dataclass
from loguru import logger

@dataclass
class DimensionWeights:
    """ç»´åº¦æƒé‡é…ç½®"""
    success: float = 0.4
    latency: float = 0.3
    cost: float = 0.1
    user_satisfaction: float = 0.2
    
    def validate(self):
        """éªŒè¯æƒé‡æ€»å’Œä¸º1"""
        total = sum([self.success, self.latency, self.cost, self.user_satisfaction])
        if abs(total - 1.0) > 0.01:
            raise ValueError(f"Weights must sum to 1.0, got {total}")

class MultiDimensionalLearner:
    """
    å¤šç»´åº¦è´å¶æ–¯å­¦ä¹ å™¨
    
    ç»´åº¦:
    - success: æˆåŠŸç‡ (Betaåˆ†å¸ƒ)
    - latency: å»¶è¿Ÿ (Betaåˆ†å¸ƒï¼Œä½å»¶è¿Ÿä¸ºæˆåŠŸ)
    - cost: æˆæœ¬ (Betaåˆ†å¸ƒï¼Œä½æˆæœ¬ä¸ºæˆåŠŸ)
    - user_satisfaction: ç”¨æˆ·æ»¡æ„åº¦ (Betaåˆ†å¸ƒ)
    """
    
    def __init__(self, redis_client, user_id: str, weights: DimensionWeights = None):
        self.redis = redis_client
        self.user_id = user_id
        self.weights = weights or DimensionWeights()
        self.weights.validate()
        
        # æ¯ä¸ªç»´åº¦ä¸€ä¸ªå­¦ä¹ å™¨
        self.dimensions = {
            'success': BayesianLearner(),
            'latency': BayesianLearner(),
            'cost': BayesianLearner(),
            'user_satisfaction': BayesianLearner()
        }
    
    async def update(self, source: str, target: str, metrics: Dict):
        """
        å¤šç»´åº¦æ›´æ–°
        
        Args:
            source: æºèŠ‚ç‚¹
            target: ç›®æ ‡èŠ‚ç‚¹
            metrics: æŒ‡æ ‡å­—å…¸
                {
                    'success': True/False,
                    'latency': 0.5,  # ç§’
                    'cost': 0.01,    # ç¾å…ƒ
                    'user_satisfaction': 4.5  # 1-5åˆ†
                }
        """
        # æ ‡å‡†åŒ–ä¸ºæˆåŠŸ/å¤±è´¥
        normalized = self._normalize_metrics(metrics)
        
        # æ›´æ–°å„ç»´åº¦
        for dim, value in normalized.items():
            if dim in self.dimensions:
                self.dimensions[dim].update(source, target, value)
        
        # å¼‚æ­¥æŒä¹…åŒ–
        asyncio.create_task(self._save())
        
        logger.debug(f"Multi-dimension update: {source}->{target}, metrics={metrics}")
    
    async def get_combined_score(self, source: str, target: str, user_pref: Dict = None) -> float:
        """
        è·å–ç»¼åˆè¯„åˆ†
        
        Args:
            user_pref: ç”¨æˆ·åå¥½ï¼Œå¯è¦†ç›–é»˜è®¤æƒé‡
        
        Returns:
            0-1ä¹‹é—´çš„ç»¼åˆè¯„åˆ†
        """
        weights = user_pref.get('weights', self.weights.__dict__) if user_pref else self.weights.__dict__
        
        score = 0
        for dim, learner in self.dimensions.items():
            prob = learner.get_probability(source, target)
            weight = weights.get(dim, 0.25)
            score += prob * weight
        
        return score
    
    async def get_dimension_breakdown(self, source: str, target: str) -> Dict:
        """è·å–å„ç»´åº¦è¯¦ç»†ä¿¡æ¯"""
        breakdown = {}
        for dim, learner in self.dimensions.items():
            stats = learner.stats.get(f"{source}->{target}")
            if stats:
                breakdown[dim] = {
                    'probability': stats.mean,
                    'alpha': stats.alpha,
                    'beta': stats.beta,
                    'attempts': stats.alpha + stats.beta - 2
                }
            else:
                breakdown[dim] = {
                    'probability': 0.5,
                    'alpha': 1,
                    'beta': 1,
                    'attempts': 0
                }
        
        return breakdown
    
    def _normalize_metrics(self, metrics: Dict) -> Dict[str, bool]:
        """å°†æŒ‡æ ‡è½¬æ¢ä¸ºæˆåŠŸ/å¤±è´¥"""
        normalized = {}
        
        # æˆåŠŸç‡ï¼šç›´æ¥ä½¿ç”¨
        if 'success' in metrics:
            normalized['success'] = bool(metrics['success'])
        
        # å»¶è¿Ÿï¼šä½äºé˜ˆå€¼ä¸ºæˆåŠŸ
        if 'latency' in metrics:
            latency = metrics['latency']
            normalized['latency'] = latency < 1.0  # 1ç§’é˜ˆå€¼
        
        # æˆæœ¬ï¼šä½äºé˜ˆå€¼ä¸ºæˆåŠŸ
        if 'cost' in metrics:
            cost = metrics['cost']
            normalized['cost'] = cost < 0.05  # 5ç¾åˆ†é˜ˆå€¼
        
        # ç”¨æˆ·æ»¡æ„åº¦ï¼šé«˜äºé˜ˆå€¼ä¸ºæˆåŠŸ
        if 'user_satisfaction' in metrics:
            satisfaction = metrics['user_satisfaction']
            normalized['user_satisfaction'] = satisfaction >= 3.5  # 3.5/5é˜ˆå€¼
        
        return normalized
    
    async def _save(self):
        """æŒä¹…åŒ–åˆ°Redis"""
        try:
            data = {
                dim: {
                    'stats': {
                        key: {'alpha': stats.alpha, 'beta': stats.beta}
                        for key, stats in learner.stats.items()
                    },
                    'weights': self.weights.__dict__
                }
                for dim, learner in self.dimensions.items()
            }
            
            await self.redis.setex(
                f"multi_learner:{self.user_id}",
                86400 * 7,
                json.dumps(data)
            )
        except Exception as e:
            logger.error(f"Failed to save multi-dimensional learner: {e}")
    
    async def _load(self):
        """ä»RedisåŠ è½½"""
        try:
            data = await self.redis.get(f"multi_learner:{self.user_id}")
            if not data:
                return
            
            loaded = json.loads(data)
            
            for dim, dim_data in loaded.items():
                if dim in self.dimensions:
                    # æ¢å¤å­¦ä¹ å™¨çŠ¶æ€
                    for key, stats_data in dim_data['stats'].items():
                        self.dimensions[dim].stats[key] = RouteStats(
                            alpha=stats_data['alpha'],
                            beta=stats_data['beta']
                        )
            
            # æ¢å¤æƒé‡
            if 'weights' in loaded.get('success', {}):
                self.weights = DimensionWeights(**loaded['success']['weights'])
            
        except Exception as e:
            logger.error(f"Failed to load multi-dimensional learner: {e}")

# æ™ºèƒ½è·¯ç”±å™¨ï¼ˆä½¿ç”¨å¤šç»´åº¦è¯„åˆ†ï¼‰
class SmartRouter:
    """
    åŸºäºå¤šç»´åº¦è¯„åˆ†çš„æ™ºèƒ½è·¯ç”±
    """
    
    def __init__(self, learner: MultiDimensionalLearner, graph_router):
        self.learner = learner
        self.graph = graph_router
    
    async def find_route(self, source: str, query: str, context: Dict) -> Optional[str]:
        """
        å¤šç»´åº¦è·¯ç”±å†³ç­–
        
        1. ä»å›¾ä¸­è·å–å€™é€‰è·¯ç”±
        2. ä¸ºæ¯ä¸ªå€™é€‰è®¡ç®—å¤šç»´åº¦è¯„åˆ†
        3. é€‰æ‹©æœ€ä¼˜è·¯ç”±
        """
        # 1. è·å–å€™é€‰ï¼ˆåŸºäºèƒ½åŠ›æ˜ å°„ï¼‰
        capability = self._extract_capability(query)
        target_node = self.graph._map_capability_to_node(capability)
        
        if not target_node or target_node == source:
            return None
        
        # 2. è·å–ç”¨æˆ·åå¥½
        user_pref = context.get('user_preferences', {})
        
        # 3. è®¡ç®—ç»¼åˆè¯„åˆ†
        score = await self.learner.get_combined_score(source, target_node, user_pref)
        
        # 4. é˜ˆå€¼æ£€æŸ¥
        if score < 0.3:
            logger.warning(f"Low combined score: {score:.2f}")
            return None
        
        # 5. è·å–è¯¦ç»†åˆ†è§£ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        breakdown = await self.learner.get_dimension_breakdown(source, target_node)
        logger.info(f"Routing decision: {source}->{target_node}, score={score:.2f}, breakdown={breakdown}")
        
        return target_node
    
    def _extract_capability(self, query: str) -> str:
        """æå–èƒ½åŠ›ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['math', 'è®¡ç®—', 'å…¬å¼']):
            return 'math'
        if any(word in query_lower for word in ['code', 'ç¼–ç¨‹', 'python']):
            return 'code'
        if any(word in query_lower for word in ['search', 'æŸ¥è¯¢', 'çŸ¥è¯†']):
            return 'knowledge'
        
        return 'orchestrator'

# é›†æˆåˆ°RouterNode
# backend/app/routing/router_node.py
class RouterNode:
    def __init__(self, routes: List[str], redis_client=None, user_id: str = None):
        # ... åŸæœ‰åˆå§‹åŒ– ...
        
        # æ·»åŠ å¤šç»´åº¦å­¦ä¹ å™¨
        if redis_client and user_id:
            from app.learning.multi_dimensional_learner import MultiDimensionalLearner, SmartRouter
            
            self.multi_learner = MultiDimensionalLearner(redis_client, user_id)
            self.smart_router = SmartRouter(self.multi_learner, self.graph_router)
            
            # åŠ è½½å†å²æ•°æ®
            asyncio.create_task(self.multi_learner._load())
    
    async def __call__(self, state: WorkflowState) -> WorkflowState:
        # ... åŸæœ‰é€»è¾‘ ...
        
        # ä½¿ç”¨å¤šç»´åº¦è·¯ç”±å™¨
        if hasattr(self, 'smart_router'):
            next_route = await self.smart_router.find_route(
                source=current_node,
                query=last_msg,
                context=state.context_data
            )
        else:
            # å›é€€
            next_route = await self.hybrid_router.find_route(current_node, last_msg, state.context_data)
        
        # ... åç»­é€»è¾‘ ...
        
        # åœ¨æ‰§è¡Œåæ›´æ–°å­¦ä¹ å™¨
        async def update_learning(result):
            # æ”¶é›†æ‰§è¡ŒæŒ‡æ ‡
            metrics = {
                'success': result.success if hasattr(result, 'success') else True,
                'latency': result.latency if hasattr(result, 'latency') else 0,
                'cost': result.cost if hasattr(result, 'cost') else 0,
                'user_satisfaction': result.satisfaction if hasattr(result, 'satisfaction') else 3.0
            }
            
            if hasattr(self, 'multi_learner'):
                await self.multi_learner.update(current_node, next_route, metrics)
        
        # æ³¨å†Œå›è°ƒ
        state.context_data['learning_callback'] = update_learning
        
        return state
```

**ç”¨æˆ·åå¥½é…ç½®**:
```python
# backend/app/schemas/user_preferences.py
from pydantic import BaseModel, Field
from typing import Dict, Optional

class UserRoutingPreferences(BaseModel):
    """ç”¨æˆ·è·¯ç”±åå¥½"""
    
    # ç»´åº¦æƒé‡
    weight_success: float = Field(0.4, ge=0, le=1)
    weight_latency: float = Field(0.3, ge=0, le=1)
    weight_cost: float = Field(0.1, ge=0, le=1)
    weight_satisfaction: float = Field(0.2, ge=0, le=1)
    
    # é˜ˆå€¼é…ç½®
    max_latency: float = Field(2.0, description="æœ€å¤§å¯æ¥å—å»¶è¿Ÿï¼ˆç§’ï¼‰")
    max_cost: float = Field(0.1, description="æœ€å¤§å¯æ¥å—æˆæœ¬ï¼ˆç¾å…ƒï¼‰")
    min_satisfaction: float = Field(3.5, description="æœ€ä½æ»¡æ„åº¦ï¼ˆ1-5ï¼‰")
    
    # æ¢ç´¢åå¥½
    exploration_level: str = Field("medium", enum=["low", "medium", "high"])
    
    def to_weights(self):
        """è½¬æ¢ä¸ºæƒé‡å¯¹è±¡"""
        from app.learning.multi_dimensional_learner import DimensionWeights
        return DimensionWeights(
            success=self.weight_success,
            latency=self.weight_latency,
            cost=self.weight_cost,
            user_satisfaction=self.weight_satisfaction
        )

# ç”¨æˆ·æœåŠ¡ä¸­è·å–åå¥½
class UserService:
    async def get_routing_preferences(self, user_id: str) -> UserRoutingPreferences:
        """è·å–ç”¨æˆ·è·¯ç”±åå¥½"""
        # ä»æ•°æ®åº“æˆ–Redisè·å–
        # å¦‚æœæ²¡æœ‰ï¼Œè¿”å›é»˜è®¤å€¼
        return UserRoutingPreferences()
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°å¤šç»´åº¦å­¦ä¹ å™¨
2. âœ… å®ç°æ™ºèƒ½è·¯ç”±å™¨
3. âœ… é›†æˆåˆ°RouterNode
4. âœ… æ·»åŠ ç”¨æˆ·åå¥½é…ç½®
5. âœ… å®ç°æŒä¹…åŒ–
6. âœ… æ·»åŠ ç»´åº¦å¯è§†åŒ–

**é¢„æœŸæ•ˆæœ**: 
- è·¯ç”±å†³ç­–æ›´å…¨é¢
- è€ƒè™‘å¤šæ–¹é¢å› ç´ 
- ä¸ªæ€§åŒ–è·¯ç”±ç­–ç•¥

---

### ğŸ”¬ P3 - æœªæ¥æ‰©å±•

#### 10. æœåŠ¡åŒ–æ¶æ„

**é—®é¢˜**: ç»„ä»¶è€¦åˆï¼Œéš¾ä»¥ç‹¬ç«‹æ‰©å±•

**æ”¹è¿›æ–¹æ¡ˆ**:
```yaml
# docker-compose.services.yml
version: '3.8'

services:
  # è·¯ç”±æœåŠ¡
  routing-service:
    build: ./services/routing
    environment:
      - REDIS_URL=redis://redis:6379/0
      - POSTGRES_URL=postgresql://user:pass@postgres:5432/sparkle
      - GRAPH_FILE=/data/graph.json
      - LOG_LEVEL=INFO
    ports:
      - "8001:8000"
    depends_on:
      - redis
      - postgres
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 512M
  
  # å¯è§†åŒ–æœåŠ¡
  visualization-service:
    build: ./services/visualization
    environment:
      - REDIS_URL=redis://redis:6379/1
      - WS_PORT=8002
      - LOG_LEVEL=INFO
    ports:
      - "8002:8002"
    depends_on:
      - redis
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
  
  # å­¦ä¹ æœåŠ¡
  learning-service:
    build: ./services/learning
    environment:
      - REDIS_URL=redis://redis:6379/2
      - POSTGRES_URL=postgresql://user:pass@postgres:5432/sparkle
      - LOG_LEVEL=INFO
    ports:
      - "8003:8000"
    depends_on:
      - redis
      - postgres
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
  
  # APIç½‘å…³
  api-gateway:
    build: ./services/gateway
    environment:
      - ROUTING_SERVICE_URL=http://routing-service:8000
      - VISUALIZATION_SERVICE_URL=http://visualization-service:8002
      - LEARNING_SERVICE_URL=http://learning-service:8003
    ports:
      - "8000:8000"
    depends_on:
      - routing-service
      - visualization-service
      - learning-service
  
  # åŸºç¡€è®¾æ–½
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
  
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: sparkle
      POSTGRES_PASSWORD: devpassword
      POSTGRES_DB: sparkle
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  redis_data:
  postgres_data:
```

**è·¯ç”±æœåŠ¡API**:
```python
# services/routing/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, Dict, List
import asyncio

app = FastAPI(title="Routing Service")

# å…¨å±€ä¾èµ–
router = None
learner = None

@app.on_event("startup")
async def startup():
    """æœåŠ¡å¯åŠ¨"""
    global router, learner
    redis = await get_redis_client()
    router = GraphBasedRouter(redis)
    learner = await create_learner(redis, "system")
    
    # é¢„è®¡ç®—
    if hasattr(router, 'precomputed_router'):
        await router.precomputed_router.precompute_all()

class RouteRequest(BaseModel):
    source: str
    query: str
    context: Optional[Dict] = None
    user_id: Optional[str] = None

class RouteResponse(BaseModel):
    route: Optional[str]
    confidence: float
    method: str
    breakdown: Optional[Dict] = None

@app.post("/v1/route", response_model=RouteResponse)
async def route(request: RouteRequest):
    """è·¯ç”±API"""
    try:
        # ä½¿ç”¨æ··åˆè·¯ç”±å™¨
        route = await router.find_route(request.source, request.query)
        
        # è·å–ç½®ä¿¡åº¦
        confidence = 0.5
        if route and learner:
            confidence = await learner.get_probability(request.source, route)
        
        # è·å–ç»´åº¦åˆ†è§£
        breakdown = None
        if hasattr(learner, 'get_dimension_breakdown'):
            breakdown = await learner.get_dimension_breakdown(request.source, route)
        
        return RouteResponse(
            route=route,
            confidence=confidence,
            method="hybrid",
            breakdown=breakdown
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/v1/learning/update")
async def update_learning(update: Dict):
    """å­¦ä¹ æ›´æ–°API"""
    try:
        source = update['source']
        target = update['target']
        metrics = update['metrics']
        
        if hasattr(learner, 'update'):
            await learner.update(source, target, metrics)
        
        return {"status": "success"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v1/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "service": "routing"}

# å¯è§†åŒ–æœåŠ¡API
# services/visualization/main.py
from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.responses import HTMLResponse

app = FastAPI(title="Visualization Service")

ws_manager = None

@app.on_event("startup")
async def startup():
    global ws_manager
    ws_manager = WebSocketManager()

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocketå®æ—¶å¯è§†åŒ–"""
    await websocket.accept()
    await ws_manager.connect(session_id, websocket)
    
    try:
        while True:
            data = await websocket.receive_text()
            if data == "ping":
                await websocket.send_text("pong")
    except:
        await ws_manager.disconnect(session_id)

@app.get("/debug/{session_id}")
async def get_debug_dashboard(session_id: str):
    """è°ƒè¯•é¢æ¿"""
    debug_console = DebugConsole(ws_manager.get_visualizer().tracer, ws_manager.get_visualizer())
    return await debug_console.get_debug_dashboard(session_id)

@app.get("/trace/{session_id}/export")
async def export_trace(session_id: str, format: str = "json"):
    """å¯¼å‡ºè¿½è¸ª"""
    tracer = ws_manager.get_visualizer().tracer
    try:
        data = await tracer.export_trace(session_id, format)
        return {"data": data}
    except:
        raise HTTPException(status_code=404, detail="Trace not found")

# å­¦ä¹ æœåŠ¡API
# services/learning/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, List, Optional

app = FastAPI(title="Learning Service")

learner_manager = None

@app.on_event("startup")
async def startup():
    global learner_manager
    redis = await get_redis_client()
    learner_manager = MultiDimensionalLearnerManager(redis)

class LearningUpdate(BaseModel):
    user_id: str
    source: str
    target: str
    metrics: Dict

class ExperimentRequest(BaseModel):
    user_id: str
    experiment: str
    variant: str
    metrics: Dict

@app.post("/v1/learning/update")
async def update_learning(update: LearningUpdate):
    """æ›´æ–°å­¦ä¹ """
    try:
        learner = await learner_manager.get_learner(update.user_id)
        await learner.update(update.source, update.target, update.metrics)
        return {"status": "success"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/v1/experiment/record")
async def record_experiment(record: ExperimentRequest):
    """è®°å½•å®éªŒ"""
    try:
        framework = learner_manager.get_ab_framework()
        await framework.record_outcome(
            record.experiment,
            record.variant,
            record.user_id,
            record.metrics
        )
        return {"status": "success"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v1/experiment/stats/{exp_id}")
async def get_experiment_stats(exp_id: str):
    """è·å–å®éªŒç»Ÿè®¡"""
    try:
        framework = learner_manager.get_ab_framework()
        stats = await framework.get_stats(exp_id)
        return {"stats": stats}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v1/health")
async def health():
    return {"status": "healthy", "service": "learning"}

# APIç½‘å…³
# services/gateway/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import httpx
import os

app = FastAPI(title="Sparkle API Gateway")

ROUTING_URL = os.getenv("ROUTING_SERVICE_URL", "http://localhost:8001")
VISUALIZATION_URL = os.getenv("VISUALIZATION_SERVICE_URL", "http://localhost:8002")
LEARNING_URL = os.getenv("LEARNING_SERVICE_URL", "http://localhost:8003")

class ChatRequest(BaseModel):
    session_id: str
    user_id: str
    query: str
    context: Optional[Dict] = None

@app.post("/v1/chat")
async def chat(request: ChatRequest):
    """ç»Ÿä¸€èŠå¤©API"""
    async with httpx.AsyncClient() as client:
        # 1. è·å–è·¯ç”±
        route_response = await client.post(
            f"{ROUTING_URL}/v1/route",
            json={
                "source": "orchestrator",
                "query": request.query,
                "context": request.context,
                "user_id": request.user_id
            }
        )
        route_data = route_response.json()
        
        # 2. æ‰§è¡ŒAgentï¼ˆç®€åŒ–ï¼‰
        # å®é™…ä¼šè°ƒç”¨AgentæœåŠ¡
        
        # 3. è®°å½•å­¦ä¹ 
        await client.post(
            f"{LEARNING_URL}/v1/learning/update",
            json={
                "user_id": request.user_id,
                "source": "orchestrator",
                "target": route_data['route'],
                "metrics": {"success": True, "latency": 0.5}
            }
        )
        
        return {
            "route": route_data['route'],
            "confidence": route_data['confidence'],
            "response": "Demo response"
        }

@app.get("/v1/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "service": "gateway"}
```

**æœåŠ¡é—´é€šä¿¡**:
```python
# services/shared/client.py
from typing import Optional
import httpx
from loguru import logger

class ServiceClient:
    """æœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.client = httpx.AsyncClient(timeout=30.0)
    
    async def route(self, source: str, query: str, context: dict = None, user_id: str = None):
        """è°ƒç”¨è·¯ç”±æœåŠ¡"""
        try:
            response = await self.client.post(
                f"{self.base_url}/v1/route",
                json={
                    "source": source,
                    "query": query,
                    "context": context,
                    "user_id": user_id
                }
            )
            return response.json()
        except Exception as e:
            logger.error(f"Routing service error: {e}")
            return None
    
    async def update_learning(self, user_id: str, source: str, target: str, metrics: dict):
        """è°ƒç”¨å­¦ä¹ æœåŠ¡"""
        try:
            await self.client.post(
                f"{self.base_url}/v1/learning/update",
                json={
                    "user_id": user_id,
                    "source": source,
                    "target": target,
                    "metrics": metrics
                }
            )
        except Exception as e:
            logger.error(f"Learning service error: {e}")
    
    async def get_debug_dashboard(self, session_id: str):
        """è°ƒç”¨å¯è§†åŒ–æœåŠ¡"""
        try:
            response = await self.client.get(
                f"{self.base_url}/debug/{session_id}"
            )
            return response.json()
        except Exception as e:
            logger.error(f"Visualization service error: {e}")
            return None
```

**å®æ–½æ­¥éª¤**:
1. âœ… æ‹†åˆ†æœåŠ¡è¾¹ç•Œ
2. âœ… é‡æ„ä¸ºå¾®æœåŠ¡
3. âœ… å®ç°æœåŠ¡é—´é€šä¿¡
4. âœ… æ·»åŠ APIç½‘å…³
5. âœ… é…ç½®Docker Compose
6. âœ… æ·»åŠ æœåŠ¡å‘ç°

**é¢„æœŸæ•ˆæœ**: 
- ç‹¬ç«‹æ‰©å±•èƒ½åŠ›
- æ•…éšœéš”ç¦»
- æŠ€æœ¯æ ˆçµæ´»

---

#### 11. é«˜çº§å¯è§†åŒ–å·¥å…·

**é—®é¢˜**: è°ƒè¯•ç•Œé¢åŠŸèƒ½æœ‰é™

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/visualization/advanced_debug_console.py
from typing import Dict, List, Optional
import json
from datetime import datetime

class AdvancedDebugConsole:
    """
    é«˜çº§è°ƒè¯•æ§åˆ¶å°
    """
    
    def __init__(self, tracer, visualizer, learner):
        self.tracer = tracer
        self.visualizer = visualizer
        self.learner = learner
    
    async def get_comprehensive_dashboard(self, session_id: str) -> Dict:
        """è·å–ç»¼åˆè°ƒè¯•é¢æ¿"""
        
        # 1. æ‰§è¡Œè¿½è¸ª
        events = await self.tracer.replay(session_id)
        summary = await self.tracer.get_execution_summary(session_id)
        
        # 2. çŠ¶æ€æ£€æŸ¥
        state = await self._get_current_state(session_id)
        
        # 3. æ€§èƒ½åˆ†æ
        performance = await self._analyze_performance(events)
        
        # 4. å­¦ä¹ çŠ¶æ€
        learning = await self._get_learning_status(session_id)
        
        # 5. è·¯ç”±åˆ†æ
        routing = await self._analyze_routing(events)
        
        # 6. ç”Ÿæˆå»ºè®®
        recommendations = await self._generate_recommendations(
            events, summary, state, performance, learning, routing
        )
        
        # 7. å¯è§†åŒ–
        mermaid = await self.tracer.replay_with_visualization(session_id)
        
        return {
            'metadata': {
                'session_id': session_id,
                'timestamp': datetime.now().isoformat(),
                'version': '1.0'
            },
            'execution': {
                'events': events,
                'summary': summary,
                'mermaid': mermaid
            },
            'state': state,
            'performance': performance,
            'learning': learning,
            'routing': routing,
            'recommendations': recommendations,
            'actions': self._get_actions(session_id)
        }
    
    async def _analyze_performance(self, events: List[Dict]) -> Dict:
        """æ€§èƒ½åˆ†æ"""
        if not events:
            return {}
        
        # è®¡ç®—å„é˜¶æ®µè€—æ—¶
        stages = {}
        current_stage = None
        stage_start = None
        
        for event in events:
            if event['type'] == 'NODE_START':
                current_stage = event['node']
                stage_start = event['timestamp']
            elif event['type'] == 'NODE_END' and current_stage:
                latency = event['timestamp'] - stage_start
                stages[current_stage] = {
                    'latency': latency,
                    'status': 'success'
                }
                current_stage = None
            elif event['type'] == 'ERROR':
                if current_stage:
                    stages[current_stage]['status'] = 'error'
        
        # è¯†åˆ«ç“¶é¢ˆ
        sorted_stages = sorted(stages.items(), key=lambda x: x[1]['latency'], reverse=True)
        
        return {
            'total_latency': events[-1]['timestamp'] - events[0]['timestamp'],
            'stages': stages,
            'bottlenecks': sorted_stages[:3],
            'recommendations': self._get_performance_recommendations(stages)
        }
    
    async def _get_learning_status(self, session_id: str) -> Dict:
        """å­¦ä¹ çŠ¶æ€åˆ†æ"""
        if not hasattr(self.learner, 'get_stats'):
            return {}
        
        stats = await self.learner.get_stats()
        
        # åˆ†æå­¦ä¹ è¿›åº¦
        total_routes = len(stats)
        explored_routes = sum(1 for s in stats.values() if s['attempts'] > 0)
        
        return {
            'total_routes': total_routes,
            'explored_routes': explored_routes,
            'exploration_rate': explored_routes / total_routes if total_routes > 0 else 0,
            'top_routes': sorted(
                stats.items(),
                key=lambda x: x[1]['probability'],
                reverse=True
            )[:5],
            'needs_exploration': [
                route for route, stats in stats.items()
                if stats['attempts'] < 5
            ]
        }
    
    async def _analyze_routing(self, events: List[Dict]) -> Dict:
        """è·¯ç”±åˆ†æ"""
        routing_events = [e for e in events if e['type'] in ['EDGE_TRAVERSAL', 'NODE_START']]
        
        routes_taken = []
        for i in range(len(routing_events) - 1):
            if routing_events[i]['type'] == 'NODE_START' and routing_events[i+1]['type'] == 'EDGE_TRAVERSAL':
                routes_taken.append({
                    'from': routing_events[i]['node'],
                    'to': routing_events[i+1]['node'].split('->')[1] if '->' in routing_events[i+1]['node'] else '?'
                })
        
        return {
            'routes_taken': routes_taken,
            'route_count': len(routes_taken),
            'route_efficiency': self._calculate_route_efficiency(routes_taken)
        }
    
    def _calculate_route_efficiency(self, routes: List[Dict]) -> float:
        """è®¡ç®—è·¯ç”±æ•ˆç‡"""
        if not routes:
            return 0.0
        
        # ç®€å•å¯å‘å¼ï¼šè·¯å¾„è¶ŠçŸ­è¶Šå¥½
        unique_nodes = set()
        for route in routes:
            unique_nodes.add(route['from'])
            unique_nodes.add(route['to'])
        
        efficiency = 1.0 - (len(unique_nodes) - 2) / 10  # ç®€åŒ–è®¡ç®—
        return max(0.0, efficiency)
    
    async def _generate_recommendations(
        self, events, summary, state, performance, learning, routing
    ) -> List[Dict]:
        """ç”Ÿæˆç»¼åˆå»ºè®®"""
        recommendations = []
        
        # æ€§èƒ½å»ºè®®
        if performance and performance['total_latency'] > 5.0:
            recommendations.append({
                'category': 'performance',
                'priority': 'high',
                'title': 'æ‰§è¡Œæ—¶é—´è¿‡é•¿',
                'description': f"æ€»è€—æ—¶ {performance['total_latency']:.2f}s",
                'suggestions': [
                    'æ·»åŠ è·¯ç”±ç¼“å­˜',
                    'ä¼˜åŒ–LLMè°ƒç”¨',
                    'å‡å°‘ä¸å¿…è¦çš„èŠ‚ç‚¹'
                ],
                'estimated_impact': 'å»¶è¿Ÿå‡å°‘ 50-80%'
            })
        
        # å­¦ä¹ å»ºè®®
        if learning and learning['exploration_rate'] < 0.5:
            recommendations.append({
                'category': 'learning',
                'priority': 'medium',
                'title': 'æ¢ç´¢ä¸è¶³',
                'description': f"ä»…æ¢ç´¢äº† {learning['exploration_rate']:.1%} çš„è·¯å¾„",
                'suggestions': [
                    'å¢åŠ æ¢ç´¢ç‡',
                    'å°è¯•æ–°è·¯ç”±ç»„åˆ',
                    'è¿è¡ŒA/Bæµ‹è¯•'
                ],
                'estimated_impact': 'å‘ç°æ›´ä¼˜è·¯å¾„'
            })
        
        # è·¯ç”±å»ºè®®
        if routing and routing['route_efficiency'] < 0.7:
            recommendations.append({
                'category': 'routing',
                'priority': 'medium',
                'title': 'è·¯ç”±æ•ˆç‡ä½',
                'description': f"è·¯ç”±æ•ˆç‡ {routing['route_efficiency']:.1%}",
                'suggestions': [
                    'ä¼˜åŒ–å›¾ç»“æ„',
                    'è°ƒæ•´è¾¹æƒé‡',
                    'æ·»åŠ ç›´æ¥è·¯ç”±'
                ],
                'estimated_impact': 'å‡å°‘è·³æ•°'
            })
        
        # é”™è¯¯å»ºè®®
        error_count = summary.get('error_count', 0) if summary else 0
        if error_count > 0:
            recommendations.append({
                'category': 'reliability',
                'priority': 'high',
                'title': 'é”™è¯¯ç‡é«˜',
                'description': f"æ£€æµ‹åˆ° {error_count} ä¸ªé”™è¯¯",
                'suggestions': [
                    'æŸ¥çœ‹é”™è¯¯æ—¥å¿—',
                    'æ·»åŠ é‡è¯•æœºåˆ¶',
                    'å®ç°fallbackç­–ç•¥'
                ],
                'estimated_impact': 'æå‡æˆåŠŸç‡'
            })
        
        return recommendations
    
    def _get_actions(self, session_id: str) -> List[Dict]:
        """å¯ç”¨çš„æ“ä½œ"""
        return [
            {
                'name': 'Export Trace',
                'method': 'GET',
                'url': f'/api/trace/{session_id}/export'
            },
            {
                'name': 'Visualize',
                'method': 'GET',
                'url': f'/visualize/{session_id}'
            },
            {
                'name': 'Clear Trace',
                'method': 'DELETE',
                'url': f'/api/trace/{session_id}'
            },
            {
                'name': 'Run A/B Test',
                'method': 'POST',
                'url': f'/api/experiment/{session_id}/start'
            }
        ]
    
    def _get_performance_recommendations(self, stages: Dict) -> List[str]:
        """æ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recs = []
        for stage, data in stages.items():
            if data['latency'] > 2.0:
                recs.append(f"ä¼˜åŒ– {stage} (è€—æ—¶ {data['latency']:.2f}s)")
        return recs
    
    async def _get_current_state(self, session_id: str):
        """è·å–å½“å‰çŠ¶æ€"""
        # ä»checkpointeråŠ è½½
        from app.checkpoint.redis_checkpointer import RedisCheckpointer
        from app.services.redis_service import get_redis_client
        
        redis = await get_redis_client()
        checkpointer = RedisCheckpointer(redis)
        return await checkpointer.load(session_id)

# å‰ç«¯é«˜çº§è°ƒè¯•ç•Œé¢
# frontend/advanced_debug_console.html
"""
<!DOCTYPE html>
<html>
<head>
    <title>Sparkle Advanced Debug Console</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <style>
        body { font-family: Arial; margin: 20px; background: #f5f5f5; }
        .dashboard { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
        .panel { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .panel h3 { margin-top: 0; color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px; }
        .metric { display: flex; justify-content: space-between; padding: 8px 0; border-bottom: 1px solid #eee; }
        .recommendation { background: #fff3cd; border-left: 4px solid #ffc107; padding: 12px; margin: 10px 0; border-radius: 4px; }
        .recommendation.high { background: #f8d7da; border-left-color: #dc3545; }
        .recommendation.medium { background: #fff3cd; border-left-color: #ffc107; }
        .recommendation.low { background: #d1ecf1; border-left-color: #17a2b8; }
        .event { font-family: monospace; padding: 4px 8px; margin: 2px 0; background: #f8f9fa; border-radius: 3px; }
        .event.error { background: #f8d7da; color: #721c24; }
        .event.success { background: #d4edda; color: #155724; }
        .action-btn { background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; margin: 5px; }
        .action-btn:hover { background: #0056b3; }
        .action-btn.danger { background: #dc3545; }
        .action-btn.danger:hover { background: #c82333; }
        #graph-container { overflow: auto; max-height: 500px; border: 1px solid #ddd; background: white; padding: 10px; }
    </style>
</head>
<body>
    <h1>ğŸ” Sparkle Advanced Debug Console</h1>
    
    <div class="dashboard">
        <!-- å·¦ä¾§ï¼šæ‰§è¡Œè¿½è¸ª -->
        <div class="panel">
            <h3>ğŸ“Š Execution Trace</h3>
            <div id="trace-summary"></div>
            <div id="trace-events" style="max-height: 300px; overflow-y: auto; margin-top: 10px;"></div>
        </div>
        
        <!-- å³ä¾§ï¼šæ€§èƒ½åˆ†æ -->
        <div class="panel">
            <h3>âš¡ Performance Analysis</h3>
            <div id="performance-metrics"></div>
            <div id="bottlenecks"></div>
        </div>
        
        <!-- ä¸­é—´ï¼šå¯è§†åŒ– -->
        <div class="panel" style="grid-column: 1 / -1;">
            <h3>ğŸ“ˆ Visualization</h3>
            <div id="graph-container"></div>
        </div>
        
        <!-- å­¦ä¹ çŠ¶æ€ -->
        <div class="panel">
            <h3>ğŸ§  Learning Status</h3>
            <div id="learning-status"></div>
        </div>
        
        <!-- è·¯ç”±åˆ†æ -->
        <div class="panel">
            <h3>ğŸ—ºï¸ Routing Analysis</h3>
            <div id="routing-analysis"></div>
        </div>
        
        <!-- æ¨è -->
        <div class="panel" style="grid-column: 1 / -1;">
            <h3>ğŸ’¡ Recommendations</h3>
            <div id="recommendations"></div>
        </div>
        
        <!-- æ“ä½œ -->
        <div class="panel" style="grid-column: 1 / -1;">
            <h3>ğŸ› ï¸ Actions</h3>
            <div id="actions"></div>
        </div>
    </div>
    
    <script>
        const sessionId = new URLSearchParams(window.location.search).get('session_id') || 'demo';
        
        async function loadDashboard() {
            const response = await fetch(`/api/debug/${sessionId}`);
            const data = await response.json();
            
            // æ¸²æŸ“æ‰§è¡Œè¿½è¸ª
            renderTrace(data.execution);
            
            // æ¸²æŸ“æ€§èƒ½
            renderPerformance(data.performance);
            
            // æ¸²æŸ“å¯è§†åŒ–
            renderVisualization(data.execution.mermaid);
            
            // æ¸²æŸ“å­¦ä¹ çŠ¶æ€
            renderLearning(data.learning);
            
            // æ¸²æŸ“è·¯ç”±
            renderRouting(data.routing);
            
            // æ¸²æŸ“æ¨è
            renderRecommendations(data.recommendations);
            
            // æ¸²æŸ“æ“ä½œ
            renderActions(data.actions);
        }
        
        function renderTrace(execution) {
            const summary = document.getElementById('trace-summary');
            const events = document.getElementById('trace-events');
            
            if (execution.summary) {
                summary.innerHTML = `
                    <div class="metric"><span>Events:</span><span>${execution.summary.total_events}</span></div>
                    <div class="metric"><span>Latency:</span><span>${execution.summary.total_latency?.toFixed(2)}s</span></div>
                    <div class="metric"><span>Errors:</span><span>${execution.summary.error_count}</span></div>
                `;
            }
            
            if (execution.events) {
                events.innerHTML = execution.events.map(e => `
                    <div class="event ${e.type === 'ERROR' ? 'error' : 'success'}">
                        [${new Date(e.timestamp * 1000).toLocaleTimeString()}] ${e.type}: ${e.node}
                    </div>
                `).join('');
            }
        }
        
        function renderPerformance(performance) {
            if (!performance) return;
            
            const metrics = document.getElementById('performance-metrics');
            const bottlenecks = document.getElementById('bottlenecks');
            
            metrics.innerHTML = `
                <div class="metric"><span>Total:</span><span>${performance.total_latency?.toFixed(2)}s</span></div>
            `;
            
            if (performance.bottlenecks) {
                bottlenecks.innerHTML = '<h4>Top Bottlenecks:</h4>' + 
                    performance.bottlenecks.map(([node, data]) => `
                        <div class="metric"><span>${node}:</span><span>${data.latency.toFixed(2)}s</span></div>
                    `).join('');
            }
        }
        
        function renderVisualization(mermaidCode) {
            if (!mermaidCode) return;
            
            mermaid.render('graph', mermaidCode, (svg) => {
                document.getElementById('graph-container').innerHTML = svg;
            });
        }
        
        function renderLearning(learning) {
            if (!learning) return;
            
            const container = document.getElementById('learning-status');
            container.innerHTML = `
                <div class="metric"><span>Explored:</span><span>${learning.explored_routes}/${learning.total_routes}</span></div>
                <div class="metric"><span>Rate:</span><span>${(learning.exploration_rate * 100).toFixed(1)}%</span></div>
                ${learning.needs_exploration?.length > 0 ? `
                    <div style="margin-top: 10px;">
                        <strong>Needs Exploration:</strong><br>
                        ${learning.needs_exploration.join(', ')}
                    </div>
                ` : ''}
            `;
        }
        
        function renderRouting(routing) {
            if (!routing) return;
            
            const container = document.getElementById('routing-analysis');
            container.innerHTML = `
                <div class="metric"><span>Routes:</span><span>${routing.route_count}</span></div>
                <div class="metric"><span>Efficiency:</span><span>${(routing.route_efficiency * 100).toFixed(1)}%</span></div>
                ${routing.routes_taken?.length > 0 ? `
                    <div style="margin-top: 10px;">
                        <strong>Path:</strong><br>
                        ${routing.routes_taken.map(r => `${r.from} â†’ ${r.to}`).join(' â†’ ')}
                    </div>
                ` : ''}
            `;
        }
        
        function renderRecommendations(recommendations) {
            const container = document.getElementById('recommendations');
            if (!recommendations || recommendations.length === 0) {
                container.innerHTML = '<p>No recommendations yet</p>';
                return;
            }
            
            container.innerHTML = recommendations.map(rec => `
                <div class="recommendation ${rec.priority}">
                    <strong>${rec.title}</strong> (${rec.category})<br>
                    <em>${rec.description}</em><br>
                    <ul>
                        ${rec.suggestions.map(s => `<li>${s}</li>`).join('')}
                    </ul>
                    <small>Impact: ${rec.estimated_impact}</small>
                </div>
            `).join('');
        }
        
        function renderActions(actions) {
            const container = document.getElementById('actions');
            if (!actions) return;
            
            container.innerHTML = actions.map(action => `
                <button class="action-btn ${action.method === 'DELETE' ? 'danger' : ''}" 
                        onclick="performAction('${action.method}', '${action.url}')">
                    ${action.name}
                </button>
            `).join('');
        }
        
        async function performAction(method, url) {
            try {
                const response = await fetch(url, { method });
                if (response.ok) {
                    alert('Action completed successfully');
                    if (method === 'GET') {
                        const data = await response.json();
                        console.log(data);
                    } else {
                        loadDashboard(); // Refresh
                    }
                } else {
                    alert('Action failed');
                }
            } catch (e) {
                alert('Error: ' + e.message);
            }
        }
        
        // Auto-refresh
        setInterval(loadDashboard, 5000);
        
        // Initial load
        loadDashboard();
    </script>
</body>
</html>
"""
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°AdvancedDebugConsole
2. âœ… é›†æˆåˆ°Orchestrator
3. âœ… åˆ›å»ºAPIç«¯ç‚¹
4. âœ… å¼€å‘å‰ç«¯HTMLç•Œé¢
5. âœ… æ·»åŠ è‡ªåŠ¨åˆ·æ–°
6. âœ… å®ç°äº¤äº’åŠŸèƒ½

**é¢„æœŸæ•ˆæœ**: 
- å¼€å‘ä½“éªŒå¤§å¹…æå‡
- ä¸€ç«™å¼è°ƒè¯•å·¥å…·
- æ™ºèƒ½å»ºè®®

---

#### 12. è‡ªåŠ¨ä¼˜åŒ–å¼•æ“

**é—®é¢˜**: äººå·¥è°ƒä¼˜æˆæœ¬é«˜

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# backend/app/learning/auto_optimizer.py
from typing import Dict, List
import asyncio
from loguru import logger
import numpy as np

class AutoOptimizer:
    """
    è‡ªåŠ¨ä¼˜åŒ–å¼•æ“ï¼šåŸºäºæ•°æ®è‡ªåŠ¨è°ƒæ•´ç³»ç»Ÿå‚æ•°
    """
    
    def __init__(self, graph_router, learner, redis_client):
        self.graph = graph_router
        self.learner = learner
        self.redis = redis_client
        self.optimization_history = []
    
    async def optimize(self):
        """æ‰§è¡Œè‡ªåŠ¨ä¼˜åŒ–"""
        logger.info("Starting auto-optimization...")
        
        # 1. æ”¶é›†æŒ‡æ ‡
        metrics = await self._collect_metrics()
        
        # 2. è¯†åˆ«ä¼˜åŒ–æœºä¼š
        opportunities = await self._identify_opportunities(metrics)
        
        # 3. æ‰§è¡Œä¼˜åŒ–
        changes = await self._apply_optimizations(opportunities)
        
        # 4. éªŒè¯æ•ˆæœ
        validation = await self._validate_improvement()
        
        # 5. è®°å½•å†å²
        await self._record_optimization(opportunities, changes, validation)
        
        logger.info(f"Auto-optimization complete: {len(changes)} changes applied")
        return {
            'opportunities': opportunities,
            'changes': changes,
            'validation': validation
        }
    
    async def _collect_metrics(self) -> Dict:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        metrics = {
            'routes': {},
            'performance': {},
            'learning': {},
            'graph': {}
        }
        
        # è·¯ç”±æŒ‡æ ‡
        if hasattr(self.learner, 'get_stats'):
            stats = await self.learner.get_stats()
            metrics['routes'] = stats
        
        # æ€§èƒ½æŒ‡æ ‡ï¼ˆä»Redisï¼‰
        perf_keys = await self.redis.keys("perf:*")
        for key in perf_keys:
            data = await self.redis.get(key)
            if data:
                metrics['performance'][key.decode().split(':')[1]] = json.loads(data)
        
        # å›¾æŒ‡æ ‡
        metrics['graph']['node_count'] = self.graph.graph.number_of_nodes()
        metrics['graph']['edge_count'] = self.graph.graph.number_of_edges()
        
        return metrics
    
    async def _identify_opportunities(self, metrics: Dict) -> List[Dict]:
        """è¯†åˆ«ä¼˜åŒ–æœºä¼š"""
        opportunities = []
        
        # æœºä¼š1: ä½æ¦‚ç‡é«˜å°è¯•è·¯å¾„
        for route, stats in metrics['routes'].items():
            attempts = stats['alpha'] + stats['beta'] - 2
            if attempts > 10 and stats['probability'] < 0.3:
                opportunities.append({
                    'type': 'route_weight_adjustment',
                    'route': route,
                    'reason': f"Low probability ({stats['probability']:.2f}) with {attempts} attempts",
                    'action': 'increase_exploration',
                    'priority': 'high'
                })
        
        # æœºä¼š2: é«˜å»¶è¿Ÿè·¯å¾„
        for route, latency in metrics['performance'].items():
            if latency > 2.0:
                opportunities.append({
                    'type': 'cache_optimization',
                    'route': route,
                    'reason': f"High latency ({latency:.2f}s)",
                    'action': 'add_cache',
                    'priority': 'medium'
                })
        
        # æœºä¼š3: æœªæ¢ç´¢è·¯å¾„
        all_possible = set()
        for source in self.graph.graph.nodes():
            for target in self.graph.graph.nodes():
                if source != target:
                    all_possible.add(f"{source}->{target}")
        
        explored = set(metrics['routes'].keys())
        unexplored = all_possible - explored
        
        for route in list(unexplored)[:5]:  # åªæ¨èå‰5ä¸ª
            opportunities.append({
                'type': 'new_path_exploration',
                'route': route,
                'reason': "Never explored",
                'action': 'explore',
                'priority': 'low'
            })
        
        # æœºä¼š4: è¾¹æƒé‡ä¸å¹³è¡¡
        for u, v, data in self.graph.graph.edges(data=True):
            weight = data.get('weight', 1.0)
            if weight > 5.0 or weight < 0.2:
                opportunities.append({
                    'type': 'weight_normalization',
                    'route': f"{u}->{v}",
                    'reason': f"Unbalanced weight ({weight:.2f})",
                    'action': 'normalize',
                    'priority': 'medium'
                })
        
        return opportunities
    
    async def _apply_optimizations(self, opportunities: List[Dict]) -> List[Dict]:
        """åº”ç”¨ä¼˜åŒ–"""
        changes = []
        
        for opp in opportunities:
            try:
                if opp['type'] == 'route_weight_adjustment':
                    # è°ƒæ•´æ¢ç´¢ç‡
                    if hasattr(self.learner, 'epsilon'):
                        old_epsilon = self.learner.epsilon
                        self.learner.epsilon = min(0.5, old_epsilon * 1.2)
                        changes.append({
                            'action': 'increase_exploration',
                            'from': old_epsilon,
                            'to': self.learner.epsilon,
                            'status': 'success'
                        })
                
                elif opp['type'] == 'cache_optimization':
                    # æ·»åŠ ç¼“å­˜
                    if hasattr(self.graph, 'cache'):
                        source, target = opp['route'].split('->')
                        # é¢„è®¡ç®—å¹¶ç¼“å­˜
                        route = self.graph._compute_route(source, target)
                        if route:
                            await self.graph.cache.set_route(source, target, route, ttl=3600)
                            changes.append({
                                'action': 'add_cache',
                                'route': opp['route'],
                                'status': 'success'
                            })
                
                elif opp['type'] == 'weight_normalization':
                    # å½’ä¸€åŒ–æƒé‡
                    u, v = opp['route'].split('->')
                    if self.graph.graph.has_edge(u, v):
                        old_weight = self.graph.graph[u][v]['weight']
                        new_weight = max(0.1, min(old_weight, 5.0))  # é™åˆ¶åœ¨0.1-5.0
                        self.graph.graph[u][v]['weight'] = new_weight
                        changes.append({
                            'action': 'normalize_weight',
                            'route': opp['route'],
                            'from': old_weight,
                            'to': new_weight,
                            'status': 'success'
                        })
                
                elif opp['type'] == 'new_path_exploration':
                    # æ ‡è®°ä¸ºéœ€è¦æ¢ç´¢
                    source, target = opp['route'].split('->')
                    # åœ¨ä¸‹æ¬¡è·¯ç”±æ—¶ä¼šè‡ªåŠ¨æ¢ç´¢
                    changes.append({
                        'action': 'mark_for_exploration',
                        'route': opp['route'],
                        'status': 'pending'
                    })
            
            except Exception as e:
                logger.error(f"Optimization failed for {opp}: {e}")
                changes.append({
                    'action': opp['type'],
                    'route': opp['route'],
                    'status': 'failed',
                    'error': str(e)
                })
        
        return changes
    
    async def _validate_improvement(self) -> Dict:
        """éªŒè¯æ”¹è¿›æ•ˆæœ"""
        # é‡‡æ ·æµ‹è¯•
        test_cases = [
            ('orchestrator', 'math_agent', 'è®¡ç®—åœ†çš„é¢ç§¯'),
            ('orchestrator', 'code_agent', 'å†™ä¸€ä¸ªPythonå‡½æ•°'),
            ('orchestrator', 'knowledge_agent', 'ä»€ä¹ˆæ˜¯AI')
        ]
        
        results = []
        for source, target, query in test_cases:
            start = time.time()
            route = await self.graph.find_route(source, target)
            latency = time.time() - start
            
            if route:
                prob = await self.learner.get_probability(source, route)
                results.append({
                    'query': query,
                    'route': route,
                    'latency': latency,
                    'confidence': prob
                })
        
        return {
            'test_results': results,
            'avg_latency': np.mean([r['latency'] for r in results]),
            'avg_confidence': np.mean([r['confidence'] for r in results])
        }
    
    async def _record_optimization(self, opportunities, changes, validation):
        """è®°å½•ä¼˜åŒ–å†å²"""
        record = {
            'timestamp': datetime.now().isoformat(),
            'opportunities_count': len(opportunities),
            'changes_count': len(changes),
            'changes': changes,
            'validation': validation,
            'success_rate': sum(1 for c in changes if c['status'] == 'success') / len(changes) if changes else 0
        }
        
        self.optimization_history.append(record)
        
        # æŒä¹…åŒ–åˆ°Redis
        await self.redis.lpush(
            "auto_optimization_history",
            json.dumps(record)
        )
        await self.redis.ltrim("auto_optimization_history", 0, 99)  # ä¿ç•™æœ€è¿‘100æ¡
    
    async def get_optimization_history(self, limit: int = 10):
        """è·å–ä¼˜åŒ–å†å²"""
        history = await self.redis.lrange("auto_optimization_history", 0, limit - 1)
        return [json.loads(h) for h in history]

# å®šæ—¶ä¼˜åŒ–å™¨
class ScheduledOptimizer:
    """å®šæ—¶è‡ªåŠ¨ä¼˜åŒ–"""
    
    def __init__(self, optimizer: AutoOptimizer, interval: int = 3600):
        self.optimizer = optimizer
        self.interval = interval  # ç§’
        self.running = False
    
    async def start(self):
        """å¯åŠ¨å®šæ—¶ä¼˜åŒ–"""
        self.running = True
        logger.info(f"Scheduled optimizer started (interval: {self.interval}s)")
        
        while self.running:
            try:
                # ç­‰å¾…é—´éš”
                await asyncio.sleep(self.interval)
                
                # æ‰§è¡Œä¼˜åŒ–
                if self.running:
                    logger.info("Running scheduled optimization...")
                    result = await self.optimizer.optimize()
                    logger.info(f"Scheduled optimization completed: {result}")
            
            except Exception as e:
                logger.error(f"Scheduled optimization error: {e}")
    
    def stop(self):
        """åœæ­¢å®šæ—¶ä¼˜åŒ–"""
        self.running = False
        logger.info("Scheduled optimizer stopped")

# é›†æˆåˆ°ç³»ç»Ÿ
# backend/app/learning/optimization_service.py
class OptimizationService:
    """ä¼˜åŒ–æœåŠ¡"""
    
    def __init__(self, redis_client):
        self.redis = redis_client
        self.optimizer = None
        self.scheduler = None
    
    async def initialize(self, graph_router, learner):
        """åˆå§‹åŒ–ä¼˜åŒ–æœåŠ¡"""
        self.optimizer = AutoOptimizer(graph_router, learner, self.redis)
        self.scheduler = ScheduledOptimizer(self.optimizer, interval=1800)  # 30åˆ†é’Ÿ
        
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡
        asyncio.create_task(self.scheduler.start())
        
        logger.info("Optimization service initialized")
    
    async def manual_optimize(self):
        """æ‰‹åŠ¨è§¦å‘ä¼˜åŒ–"""
        if not self.optimizer:
            raise ValueError("Optimizer not initialized")
        
        return await self.optimizer.optimize()
    
    async def get_status(self):
        """è·å–ä¼˜åŒ–æœåŠ¡çŠ¶æ€"""
        if not self.scheduler:
            return {"status": "not_initialized"}
        
        history = await self.optimizer.get_optimization_history(5)
        
        return {
            "status": "running" if self.scheduler.running else "stopped",
            "interval": self.scheduler.interval,
            "history": history,
            "can_optimize": self.optimizer is not None
        }
    
    async def stop(self):
        """åœæ­¢ä¼˜åŒ–æœåŠ¡"""
        if self.scheduler:
            self.scheduler.stop()
            return {"status": "stopped"}
        return {"status": "not_running"}

# é›†æˆåˆ°Orchestrator
# backend/app/orchestration/orchestrator.py
class ChatOrchestrator:
    def __init__(self, db_session=None, redis_client=None):
        # ... åŸæœ‰åˆå§‹åŒ– ...
        
        # æ·»åŠ ä¼˜åŒ–æœåŠ¡
        if redis_client:
            from app.learning.optimization_service import OptimizationService
            self.optimization_service = OptimizationService(redis_client)
            
            # å»¶è¿Ÿåˆå§‹åŒ–ï¼ˆç­‰å¾…graphå’Œlearnerå‡†å¤‡å¥½ï¼‰
            asyncio.create_task(self._initialize_optimization())
    
    async def _initialize_optimization(self):
        """å»¶è¿Ÿåˆå§‹åŒ–ä¼˜åŒ–æœåŠ¡"""
        await asyncio.sleep(5)  # ç­‰å¾…å…¶ä»–ç»„ä»¶åˆå§‹åŒ–
        
        if hasattr(self, 'graph') and hasattr(self, 'learner'):
            await self.optimization_service.initialize(
                self.graph,
                self.learner
            )
    
    async def process_stream(self, request, db_session, context_data):
        """å¤„ç†æµç¨‹"""
        # ... åŸæœ‰é€»è¾‘ ...
        
        # åœ¨finallyä¸­è§¦å‘ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
        try:
            # ... æ‰§è¡Œ ...
        finally:
            # å¦‚æœæ€§èƒ½å·®ï¼Œè§¦å‘ä¼˜åŒ–
            if hasattr(self, 'optimization_service'):
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
                summary = await self.tracer.get_execution_summary(request.session_id)
                if summary and summary['total_latency'] > 10.0:
                    # å¼‚æ­¥è§¦å‘ä¼˜åŒ–
                    asyncio.create_task(
                        self.optimization_service.manual_optimize()
                    )

# APIç«¯ç‚¹
from fastapi import APIRouter

optimization_router = APIRouter(prefix="/api/optimization")

@optimization_router.post("/optimize")
async def manual_optimize():
    """æ‰‹åŠ¨è§¦å‘ä¼˜åŒ–"""
    service = get_optimization_service()
    result = await service.manual_optimize()
    return result

@optimization_router.get("/status")
async def get_status():
    """è·å–ä¼˜åŒ–çŠ¶æ€"""
    service = get_optimization_service()
    return await service.get_status()

@optimization_router.post("/stop")
async def stop_optimization():
    """åœæ­¢ä¼˜åŒ–"""
    service = get_optimization_service()
    return await service.stop()

@optimization_router.get("/history")
async def get_history(limit: int = 10):
    """è·å–ä¼˜åŒ–å†å²"""
    service = get_optimization_service()
    if hasattr(service, 'optimizer'):
        history = await service.optimizer.get_optimization_history(limit)
        return {"history": history}
    return {"history": []}
```

**å®æ–½æ­¥éª¤**:
1. âœ… å®ç°AutoOptimizeræ ¸å¿ƒ
2. âœ… å®ç°ScheduledOptimizer
3. âœ… åˆ›å»ºOptimizationService
4. âœ… é›†æˆåˆ°Orchestrator
5. âœ… æ·»åŠ APIç«¯ç‚¹
6. âœ… é…ç½®å®šæ—¶ä»»åŠ¡

**é¢„æœŸæ•ˆæœ**: 
- ç³»ç»Ÿè‡ªæˆ‘è¿›åŒ–
- å‡å°‘äººå·¥å¹²é¢„
- æŒç»­æ€§èƒ½æå‡

---

## ğŸ“ˆ å®æ–½è·¯çº¿å›¾

### ç¬¬1å‘¨ï¼šP0æ ¸å¿ƒä¿®å¤
- [ ] å®ç°æŒä¹…åŒ–è´å¶æ–¯å­¦ä¹ å™¨
- [ ] é›†æˆè¯­ä¹‰è·¯ç”±
- [ ] æ·»åŠ ä¸šåŠ¡ç›‘æ§æŒ‡æ ‡
- [ ] éƒ¨ç½²Prometheus + Grafana
- [ ] é…ç½®å‘Šè­¦è§„åˆ™

### ç¬¬2å‘¨ï¼šP1ä½“éªŒæå‡
- [ ] WebSocketå®æ—¶å¯è§†åŒ–
- [ ] æ¢ç´¢-åˆ©ç”¨ç­–ç•¥
- [ ] å¤šçº§ç¼“å­˜ç³»ç»Ÿ
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§

### ç¬¬3-4å‘¨ï¼šP2é«˜çº§åŠŸèƒ½
- [ ] A/Bæµ‹è¯•æ¡†æ¶
- [ ] æ‰§è¡Œè¿½è¸ªå›æ”¾
- [ ] å¤šç»´åº¦å­¦ä¹ 
- [ ] è°ƒè¯•æ§åˆ¶å°
- [ ] ç”¨æˆ·åå¥½ç³»ç»Ÿ

### ç¬¬5-8å‘¨ï¼šP3æœªæ¥æ‰©å±•
- [ ] æœåŠ¡åŒ–æ¶æ„æ‹†åˆ†
- [ ] é«˜çº§å¯è§†åŒ–å·¥å…·
- [ ] è‡ªåŠ¨ä¼˜åŒ–å¼•æ“
- [ ] ç”Ÿäº§éªŒè¯
- [ ] æ–‡æ¡£å’ŒåŸ¹è®­

---

## ğŸ¯ é¢„æœŸæ”¶ç›Š

### æŠ€æœ¯æŒ‡æ ‡
| æŒ‡æ ‡ | å½“å‰ | æ”¹è¿›å | æå‡ |
|------|------|--------|------|
| è·¯ç”±å‡†ç¡®ç‡ | 70% | 85-90% | +20% |
| å“åº”å»¶è¿Ÿ | 2s | 0.8s | -60% |
| åä½œæˆåŠŸç‡ | 75% | 90% | +20% |
| è°ƒè¯•æ•ˆç‡ | åŸºç¡€ | é«˜æ•ˆ | +70% |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | 70% | æ–°å¢ |
| æ¢ç´¢è¦†ç›–ç‡ | 30% | 80% | +170% |

### ä¸šåŠ¡æŒ‡æ ‡
| æŒ‡æ ‡ | å½“å‰ | æ”¹è¿›å | æå‡ |
|------|------|--------|------|
| ç”¨æˆ·æ»¡æ„åº¦ | 7.5/10 | 9.0/10 | +20% |
| ç³»ç»Ÿå¯ç”¨æ€§ | 99% | 99.9% | +0.9% |
| è¿ç»´æˆæœ¬ | é«˜ | ä¸­ | -50% |
| å¼€å‘æ•ˆç‡ | ä¸­ | é«˜ | +40% |
| é—®é¢˜å®šä½æ—¶é—´ | 30min | 5min | -83% |

### æ¶æ„æŒ‡æ ‡
| æŒ‡æ ‡ | å½“å‰ | æ”¹è¿›å | å˜åŒ– |
|------|------|--------|------|
| æ‰©å±•æ€§ | 10 Agents | 100+ Agents | +10x |
| å¯è§‚æµ‹æ€§ | åŸºç¡€ç›‘æ§ | ä¼ä¸šçº§ | è´¨å˜ |
| å¯ç»´æŠ¤æ€§ | ä¸­ç­‰ | é«˜ | æ¨¡å—åŒ– |
| å¯è¿›åŒ–æ€§ | æ‰‹åŠ¨ | è‡ªåŠ¨ | æ–°å¢ |

---

## ğŸ’° èµ„æºéœ€æ±‚

### äººåŠ›æŠ•å…¥
| è§’è‰² | æŠ•å…¥æ¯”ä¾‹ | ä¸»è¦ä»»åŠ¡ |
|------|----------|----------|
| æ¶æ„å¸ˆ | 20% | æ¶æ„è®¾è®¡ã€æŠ€æœ¯é€‰å‹ |
| åç«¯å¼€å‘ | 40% | æ ¸å¿ƒåŠŸèƒ½å®ç° |
| å‰ç«¯å¼€å‘ | 20% | å¯è§†åŒ–ç•Œé¢ |
| è¿ç»´å·¥ç¨‹å¸ˆ | 20% | åŸºç¡€è®¾æ–½ã€ç›‘æ§ |

### åŸºç¡€è®¾æ–½
| ç»„ä»¶ | é…ç½® | æ•°é‡ | ç”¨é€” |
|------|------|------|------|
| Redis | 4GBå†…å­˜ | 3èŠ‚ç‚¹ | ç¼“å­˜ã€çŠ¶æ€ã€æ¶ˆæ¯é˜Ÿåˆ— |
| PostgreSQL | 2æ ¸4GB | 1å®ä¾‹ | æŒä¹…åŒ–å­˜å‚¨ |
| Prometheus | 2æ ¸2GB | 1å®ä¾‹ | æŒ‡æ ‡æ”¶é›† |
| Grafana | 1æ ¸1GB | 1å®ä¾‹ | å¯è§†åŒ– |
| WebSocketæœåŠ¡å™¨ | 2æ ¸4GB | 2å®ä¾‹ | å®æ—¶æ¨é€ |
| åº”ç”¨æœåŠ¡å™¨ | 4æ ¸8GB | 3-5å®ä¾‹ | æœåŠ¡è¿è¡Œ |

### æ—¶é—´æŠ•å…¥
| é˜¶æ®µ | å‘¨æ•° | äººå¤© | äº§å‡º |
|------|------|------|------|
| P0æ ¸å¿ƒ | 1å‘¨ | 15äººå¤© | ç”Ÿäº§å°±ç»ª |
| P1ä½“éªŒ | 1å‘¨ | 15äººå¤© | ç”¨æˆ·ä½“éªŒæå‡ |
| P2é«˜çº§ | 2å‘¨ | 30äººå¤© | é«˜çº§åŠŸèƒ½ |
| P3æ‰©å±• | 4å‘¨ | 60äººå¤© | æœåŠ¡åŒ–æ¶æ„ |
| æµ‹è¯•ä¼˜åŒ– | 1å‘¨ | 15äººå¤© | ç”Ÿäº§éªŒè¯ |
| **æ€»è®¡** | **9å‘¨** | **135äººå¤©** | **å®Œæ•´ç³»ç»Ÿ** |

---

## ğŸ‰ æ€»ç»“

### å½“å‰ç³»ç»Ÿè¯„ä¼°

**ä¼˜åŠ¿**:
- âœ… æ¶æ„è®¾è®¡æ­£ç¡®ï¼ˆå“‘ç½‘å…³+èƒ–æ ¸å¿ƒï¼‰
- âœ… Statechartså¼•æ“åŠŸèƒ½å®Œæ•´
- âœ… åŸºç¡€è·¯ç”±å’Œå­¦ä¹ å·²å®ç°
- âœ… ç”Ÿäº§ç‰¹æ€§å…·å¤‡ï¼ˆæŒä¹…åŒ–ã€é”ã€å¹‚ç­‰æ€§ï¼‰

**æ”¹è¿›æœºä¼š**:
- âš ï¸ å­¦ä¹ çŠ¶æ€æ— æŒä¹…åŒ–
- âš ï¸ è·¯ç”±ç­–ç•¥å•ä¸€
- âš ï¸ å¯è§‚æµ‹æ€§ä¸è¶³
- âš ï¸ è°ƒè¯•å·¥å…·ç®€é™‹
- âš ï¸ æ— è‡ªåŠ¨ä¼˜åŒ–

### æ”¹è¿›æ–¹æ¡ˆä»·å€¼

**æŠ€æœ¯ä»·å€¼**:
1. **ç³»ç»Ÿæ™ºèƒ½åŒ–**: ä»é™æ€è§„åˆ™åˆ°è‡ªé€‚åº”å­¦ä¹ 
2. **å¯è§‚æµ‹æ€§**: ä»é»‘ç›’åˆ°å…¨é“¾è·¯é€æ˜
3. **æ€§èƒ½ä¼˜åŒ–**: ä»é‡å¤è®¡ç®—åˆ°æ™ºèƒ½ç¼“å­˜
4. **å¼€å‘æ•ˆç‡**: ä»æ‰‹åŠ¨è°ƒè¯•åˆ°è‡ªåŠ¨è¯Šæ–­

**ä¸šåŠ¡ä»·å€¼**:
1. **ç”¨æˆ·ä½“éªŒ**: æ›´å¿«ã€æ›´å‡†ã€æ›´æ™ºèƒ½
2. **è¿ç»´æˆæœ¬**: è‡ªåŠ¨åŒ–å‡å°‘äººå·¥å¹²é¢„
3. **ç³»ç»Ÿç¨³å®š**: ç”Ÿäº§çº§å¯é æ€§å’Œå®¹é”™
4. **æŒç»­è¿›åŒ–**: æ•°æ®é©±åŠ¨çš„è‡ªæˆ‘ä¼˜åŒ–

### å…³é”®æˆåŠŸå› ç´ 

1. **åˆ†é˜¶æ®µå®æ–½**: ä»P0åˆ°P3ï¼Œé£é™©å¯æ§
2. **æ•°æ®é©±åŠ¨**: A/Bæµ‹è¯•éªŒè¯æ¯ä¸ªæ”¹è¿›
3. **å¯è§‚æµ‹æ€§**: å…¨é¢çš„ç›‘æ§å’Œè¿½è¸ª
4. **è‡ªåŠ¨åŒ–**: å‡å°‘äººå·¥å¹²é¢„
5. **å›¢é˜Ÿåä½œ**: æ¶æ„ã€å¼€å‘ã€è¿ç»´ç´§å¯†é…åˆ

### é¢„æœŸæˆæœ

**8å‘¨åï¼ŒSparkleå°†æˆä¸º**:
- ğŸš€ **é«˜æ€§èƒ½**: å»¶è¿Ÿé™ä½60%ï¼Œååé‡æå‡
- ğŸ§  **æ™ºèƒ½åŒ–**: è‡ªé€‚åº”å­¦ä¹ ï¼Œè‡ªåŠ¨ä¼˜åŒ–
- ğŸ‘ï¸ **å¯è§‚æµ‹**: å…¨é“¾è·¯è¿½è¸ªï¼Œå®æ—¶å¯è§†åŒ–
- ğŸ› ï¸ **æ˜“è°ƒè¯•**: ä¸€ç«™å¼è°ƒè¯•æ§åˆ¶å°
- ğŸ“Š **æ•°æ®é©±åŠ¨**: ç§‘å­¦å†³ç­–ï¼ŒæŒç»­æ”¹è¿›
- ğŸ”§ **å¯æ‰©å±•**: å¾®æœåŠ¡æ¶æ„ï¼Œç‹¬ç«‹éƒ¨ç½²

---

**éœ€è¦æˆ‘å¼€å§‹å®æ–½å…·ä½“çš„æ”¹è¿›æ–¹æ¡ˆå—ï¼Ÿè¯·å‘Šè¯‰æˆ‘æ‚¨å¸Œæœ›ä»å“ªä¸ªéƒ¨åˆ†å¼€å§‹ï¼ˆP0/P1/P2/P3ï¼‰ï¼Œæˆ‘å¯ä»¥æä¾›è¯¦ç»†çš„ä»£ç å®ç°å’Œéƒ¨ç½²æ­¥éª¤ã€‚**
