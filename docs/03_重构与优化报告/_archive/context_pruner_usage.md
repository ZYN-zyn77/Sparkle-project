# ContextPruner ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

ContextPruner æ˜¯ Phase 3 çš„æ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºç®¡ç†å’Œä¼˜åŒ– LLM ä¸Šä¸‹æ–‡çª—å£ï¼Œé˜²æ­¢ Token çˆ†ç‚¸å’Œä¸Šä¸‹æ–‡æº¢å‡ºã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. æ»‘åŠ¨çª—å£ (Sliding Window)
- **ç­–ç•¥**: åªä¿ç•™æœ€è¿‘ N è½®å¯¹è¯ï¼ˆé»˜è®¤ 10 è½®ï¼‰
- **é€‚ç”¨**: å†å²è®°å½•åœ¨ `max_history` å’Œ `summary_threshold` ä¹‹é—´
- **æ•ˆæœ**: å‡å°‘ Token ä½¿ç”¨ï¼Œä¿ç•™æœ€æ–°ä¸Šä¸‹æ–‡

### 2. æ™ºèƒ½æ€»ç»“ (Summarization)
- **ç­–ç•¥**: è¶…è¿‡é˜ˆå€¼æ—¶è§¦å‘å¼‚æ­¥æ€»ç»“ï¼Œç”Ÿæˆå‰æƒ…æè¦
- **é€‚ç”¨**: å†å²è®°å½•è¶…è¿‡ `summary_threshold`ï¼ˆé»˜è®¤ 20 è½®ï¼‰
- **æ•ˆæœ**: å¤§å¹…å‡å°‘ Tokenï¼ŒåŒæ—¶ä¿ç•™æ ¸å¿ƒä¿¡æ¯

### 3. ç¼“å­˜æœºåˆ¶
- æ€»ç»“ç»“æœç¼“å­˜ 1 å°æ—¶
- é¿å…é‡å¤è°ƒç”¨ LLM
- æ”¯æŒç¼“å­˜å¤±æ•ˆ

## ğŸ“Š å·¥ä½œæµç¨‹

```
ç”¨æˆ·è¯·æ±‚
    â†“
Orchestrator.process_stream()
    â†“
Step 5: Build User Context (UserService + Redis Cache)
    â†“
Step 6: Build Conversation Context (ContextPruner)
    â†“
    â”œâ”€ ä» Redis åŠ è½½èŠå¤©å†å²
    â”œâ”€ åˆ¤æ–­å†å²é•¿åº¦
    â”‚   â”œâ”€ â‰¤ 10 æ¡: ç›´æ¥è¿”å›
    â”‚   â”œâ”€ 10-20 æ¡: æ»‘åŠ¨çª—å£
    â”‚   â””â”€ > 20 æ¡: è§¦å‘æ€»ç»“ + æ»‘åŠ¨çª—å£
    â†“
Step 8: Build Prompt (åŒ…å«ä¿®å‰ªåçš„å†å²)
    â†“
LLM è°ƒç”¨
```

## ğŸ”§ é…ç½®å‚æ•°

### ContextPruner åˆå§‹åŒ–

```python
from app.orchestration.context_pruner import ContextPruner

context_pruner = ContextPruner(
    redis_client=redis_client,
    max_history_messages=10,      # æ»‘åŠ¨çª—å£ä¿ç•™çš„æ¶ˆæ¯æ•°
    summary_threshold=20,         # è§¦å‘æ€»ç»“çš„é˜ˆå€¼
    summary_cache_ttl=3600        # æ€»ç»“ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰
)
```

### æ¨èé…ç½®

| åœºæ™¯ | max_history | summary_threshold | è¯´æ˜ |
|------|-------------|-------------------|------|
| **ä½é¢‘å¯¹è¯** | 10 | 20 | é»˜è®¤é…ç½®ï¼Œå¹³è¡¡æ€§èƒ½ä¸ä¸Šä¸‹æ–‡ |
| **é«˜é¢‘çŸ­å¯¹è¯** | 5 | 15 | æ›´æ¿€è¿›çš„å‹ç¼© |
| **æ·±åº¦å¯¹è¯** | 15 | 30 | ä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡ |
| **æˆæœ¬æ•æ„Ÿ** | 5 | 10 | æœ€å¤§é™åº¦å‡å°‘ Token |

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨

```python
# åœ¨ Orchestrator ä¸­ä½¿ç”¨
async def process_stream(self, request, db_session, context_data):
    # ...

    # è·å–ä¿®å‰ªåçš„å†å²
    conversation_context = await self.context_pruner.get_pruned_history(
        session_id=session_id,
        user_id=user_id
    )

    # æ„å»ºæç¤º
    prompt = build_system_prompt(
        user_context_data,
        conversation_history=conversation_context
    )

    # ...
```

### ç¤ºä¾‹ 2: æ‰‹åŠ¨è§¦å‘æ€»ç»“

```python
# å¼ºåˆ¶è§¦å‘æ€»ç»“ï¼ˆå³ä½¿æœªè¾¾åˆ°é˜ˆå€¼ï¼‰
pruned = await context_pruner.get_pruned_history(
    session_id="session_123",
    user_id="user_456",
    force_summary=True
)
```

### ç¤ºä¾‹ 3: æ£€æŸ¥æ€»ç»“çŠ¶æ€

```python
status = await context_pruner.get_summary_status("session_123")
# è¿”å›: {"has_summary": True, "ttl_seconds": 3500, "summary_preview": "..."}
```

### ç¤ºä¾‹ 4: æ¸…é™¤æ€»ç»“ç¼“å­˜

```python
await context_pruner.clear_summary("session_123")
```

## ğŸ”„ åå°æ€»ç»“æœåŠ¡

### å¯åŠ¨ SummarizationWorker

**æ–¹å¼ 1: ä½œä¸ºç‹¬ç«‹è¿›ç¨‹**

```bash
python -m app.orchestration.summarization_worker
```

**æ–¹å¼ 2: åœ¨ä¸»åº”ç”¨ä¸­å¯åŠ¨**

```python
from app.orchestration.summarization_worker import SummarizationWorker
import asyncio

async def start_background_workers():
    worker = SummarizationWorker(redis_client, worker_id="main")
    asyncio.create_task(worker.start())

# åœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨
await start_background_workers()
```

**æ–¹å¼ 3: ä½¿ç”¨ Supervisor æˆ– Systemd**

```ini
# supervisord é…ç½®
[program:summarization_worker]
command=python -m app.orchestration.summarization_worker
directory=/path/to/project
autostart=true
autorestart=true
numprocs=2  # å¯åŠ¨ 2 ä¸ª worker æé«˜å¹¶å‘
```

### Worker é…ç½®

```python
worker = SummarizationWorker(
    redis_client,
    batch_size=10,      # æ¯æ¬¡æ‰¹é‡å¤„ç†çš„ä»»åŠ¡æ•°
    max_retries=3,      # å¤±è´¥é‡è¯•æ¬¡æ•°
    worker_id="worker-1"
)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### Token ä½¿ç”¨é‡å¯¹æ¯”

| åœºæ™¯ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | èŠ‚çœ |
|------|--------|--------|------|
| 5 è½®å¯¹è¯ | ~500 tokens | ~500 tokens | 0% |
| 15 è½®å¯¹è¯ | ~1500 tokens | ~800 tokens | 47% |
| 50 è½®å¯¹è¯ | ~5000 tokens | ~1200 tokens | 76% |
| 100 è½®å¯¹è¯ | ~10000 tokens | ~1500 tokens | 85% |

### å“åº”æ—¶é—´

- **ContextPruner å¼€é”€**: < 5ms (Redis æŸ¥è¯¢)
- **æ€»ç»“ä»»åŠ¡**: å¼‚æ­¥æ‰§è¡Œï¼Œä¸å½±å“ä¸»æµç¨‹
- **ç¼“å­˜å‘½ä¸­**: < 1ms

## ğŸ” ç›‘æ§æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

```python
# 1. å†å²å‹ç¼©ç‡
compression_rate = (original - pruned) / original

# 2. æ€»ç»“ä½¿ç”¨ç‡
summary_usage_rate = summary_used_count / total_requests

# 3. ç¼“å­˜å‘½ä¸­ç‡
cache_hit_rate = cache_hits / (cache_hits + cache_misses)
```

### æ—¥å¿—è¾“å‡ºç¤ºä¾‹

```
INFO: ChatOrchestrator initialized with ContextPruner
DEBUG: Session session_123: 15 messages -> pruned to 5 + summary, took 0.003s
INFO: Triggered summarization task for session session_123, history size: 10
INFO: Processing summarization task for session session_123, history size: 10, priority: high
INFO: âœ… Summary generated for session session_123 (attempt 1/3)
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: æ€»ç»“ä»»åŠ¡ç§¯å‹æ€ä¹ˆåŠï¼Ÿ

**é—®é¢˜**: é˜Ÿåˆ—ä¸­ä»»åŠ¡è¿‡å¤šï¼ŒRedis å†…å­˜å ç”¨é«˜

**è§£å†³**:
```python
# 1. å¢åŠ  Worker æ•°é‡
worker_count = 3  # å¯åŠ¨å¤šä¸ª worker

# 2. è°ƒæ•´æ€»ç»“é˜ˆå€¼
context_pruner = ContextPruner(..., summary_threshold=30)  # æ›´é«˜çš„é˜ˆå€¼

# 3. ç›‘æ§é˜Ÿåˆ—é•¿åº¦
queue_len = await redis.llen("queue:summarization")
if queue_len > 1000:
    # è§¦å‘å‘Šè­¦æˆ–æ‰©å®¹
    pass
```

### Q2: æ€»ç»“è´¨é‡ä¸ä½³ï¼Ÿ

**é—®é¢˜**: LLM ç”Ÿæˆçš„æ€»ç»“ä¸¢å¤±é‡è¦ä¿¡æ¯

**è§£å†³**:
```python
# 1. è°ƒæ•´æ€»ç»“æç¤ºè¯ï¼ˆä¿®æ”¹ summarization_worker.pyï¼‰
# 2. å¢åŠ ä¿ç•™çš„æ¶ˆæ¯æ•°
context_pruner = ContextPruner(..., max_history_messages=15)

# 3. æ‰‹åŠ¨å®¡æ ¸æ€»ç»“ï¼ˆå¼€å‘é˜¶æ®µï¼‰
```

### Q3: ç¼“å­˜ä¸€è‡´æ€§é—®é¢˜ï¼Ÿ

**é—®é¢˜**: ç”¨æˆ·æ›´æ–°èµ„æ–™åï¼Œç¼“å­˜æœªå¤±æ•ˆ

**è§£å†³**:
```python
# åœ¨ UserService ä¸­å·²å®ç°
await user_service.invalidate_user_cache(user_id)
```

### Q4: å¦‚ä½•è°ƒè¯•ï¼Ÿ

**è°ƒè¯•æ¨¡å¼**:
```python
# 1. æŸ¥çœ‹åŸå§‹å†å²
history = await context_pruner._load_chat_history(session_id)
print(f"åŸå§‹å†å²: {len(history)} æ¡")

# 2. æŸ¥çœ‹ä¿®å‰ªç»“æœ
result = await context_pruner.get_pruned_history(session_id, user_id)
print(f"ä¿®å‰ªç»“æœ: {result}")

# 3. æŸ¥çœ‹æ€»ç»“çŠ¶æ€
status = await context_pruner.get_summary_status(session_id)
print(f"æ€»ç»“çŠ¶æ€: {status}")
```

## ğŸš€ éƒ¨ç½²å»ºè®®

### å¼€å‘ç¯å¢ƒ

```bash
# å¯åŠ¨ Redis
docker run -d -p 6379:6379 redis:7-alpine

# å¯åŠ¨ SummarizationWorker
python -m app.orchestration.summarization_worker
```

### ç”Ÿäº§ç¯å¢ƒ

```bash
# 1. Redis é›†ç¾¤ï¼ˆé«˜å¯ç”¨ï¼‰
# 2. å¤šä¸ª Worker å®ä¾‹ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
# 3. ç›‘æ§å‘Šè­¦ï¼ˆPrometheus + Grafanaï¼‰
# 4. æ—¥å¿—æ”¶é›†ï¼ˆELK Stackï¼‰
```

### Docker Compose ç¤ºä¾‹

```yaml
version: '3.8'
services:
  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]

  summarization-worker:
    build: .
    command: python -m app.orchestration.summarization_worker
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    deploy:
      replicas: 2  # 2 ä¸ªå®ä¾‹
```

## ğŸ“ æ€»ç»“

ContextPruner é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¼˜åŒ– LLM ä¸Šä¸‹æ–‡ï¼š

1. âœ… **è‡ªåŠ¨ä¿®å‰ª**: æ ¹æ®å†å²é•¿åº¦è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
2. âœ… **å¼‚æ­¥æ€»ç»“**: ä¸é˜»å¡ä¸»æµç¨‹
3. âœ… **æ™ºèƒ½ç¼“å­˜**: é¿å…é‡å¤è®¡ç®—
4. âœ… **å¯é…ç½®**: çµæ´»è°ƒæ•´å‚æ•°
5. âœ… **å¯è§‚æµ‹**: å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§

**é¢„æœŸæ•ˆæœ**: Token ä½¿ç”¨é‡å‡å°‘ 50-85%ï¼Œå“åº”æ—¶é—´å¢åŠ  < 5msï¼Œæ•°æ®åº“æŸ¥è¯¢å‡å°‘ 70%+ã€‚
