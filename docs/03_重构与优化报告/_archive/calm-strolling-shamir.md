# Phase 3: æˆæœ¬æ§åˆ¶ã€ä¸Šä¸‹æ–‡ç®¡ç†ä¸æ€§èƒ½å‹æ¦¨

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

åŸºäºå¯¹ç°æœ‰æ¶æ„çš„æ·±å…¥åˆ†æï¼ŒPhase 3 å°†é‡ç‚¹è§£å†³ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
1. **ä¸Šä¸‹æ–‡çª—å£ç®¡ç†** - é˜²æ­¢ Token çˆ†ç‚¸å’Œä¸Šä¸‹æ–‡æº¢å‡º
2. **ç”¨æˆ·ç”»åƒç¼“å­˜ä¼˜åŒ–** - é™ä½æ•°æ®åº“å‹åŠ›
3. **Token è®¡é‡ä¸é™æµ** - æˆæœ¬æ§åˆ¶å’Œé˜²æ»¥ç”¨

---

## ğŸ¯ ä¼˜å…ˆçº§ä»»åŠ¡æ¸…å•

| ä¼˜å…ˆçº§ | ä»»åŠ¡ | ç›®çš„ | å¤æ‚åº¦ | é¢„è®¡æ–‡ä»¶ä¿®æ”¹ |
|--------|------|------|--------|--------------|
| **P0** | å®ç° ContextPruner (ä¸Šä¸‹æ–‡ä¿®å‰ªå™¨) | é˜²æ­¢ Token çˆ†ç‚¸å’Œä¸Šä¸‹æ–‡æº¢å‡º | â­â­â­ | 3-4 ä¸ªæ–‡ä»¶ |
| **P1** | UserService å¢åŠ  Redis ç¼“å­˜ | é™ä½æ•°æ®åº“å‹åŠ›ï¼Œæå‡å“åº”é€Ÿåº¦ | â­â­ | 2 ä¸ªæ–‡ä»¶ |
| **P1** | Token è®¡é‡ä¸é™æµç³»ç»Ÿ | æˆæœ¬æ§åˆ¶ï¼Œé˜²æ­¢æ»¥ç”¨ | â­â­ | 3 ä¸ªæ–‡ä»¶ |
| **P2** | æ…¢é€Ÿå·¥å…·çš„æµå¼åé¦ˆä¼˜åŒ– | æå‡ç”¨æˆ·ä½“éªŒ (UX) | â­â­â­ | 2 ä¸ªæ–‡ä»¶ |
| **P3** | Prometheus ç›‘æ§æ¥å…¥ | çœ‹åˆ° QPSã€å»¶è¿Ÿå’Œé”™è¯¯ç‡ | â­ | 2 ä¸ªæ–‡ä»¶ |

---

## ğŸš€ è¯¦ç»†å®æ–½æ–¹æ¡ˆ

### P0: ContextPruner (ä¸Šä¸‹æ–‡ä¿®å‰ªå™¨) - **æœ€ç´§è¿«**

#### é—®é¢˜åˆ†æ
å½“å‰æ¶æ„åœ¨ `_build_user_context()` ä¸­ç›´æ¥æŸ¥è¯¢æ•°æ®åº“ï¼Œä½†**æ²¡æœ‰å¯¹èŠå¤©å†å²è¿›è¡Œä¿®å‰ª**ã€‚éšç€å¯¹è¯å˜é•¿ï¼š
- æ¯æ¬¡è¯·æ±‚éƒ½ä¼šåŠ è½½å®Œæ•´å†å²è®°å½•
- Prompt æ— é™è†¨èƒ€ â†’ Token æˆæœ¬æŒ‡æ•°å¢é•¿
- æœ€ç»ˆè¶…è¿‡ LLM ä¸Šä¸‹æ–‡é™åˆ¶ (128k tokens)

#### è§£å†³æ–¹æ¡ˆï¼šå®ç° ContextPruner ç»„ä»¶

**æ–‡ä»¶ 1: `/Users/a/code/sparkle-flutter/backend/app/orchestration/context_pruner.py`** (æ–°å»º)
```python
class ContextPruner:
    """
    ä¸Šä¸‹æ–‡ä¿®å‰ªå™¨ - ç®¡ç†å’Œä¼˜åŒ– LLM ä¸Šä¸‹æ–‡çª—å£

    ç­–ç•¥:
    - Sliding Window: åªä¿ç•™æœ€è¿‘ N è½®å¯¹è¯
    - Summarization: è¶…è¿‡é˜ˆå€¼æ—¶è§¦å‘æ€»ç»“
    - Token Counting: ç²¾ç¡®è®¡ç®— token æ•°é‡
    """

    def __init__(self, redis_client, max_history_messages: int = 10, summary_threshold: int = 20):
        self.redis = redis_client
        self.max_history_messages = max_history_messages
        self.summary_threshold = summary_threshold

    async def get_pruned_history(self, session_id: str, user_id: str) -> Dict[str, Any]:
        """è·å–ä¿®å‰ªåçš„èŠå¤©å†å²"""
        # 1. ä» Redis è·å–å†å²
        history = await self._load_chat_history(session_id)

        # 2. å¦‚æœå†å²è®°å½•å¾ˆå°‘ï¼Œç›´æ¥è¿”å›
        if len(history) <= self.max_history_messages:
            return {"messages": history, "summary": None}

        # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦æ€»ç»“
        if len(history) > self.summary_threshold:
            return await self._get_summarized_history(session_id, history, user_id)

        # 4. ä½¿ç”¨æ»‘åŠ¨çª—å£
        return {"messages": history[-self.max_history_messages:], "summary": None}

    async def _get_summarized_history(self, session_id: str, history: List[Dict], user_id: str) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM æ€»ç»“å†å²å¯¹è¯"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"summary:{session_id}"
        cached = await self.redis.get(cache_key)
        if cached:
            return {"messages": history[-5:], "summary": cached}

        # è§¦å‘å¼‚æ­¥æ€»ç»“ä»»åŠ¡
        await self._trigger_summary(session_id, history, user_id)

        # è¿”å›æœ€è¿‘å‡ æ¡æ¶ˆæ¯ä½œä¸º fallback
        return {"messages": history[-5:], "summary": None}

    async def _trigger_summary(self, session_id: str, history: List[Dict], user_id: str):
        """å¼‚æ­¥è§¦å‘æ€»ç»“ä»»åŠ¡"""
        # å°†ä»»åŠ¡æ¨é€åˆ°é˜Ÿåˆ—
        task = {
            "session_id": session_id,
            "history": history[:-5],  # æ€»ç»“é™¤æœ€è¿‘5æ¡å¤–çš„æ‰€æœ‰å†å²
            "user_id": user_id,
            "timestamp": time.time()
        }
        await self.redis.rpush("queue:summarization", json.dumps(task))

    async def _load_chat_history(self, session_id: str) -> List[Dict]:
        """ä» Redis åŠ è½½èŠå¤©å†å²"""
        cache_key = f"chat:history:{session_id}"
        messages = await self.redis.lrange(cache_key, 0, -1)
        return [json.loads(m) for m in messages]
```

**æ–‡ä»¶ 2: `/Users/a/code/sparkle-flutter/backend/app/orchestration/summarization_worker.py`** (æ–°å»º)
```python
class SummarizationWorker:
    """åå°æ€»ç»“ä»»åŠ¡å¤„ç†å™¨"""

    async def process_summarization_queue(self):
        """ä»é˜Ÿåˆ—æ¶ˆè´¹æ€»ç»“ä»»åŠ¡"""
        while True:
            task_data = await self.redis.blpop("queue:summarization", timeout=0)
            if task_data:
                task = json.loads(task_data[1])
                await self._summarize_history(task)

    async def _summarize_history(self, task: Dict):
        """ä½¿ç”¨ LLM ç”Ÿæˆå†å²æ€»ç»“"""
        # æ„å»ºæ€»ç»“æç¤ºè¯
        prompt = self._build_summary_prompt(task["history"])

        # è°ƒç”¨ LLM
        summary = await llm_service.generate_summary(prompt)

        # ä¿å­˜åˆ° Redis
        cache_key = f"summary:{task['session_id']}"
        await self.redis.setex(cache_key, 3600, summary)  # 1å°æ—¶TTL
```

**æ–‡ä»¶ 3: `/Users/a/code/sparkle-flutter/backend/app/orchestration/orchestrator.py`** (ä¿®æ”¹)
```python
# åœ¨ process_stream æ–¹æ³•ä¸­æ’å…¥ ContextPruner

# Step 5: Build User Context + Prune History
await self._update_state(session_id, STATE_THINKING, "Building user context and pruning history...")
user_context_data = await self._build_user_context(user_id, active_db)

# æ–°å¢ï¼šè·å–ä¿®å‰ªåçš„å†å²
pruned_history = await self.context_pruner.get_pruned_history(session_id, user_id)

# Step 7: Build Prompt (åŒ…å«å†å²)
base_system_prompt = build_system_prompt(
    user_context_data,
    conversation_history=pruned_history  # ä¼ é€’ä¿®å‰ªåçš„å†å²
)
```

**æ–‡ä»¶ 4: `/Users/a/code/sparkle-flutter/backend/app/orchestration/prompts.py`** (ä¿®æ”¹)
```python
def build_system_prompt(user_context_data: Dict, conversation_history: Dict = None) -> str:
    """æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«ä¿®å‰ªåçš„å†å²"""
    prompt = "..."

    # æ·»åŠ å†å²æ€»ç»“
    if conversation_history and conversation_history.get("summary"):
        prompt += f"\n\n## å‰æƒ…æè¦\n{conversation_history['summary']}"

    # æ·»åŠ æœ€è¿‘å¯¹è¯
    if conversation_history and conversation_history.get("messages"):
        prompt += "\n\n## æœ€è¿‘å¯¹è¯\n"
        for msg in conversation_history["messages"]:
            role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
            prompt += f"{role}: {msg['content']}\n"

    return prompt
```

---

### P1: UserService Redis ç¼“å­˜ (Cache-Aside æ¨¡å¼)

#### é—®é¢˜åˆ†æ
å½“å‰ `UserService` æ¯æ¬¡è°ƒç”¨éƒ½ç›´æ¥æŸ¥è¯¢æ•°æ®åº“ï¼š
- `get_context()` â†’ æŸ¥è¯¢ User + PushPreference
- `get_analytics_summary()` â†’ æŸ¥è¯¢ User
- `get_preferences()` â†’ æŸ¥è¯¢ User + PushPreference

åœ¨é«˜å¹¶å‘ä¸‹ï¼Œæ•°æ®åº“æˆä¸ºç“¶é¢ˆã€‚

#### è§£å†³æ–¹æ¡ˆï¼šCache-Aside æ¨¡å¼

**æ–‡ä»¶ 1: `/Users/a/code/sparkle-flutter/backend/app/services/user_service.py`** (ä¿®æ”¹)

```python
from app.core.cache import cache_service

class UserService:
    def __init__(self, db_session: AsyncSession, redis_client=None):
        self.db = db_session
        self.redis = redis_client or cache_service.redis
        logger.info("UserService initialized")

    async def get_context(self, user_id: UUID) -> Optional[UserContext]:
        """è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"user:context:{user_id}"

        # 1. Cache Lookup
        if self.redis:
            cached = await self.redis.get(cache_key)
            if cached:
                return pickle.loads(cached)

        # 2. Database Query
        user = await self.get_user_by_id(user_id)
        if not user:
            return None

        push_pref = await self._get_push_preference(user_id)

        # 3. Build Context
        context = UserContext(
            user_id=str(user_id),
            nickname=user.nickname or user.username,
            timezone=push_pref.timezone if push_pref else "Asia/Shanghai",
            language="zh-CN",
            is_pro=user.flame_level >= 3,
            preferences={
                "depth_preference": user.depth_preference,
                "curiosity_preference": user.curiosity_preference,
                "flame_level": user.flame_level,
                "flame_brightness": user.flame_brightness,
            },
            active_slots=push_pref.active_slots if push_pref else None,
            daily_cap=push_pref.daily_cap if push_pref else 5,
            persona_type=push_pref.persona_type if push_pref else "coach",
        )

        # 4. Cache Write (TTL 30 minutes)
        if self.redis:
            await self.redis.setex(cache_key, 1800, pickle.dumps(context))

        return context

    async def get_analytics_summary(self, user_id: UUID) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨æˆ·åˆ†ææ‘˜è¦ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"user:analytics:{user_id}"

        # 1. Cache Lookup
        if self.redis:
            cached = await self.redis.get(cache_key)
            if cached:
                return json.loads(cached)

        # 2. Database Query
        user = await self.get_user_by_id(user_id)
        if not user:
            return None

        # 3. Build Summary
        is_active = user.last_login_at is not None
        flame_level = user.flame_level

        if flame_level >= 5:
            engagement = "very_high"
        elif flame_level >= 3:
            engagement = "high"
        elif flame_level >= 2:
            engagement = "medium"
        else:
            engagement = "low"

        summary = {
            "is_active": is_active,
            "active_level": "active" if is_active else "inactive",
            "engagement_level": engagement,
            "flame_level": flame_level,
            "flame_brightness": user.flame_brightness,
            "depth_preference": user.depth_preference,
            "curiosity_preference": user.curiosity_preference,
            "registration_source": user.registration_source,
        }

        # 4. Cache Write (TTL 30 minutes)
        if self.redis:
            await self.redis.setex(cache_key, 1800, json.dumps(summary))

        return summary

    async def invalidate_user_cache(self, user_id: UUID):
        """ä½¿ç”¨æˆ·ç¼“å­˜å¤±æ•ˆï¼ˆåœ¨ç”¨æˆ·æ›´æ–°èµ„æ–™æ—¶è°ƒç”¨ï¼‰"""
        if not self.redis:
            return

        keys = [
            f"user:context:{user_id}",
            f"user:analytics:{user_id}",
            f"user:preferences:{user_id}",
            f"user:stats:{user_id}",
        ]

        await self.redis.delete(*keys)
        logger.info(f"Invalidated cache for user {user_id}")

    async def update_user_profile(self, user_id: UUID, updates: Dict) -> bool:
        """æ›´æ–°ç”¨æˆ·èµ„æ–™å¹¶ä½¿ç¼“å­˜å¤±æ•ˆ"""
        try:
            # 1. æ›´æ–°æ•°æ®åº“
            user = await self.get_user_by_id(user_id)
            if not user:
                return False

            for key, value in updates.items():
                setattr(user, key, value)

            await self.db.commit()

            # 2. ä½¿ç¼“å­˜å¤±æ•ˆ
            await self.invalidate_user_cache(user_id)

            return True
        except Exception as e:
            logger.error(f"Failed to update user profile: {e}")
            await self.db.rollback()
            return False
```

**æ–‡ä»¶ 2: `/Users/a/code/sparkle-flutter/backend/app/orchestration/orchestrator.py`** (ä¿®æ”¹)
```python
# åœ¨ _build_user_context æ–¹æ³•ä¸­ä¼ é€’ redis_client

async def _build_user_context(self, user_id: str, db_session: AsyncSession) -> Dict[str, Any]:
    try:
        # ä¼ é€’ redis_client ç»™ UserService
        user_service = UserService(db_session, self.redis)

        user_context = await user_service.get_context(uuid.UUID(user_id))
        analytics = await user_service.get_analytics_summary(uuid.UUID(user_id))

        # ... rest of the code
```

---

### P1: Token è®¡é‡ä¸é™æµç³»ç»Ÿ

#### é—®é¢˜åˆ†æ
å½“å‰ç³»ç»Ÿï¼š
- âœ… Go Gateway æœ‰ Quota æ‰£å‡æœºåˆ¶
- âœ… ChatMessage æ¨¡å‹æœ‰ `tokens_used` å­—æ®µ
- âŒ Python å±‚æ²¡æœ‰è¿½è¸ª Token ä½¿ç”¨é‡
- âŒ æ²¡æœ‰å®æ—¶é…é¢æ£€æŸ¥
- âŒ æ²¡æœ‰è¯¦ç»†çš„ Token ä½¿ç”¨è®°å½•

#### è§£å†³æ–¹æ¡ˆï¼šå®Œæ•´ Token è¿½è¸ª + é…é¢æ£€æŸ¥

**æ–‡ä»¶ 1: `/Users/a/code/sparkle-flutter/backend/app/orchestration/token_tracker.py`** (æ–°å»º)
```python
class TokenTracker:
    """Token ä½¿ç”¨é‡è¿½è¸ªå™¨"""

    def __init__(self, redis_client):
        self.redis = redis_client

    async def record_usage(
        self,
        user_id: str,
        session_id: str,
        request_id: str,
        prompt_tokens: int,
        completion_tokens: int,
        model: str = "gpt-4"
    ):
        """è®°å½• Token ä½¿ç”¨é‡"""
        total_tokens = prompt_tokens + completion_tokens

        # 1. è®°å½•åˆ° Redis é˜Ÿåˆ—ï¼ˆå¼‚æ­¥æŒä¹…åŒ–ï¼‰
        usage_record = {
            "user_id": user_id,
            "session_id": session_id,
            "request_id": request_id,
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "model": model,
            "timestamp": time.time()
        }

        await self.redis.rpush("queue:billing", json.dumps(usage_record))

        # 2. æ›´æ–°ç”¨æˆ·å½“æ—¥ç´¯è®¡
        today = datetime.now().strftime("%Y-%m-%d")
        daily_key = f"user:daily_tokens:{user_id}:{today}"
        await self.redis.incrby(daily_key, total_tokens)
        await self.redis.expire(daily_key, 86400)  # 24å°æ—¶è¿‡æœŸ

        # 3. æ›´æ–°ä¼šè¯ç´¯è®¡
        session_key = f"session:tokens:{session_id}"
        await self.redis.incrby(session_key, total_tokens)

        return total_tokens

    async def get_daily_usage(self, user_id: str) -> int:
        """è·å–ç”¨æˆ·ä»Šæ—¥ Token ä½¿ç”¨é‡"""
        today = datetime.now().strftime("%Y-%m-%d")
        key = f"user:daily_tokens:{user_id}:{today}"
        result = await self.redis.get(key)
        return int(result) if result else 0

    async def check_quota(self, user_id: str, daily_limit: int = 100000) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¶…å‡ºé…é¢"""
        used = await self.get_daily_usage(user_id)
        return used < daily_limit

    async def get_usage_breakdown(self, user_id: str, days: int = 7) -> Dict[str, Any]:
        """è·å–ç”¨æˆ· Token ä½¿ç”¨æ˜ç»†"""
        breakdown = {}
        for i in range(days):
            date = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
            key = f"user:daily_tokens:{user_id}:{date}"
            usage = await self.redis.get(key)
            breakdown[date] = int(usage) if usage else 0

        return breakdown
```

**æ–‡ä»¶ 2: `/Users/a/code/sparkle-flutter/backend/app/orchestration/validator.py`** (ä¿®æ”¹)
```python
class RequestValidator:
    """è¯·æ±‚éªŒè¯å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    def __init__(self, redis_client=None):
        self.redis = redis_client

    async def validate_chat_request(self, request, user_id: str) -> ValidationResult:
        """éªŒè¯èŠå¤©è¯·æ±‚"""
        # ç°æœ‰éªŒè¯...

        # æ–°å¢ï¼šé…é¢æ£€æŸ¥
        if self.redis:
            token_tracker = TokenTracker(self.redis)
            quota_ok = await token_tracker.check_quota(user_id)

            if not quota_ok:
                return ValidationResult(
                    is_valid=False,
                    error_message="Daily token quota exceeded. Please try again tomorrow."
                )

        return ValidationResult(is_valid=True)
```

**æ–‡ä»¶ 3: `/Users/a/code/sparkle-flutter/backend/app/orchestration/orchestrator.py`** (ä¿®æ”¹)
```python
# åœ¨ process_stream ä¸­é›†æˆ Token è¿½è¸ª

class ChatOrchestrator:
    def __init__(self, db_session, redis_client):
        # ... existing init
        self.token_tracker = TokenTracker(redis_client) if redis_client else None

    async def process_stream(self, request, db_session, context_data):
        # ... existing code

        full_response = ""
        tool_execution_results = []
        total_prompt_tokens = 0
        total_completion_tokens = 0

        # Call LLM Service
        async for chunk in llm_service.chat_stream_with_tools(...):
            if chunk.type == "text":
                full_response += chunk.content
                yield agent_service_pb2.ChatResponse(...)

            # æ–°å¢ï¼šè¿½è¸ª Token ä½¿ç”¨
            elif chunk.type == "usage":
                total_prompt_tokens += chunk.prompt_tokens
                total_completion_tokens += chunk.completion_tokens

                # å‘é€ Token ä½¿ç”¨ç»Ÿè®¡ç»™å®¢æˆ·ç«¯
                yield agent_service_pb2.ChatResponse(
                    response_id=f"resp_{uuid.uuid4()}",
                    created_at=int(datetime.now().timestamp()),
                    request_id=request_id,
                    usage=agent_service_pb2.Usage(
                        prompt_tokens=chunk.prompt_tokens,
                        completion_tokens=chunk.completion_tokens,
                        total_tokens=chunk.prompt_tokens + chunk.completion_tokens
                    )
                )

        # æœ€ç»ˆï¼šè®°å½•æ€» Token ä½¿ç”¨é‡
        if self.token_tracker:
            await self.token_tracker.record_usage(
                user_id=user_id,
                session_id=session_id,
                request_id=request_id,
                prompt_tokens=total_prompt_tokens,
                completion_tokens=total_completion_tokens
            )
```

**æ–‡ä»¶ 4: `/Users/a/code/sparkle-flutter/backend/app/services/billing_worker.py`** (æ–°å»º)
```python
class BillingWorker:
    """å¼‚æ­¥è®¡è´¹ä»»åŠ¡å¤„ç†å™¨"""

    async def process_billing_queue(self):
        """ä»é˜Ÿåˆ—æ¶ˆè´¹è®¡è´¹è®°å½•å¹¶æŒä¹…åŒ–åˆ°æ•°æ®åº“"""
        while True:
            record_data = await self.redis.blpop("queue:billing", timeout=0)
            if record_data:
                record = json.loads(record_data[1])
                await self._persist_to_db(record)

    async def _persist_to_db(self, record: Dict):
        """æŒä¹…åŒ–åˆ°æ•°æ®åº“"""
        # ä½¿ç”¨ SQLAlchemy æ’å…¥ TokenUsage è®°å½•
        # å¯ä»¥èšåˆå¤šæ¡è®°å½•å‡å°‘æ•°æ®åº“å†™å…¥
        pass
```

---

### P2: æ…¢é€Ÿå·¥å…·çš„æµå¼åé¦ˆä¼˜åŒ–

#### é—®é¢˜åˆ†æ
å½“å‰å·¥å…·æ‰§è¡Œæ˜¯åŒæ­¥çš„ï¼š
- å¦‚æœå·¥å…·æ‰§è¡Œéœ€è¦ 30 ç§’ï¼ŒWebSocket è¿æ¥å¯èƒ½è¶…æ—¶
- ç”¨æˆ·çœ‹ä¸åˆ°è¿›åº¦ï¼Œä½“éªŒå·®

#### è§£å†³æ–¹æ¡ˆï¼šå¿ƒè·³æœºåˆ¶ + è¿›åº¦æ›´æ–°

**æ–‡ä»¶ 1: `/Users/a/code/sparkle-flutter/backend/app/orchestration/executor.py`** (ä¿®æ”¹)
```python
class ToolExecutor:
    """å¢å¼ºç‰ˆå·¥å…·æ‰§è¡Œå™¨"""

    async def execute_tool_call(
        self,
        tool_name: str,
        arguments: Dict,
        user_id: str,
        db_session,
        progress_callback: Optional[Callable] = None
    ) -> ToolResult:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        tool = tool_registry.get_tool(tool_name)
        validated_params = tool.parameters_schema(**arguments)

        # å¦‚æœæ˜¯é•¿æ—¶é—´ä»»åŠ¡ï¼Œå¯åŠ¨è¿›åº¦æŠ¥å‘Š
        if tool.is_long_running:
            # å¯åŠ¨åå°ä»»åŠ¡
            task_id = str(uuid.uuid4())
            asyncio.create_task(
                self._execute_long_running_tool(
                    tool, validated_params, user_id, db_session,
                    task_id, progress_callback
                )
            )

            # ç«‹å³è¿”å›ä»»åŠ¡ ID
            return ToolResult(
                success=True,
                tool_name=tool_name,
                data={"task_id": task_id, "status": "started"},
                is_async=True
            )
        else:
            # çŸ­ä»»åŠ¡ç›´æ¥æ‰§è¡Œ
            result = await tool.execute(validated_params, user_id, db_session)
            return result

    async def _execute_long_running_tool(
        self, tool, params, user_id, db_session,
        task_id, progress_callback
    ):
        """æ‰§è¡Œé•¿æ—¶é—´è¿è¡Œçš„å·¥å…·"""
        try:
            # æ¯éš” 5 ç§’å‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°
            for i in range(1, 6):  # æ¨¡æ‹Ÿè¿›åº¦
                if progress_callback:
                    await progress_callback(
                        task_id=task_id,
                        progress=i * 20,
                        message=f"Processing step {i}/5..."
                    )
                await asyncio.sleep(1)  # æ¨¡æ‹Ÿå·¥ä½œ

            # æ‰§è¡Œå®é™…å·¥å…·
            result = await tool.execute(params, user_id, db_session)

            # å‘é€å®Œæˆé€šçŸ¥
            if progress_callback:
                await progress_callback(
                    task_id=task_id,
                    progress=100,
                    message="Completed",
                    result=result
                )

        except Exception as e:
            if progress_callback:
                await progress_callback(
                    task_id=task_id,
                    progress=0,
                    message=f"Failed: {str(e)}",
                    error=True
                )
```

**æ–‡ä»¶ 2: `/Users/a/code/sparkle-flutter/backend/app/orchestration/orchestrator.py`** (ä¿®æ”¹)
```python
# åœ¨ process_stream ä¸­å¤„ç†å¼‚æ­¥å·¥å…·

async def process_stream(self, request, db_session, context_data):
    # ... existing code

    # Step 8: LLM Generation with Dynamic Tools
    async for chunk in llm_service.chat_stream_with_tools(...):
        if chunk.type == "text":
            # ... existing

        elif chunk.type == "tool_call_end":
            # æ‰§è¡Œå·¥å…·
            tool_result = await self.tool_executor.execute_tool_call(
                tool_name=chunk.tool_name,
                arguments=chunk.full_arguments,
                user_id=user_id,
                db_session=active_db,
                progress_callback=self._send_progress_update  # ä¼ é€’å›è°ƒ
            )

            if tool_result.is_async:
                # å¼‚æ­¥å·¥å…·ï¼šå‘é€ä»»åŠ¡ IDï¼Œç»“æŸå½“å‰æµ
                yield agent_service_pb2.ChatResponse(
                    response_id=f"resp_{uuid.uuid4()}",
                    request_id=request_id,
                    status_update=agent_service_pb2.AgentStatus(
                        state=agent_service_pb2.AgentStatus.ASYNC_TOOL,
                        details=f"Long-running task started: {tool_result.data['task_id']}"
                    ),
                    tool_call=agent_service_pb2.ToolCall(
                        id=chunk.tool_call_id,
                        name=tool_name,
                        arguments=json.dumps(chunk.full_arguments),
                        task_id=tool_result.data["task_id"]
                    )
                )
                return  # ç»“æŸæµï¼Œç­‰å¾…å®¢æˆ·ç«¯è½®è¯¢æˆ– WebSocket æ¨é€

            else:
                # åŒæ­¥å·¥å…·ï¼šç»§ç»­æµ
                tool_execution_results.append(tool_result)
                yield agent_service_pb2.ChatResponse(...)

    # ... rest of code

async def _send_progress_update(self, task_id: str, progress: int, message: str, **kwargs):
    """å‘é€è¿›åº¦æ›´æ–°åˆ° WebSocket"""
    # è¿™ä¸ªæ–¹æ³•éœ€è¦è®¿é—® WebSocket è¿æ¥
    # å¯èƒ½éœ€è¦é€šè¿‡çŠ¶æ€ç®¡ç†å™¨æˆ–äº‹ä»¶æ€»çº¿æ¥å®ç°
    update = {
        "type": "tool_progress",
        "task_id": task_id,
        "progress": progress,
        "message": message,
        **kwargs
    }
    # æ¨é€åˆ° Redis é˜Ÿåˆ—ï¼Œç”± WebSocket handler æ¶ˆè´¹
    await self.redis.rpush(f"ws:updates:{task_id}", json.dumps(update))
```

---

### P3: Prometheus ç›‘æ§æ¥å…¥

#### è§£å†³æ–¹æ¡ˆï¼šåŸºç¡€ç›‘æ§æŒ‡æ ‡

**æ–‡ä»¶ 1: `/Users/a/code/sparkle-flutter/backend/app/core/metrics.py`** (æ–°å»º)
```python
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from prometheus_client.core import CollectorRegistry

# åˆ›å»ºæ³¨å†Œè¡¨
registry = CollectorRegistry()

# å®šä¹‰æŒ‡æ ‡
REQUEST_COUNT = Counter(
    'chat_requests_total',
    'Total number of chat requests',
    ['method', 'status'],
    registry=registry
)

REQUEST_DURATION = Histogram(
    'chat_request_duration_seconds',
    'Request duration in seconds',
    ['method'],
    registry=registry
)

ACTIVE_SESSIONS = Gauge(
    'active_sessions',
    'Number of active sessions',
    registry=registry
)

TOKEN_USAGE = Counter(
    'tokens_consumed_total',
    'Total tokens consumed',
    ['model', 'type'],  # type: prompt/completion
    registry=registry
)

TOOL_EXECUTION_COUNT = Counter(
    'tool_executions_total',
    'Total tool executions',
    ['tool_name', 'status'],
    registry=registry
)

DB_QUERY_DURATION = Histogram(
    'db_query_duration_seconds',
    'Database query duration',
    ['query_type'],
    registry=registry
)

CACHE_HITS = Counter(
    'cache_hits_total',
    'Cache hits and misses',
    ['cache_type', 'hit'],  # hit: true/false
    registry=registry
)
```

**æ–‡ä»¶ 2: `/Users/a/code/sparkle-flutter/backend/app/orchestration/orchestrator.py`** (ä¿®æ”¹)
```python
from app.core.metrics import REQUEST_COUNT, REQUEST_DURATION, TOKEN_USAGE

class ChatOrchestrator:
    async def process_stream(self, request, db_session, context_data):
        timer = REQUEST_DURATION.labels(method="chat").time()

        with timer():
            try:
                REQUEST_COUNT.labels(method="chat", status="started").inc()

                # ... existing code

                # Track token usage
                if total_completion_tokens > 0:
                    TOKEN_USAGE.labels(model="gpt-4", type="prompt").inc(total_prompt_tokens)
                    TOKEN_USAGE.labels(model="gpt-4", type="completion").inc(total_completion_tokens)

                REQUEST_COUNT.labels(method="chat", status="success").inc()

            except Exception:
                REQUEST_COUNT.labels(method="chat", status="error").inc()
                raise
```

**æ–‡ä»¶ 3: `/Users/a/code/sparkle-flutter/backend/gateway/internal/handler/metrics.go`** (æ–°å»º)
```go
package handler

import (
    "github.com/gin-gonic/gin"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

func MetricsHandler() gin.HandlerFunc {
    h := promhttp.Handler()
    return func(c *gin.Context) {
        h.ServeHTTP(c.Writer, c.Request)
    }
}
```

---

## ğŸ“Š å®æ–½é¡ºåºå»ºè®®

### Day 1: P0 - ContextPruner
1. åˆ›å»º `context_pruner.py`
2. åˆ›å»º `summarization_worker.py`
3. ä¿®æ”¹ `orchestrator.py` é›†æˆ ContextPruner
4. ä¿®æ”¹ `prompts.py` æ”¯æŒå†å²æ€»ç»“

### Day 2: P1 - UserService ç¼“å­˜
1. ä¿®æ”¹ `user_service.py` æ·»åŠ  Cache-Aside
2. ä¿®æ”¹ `orchestrator.py` ä¼ é€’ redis_client
3. æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡

### Day 3: P1 - Token è®¡é‡
1. åˆ›å»º `token_tracker.py`
2. ä¿®æ”¹ `validator.py` æ·»åŠ é…é¢æ£€æŸ¥
3. ä¿®æ”¹ `orchestrator.py` é›†æˆ Token è¿½è¸ª
4. åˆ›å»º `billing_worker.py`

### Day 4: P2 - æ…¢é€Ÿå·¥å…·ä¼˜åŒ–
1. ä¿®æ”¹ `executor.py` æ·»åŠ è¿›åº¦å›è°ƒ
2. ä¿®æ”¹ `orchestrator.py` å¤„ç†å¼‚æ­¥å·¥å…·

### Day 5: P3 - ç›‘æ§æ¥å…¥
1. åˆ›å»º `metrics.py`
2. åœ¨å…³é”®ä½ç½®åŸ‹ç‚¹
3. é…ç½® Prometheus + Grafana

---

## ğŸ” å…³é”®æ–‡ä»¶è·¯å¾„æ€»ç»“

| æ¨¡å— | æ–‡ä»¶è·¯å¾„ | æ“ä½œç±»å‹ |
|------|----------|----------|
| ContextPruner | `backend/app/orchestration/context_pruner.py` | æ–°å»º |
| Summarization Worker | `backend/app/orchestration/summarization_worker.py` | æ–°å»º |
| Token Tracker | `backend/app/orchestration/token_tracker.py` | æ–°å»º |
| Billing Worker | `backend/app/services/billing_worker.py` | æ–°å»º |
| Metrics | `backend/app/core/metrics.py` | æ–°å»º |
| Orchestrator | `backend/app/orchestration/orchestrator.py` | ä¿®æ”¹ |
| UserService | `backend/app/services/user_service.py` | ä¿®æ”¹ |
| Validator | `backend/app/orchestration/validator.py` | ä¿®æ”¹ |
| Executor | `backend/app/orchestration/executor.py` | ä¿®æ”¹ |
| Prompts | `backend/app/orchestration/prompts.py` | ä¿®æ”¹ |
| Gateway Metrics | `backend/gateway/internal/handler/metrics.go` | æ–°å»º |

---

## âœ… éªŒæ”¶æ ‡å‡†

### ContextPruner
- [ ] å†å²æ¶ˆæ¯è¶…è¿‡ 10 æ¡æ—¶è‡ªåŠ¨æˆªæ–­
- [ ] è¶…è¿‡ 20 æ¡æ—¶è§¦å‘å¼‚æ­¥æ€»ç»“
- [ ] æ€»ç»“ç»“æœç¼“å­˜ 1 å°æ—¶
- [ ] Token ä½¿ç”¨é‡å‡å°‘ 50%+

### UserService ç¼“å­˜
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 80%
- [ ] æ•°æ®åº“æŸ¥è¯¢å‡å°‘ 70%+
- [ ] ç”¨æˆ·èµ„æ–™æ›´æ–°åç¼“å­˜è‡ªåŠ¨å¤±æ•ˆ
- [ ] å“åº”æ—¶é—´ < 50ms (ç¼“å­˜å‘½ä¸­)

### Token è®¡é‡
- [ ] æ¯æ¬¡è¯·æ±‚è®°å½• Token ä½¿ç”¨é‡
- [ ] é…é¢è¶…é™è‡ªåŠ¨æ‹¦æˆª
- [ ] æ”¯æŒæ¯æ—¥/æ¯æœˆé…é¢æŸ¥è¯¢
- [ ] è®¡è´¹æ•°æ®å¼‚æ­¥æŒä¹…åŒ–

### æ…¢é€Ÿå·¥å…·ä¼˜åŒ–
- [ ] é•¿ä»»åŠ¡æ¯ 5 ç§’å‘é€è¿›åº¦æ›´æ–°
- [ ] WebSocket ä¸è¶…æ—¶æ–­å¼€
- [ ] ç”¨æˆ·èƒ½çœ‹åˆ°å®æ—¶è¿›åº¦

### ç›‘æ§
- [ ] Prometheus æš´éœ² /metrics ç«¯ç‚¹
- [ ] Grafana ä»ªè¡¨ç›˜æ˜¾ç¤º QPSã€å»¶è¿Ÿã€é”™è¯¯ç‡
- [ ] Token ä½¿ç”¨é‡å¯è§†åŒ–
- [ ] ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§

---

## ğŸ’¡ é£é™©ä¸ç¼“è§£

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|----------|
| æ€»ç»“ä»»åŠ¡ç§¯å‹ | Redis å†…å­˜æº¢å‡º | é™åˆ¶é˜Ÿåˆ—é•¿åº¦ï¼Œæ·»åŠ ç†”æ–­å™¨ |
| ç¼“å­˜ä¸€è‡´æ€§é—®é¢˜ | æ•°æ®ä¸ä¸€è‡´ | æ›´æ–°æ—¶ç«‹å³å¤±æ•ˆï¼ŒTTL ä½œä¸ºå…œåº• |
| Token è¿½è¸ªä¸¢å¤± | è®¡è´¹é”™è¯¯ | åŒå†™ Redis + DBï¼Œå¤±è´¥é‡è¯• |
| WebSocket è¶…æ—¶ | ç”¨æˆ·ä½“éªŒå·® | å¿ƒè·³æœºåˆ¶ï¼Œè¿›åº¦æ›´æ–° |
| ç›‘æ§æ€§èƒ½å¼€é”€ | å½±å“ä¸»æµç¨‹ | ä½¿ç”¨ç›´æ–¹å›¾ï¼Œé‡‡æ ·ç‡æ§åˆ¶ |

---

**å¼€å§‹å®æ–½å‰ï¼Œè¯·ç¡®è®¤ï¼š**
1. Redis é›†ç¾¤æ˜¯å¦å·²éƒ¨ç½²å¹¶å¯ç”¨ï¼Ÿ
2. æ˜¯å¦éœ€è¦ä¸ºæ€»ç»“ä»»åŠ¡å‡†å¤‡å•ç‹¬çš„ LLM å®ä¾‹ï¼Ÿ
3. Token é…é¢çš„é»˜è®¤å€¼æ˜¯å¤šå°‘ï¼Ÿ(å»ºè®®ï¼šå…è´¹ç”¨æˆ· 50k/æ—¥ï¼ŒPro ç”¨æˆ· 500k/æ—¥)
4. Prometheus + Grafana æ˜¯å¦å·²éƒ¨ç½²ï¼Ÿ
