# Sparkle AI Learning Assistant - æ·±åº¦æŠ€æœ¯è®²è§£æ–‡æ¡£

> **æ–‡æ¡£ç‰ˆæœ¬**: v2.0
> **ç¼–å†™æ—¥æœŸ**: 2025-12-27
> **ç”Ÿäº§å°±ç»ªåº¦**: 9.5/10
> **é€‚ç”¨å¯¹è±¡**: é«˜çº§åç«¯å·¥ç¨‹å¸ˆã€æ¶æ„å¸ˆã€æŠ€æœ¯è¯„å§”

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¶æ„å…¨æ™¯](#1-ç³»ç»Ÿæ¶æ„å…¨æ™¯)
2. [Go Gateway - é«˜æ€§èƒ½ç½‘å…³å±‚](#2-go-gateway---é«˜æ€§èƒ½ç½‘å…³å±‚)
3. [Python Agent Engine - AI æ ¸å¿ƒå¼•æ“](#3-python-agent-engine---ai-æ ¸å¿ƒå¼•æ“)
4. [Flutter Mobile - è·¨å¹³å°ç§»åŠ¨ç«¯](#4-flutter-mobile---è·¨å¹³å°ç§»åŠ¨ç«¯)
5. [æ•°æ®åº“æ¶æ„æ·±åº¦è§£æ](#5-æ•°æ®åº“æ¶æ„æ·±åº¦è§£æ)
6. [æ ¸å¿ƒåŠŸèƒ½å®ç°è¯¦è§£](#6-æ ¸å¿ƒåŠŸèƒ½å®ç°è¯¦è§£)
7. [ç”Ÿäº§çº§ç‰¹æ€§ä¸å¢å¼º](#7-ç”Ÿäº§çº§ç‰¹æ€§ä¸å¢å¼º)
8. [å®Œæ•´è¯·æ±‚æµç¨‹è¿½è¸ª](#8-å®Œæ•´è¯·æ±‚æµç¨‹è¿½è¸ª)
9. [æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ](#9-æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ)
10. [é¢è¯•å¸¸è§é—®é¢˜è§£ç­”](#10-é¢è¯•å¸¸è§é—®é¢˜è§£ç­”)

---

## 1. ç³»ç»Ÿæ¶æ„å…¨æ™¯

### 1.1 é«˜å±‚æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Sparkle AI Learning Assistant                     â”‚
â”‚                  æ˜Ÿç« - AI å¤§å­¦ç”Ÿå­¦ä¹ è¾…åŠ©ç³»ç»Ÿ                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    gRPC      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚ â”‚
â”‚  â”‚ Flutter App  â”‚    (8080)       â”‚ Go Gateway   â”‚  (50051)     â”‚ Python Agent â”‚ â”‚
â”‚  â”‚              â”‚                 â”‚              â”‚              â”‚   Engine     â”‚ â”‚
â”‚  â”‚  Riverpod    â”‚                 â”‚  Gin +       â”‚              â”‚              â”‚ â”‚
â”‚  â”‚  State Mgmt  â”‚                 â”‚  WebSocket   â”‚              â”‚  FastAPI     â”‚ â”‚
â”‚  â”‚  Hive/SQLite â”‚                 â”‚  + Auth      â”‚              â”‚  + Orchestrationâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â–²                                â”‚                              â”‚         â”‚
â”‚         â”‚                                â”‚                              â”‚         â”‚
â”‚         â”‚                                â–¼                              â–¼         â”‚
â”‚         â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚         â”‚                        â”‚   Redis      â”‚              â”‚ PostgreSQL   â”‚ â”‚
â”‚         â”‚                        â”‚  (Sessions,  â”‚              â”‚  + pgvector  â”‚ â”‚
â”‚         â”‚                        â”‚   Cache,     â”‚              â”‚              â”‚ â”‚
â”‚         â”‚                        â”‚   Queues)    â”‚              â”‚              â”‚ â”‚
â”‚         â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                                â–²                              â–²         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                    Internal Communication                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒè®¾è®¡åŸåˆ™

**æ··åˆæ¶æ„ä¼˜åŠ¿**:
- **Go Gateway**: é«˜æ€§èƒ½ WebSocket å¤„ç†ï¼ŒC10K å¹¶å‘èƒ½åŠ›
- **Python Agent**: AI ç¼–æ’ã€å·¥å…·è°ƒç”¨ã€å‘é‡æ£€ç´¢çš„çµæ´»æ€§
- **Flutter**: è·¨å¹³å°ç»Ÿä¸€ä½“éªŒï¼ŒRiverpod çŠ¶æ€ç®¡ç†

**æ•°æ®æµå‘**:
```
Mobile â†’ WebSocket â†’ Go â†’ gRPC â†’ Python â†’ DB/Cache â†’ LLM â†’ Response
```

### 1.3 æŠ€æœ¯æ ˆé€‰æ‹©ç†ç”±

| ç»„ä»¶ | æŠ€æœ¯ | é€‰æ‹©ç†ç”± |
|------|------|----------|
| **ç½‘å…³** | Go + Gin + Gorilla WebSocket | é«˜å¹¶å‘ã€ä½å»¶è¿Ÿã€å†…å­˜å®‰å…¨ |
| **AI å¼•æ“** | Python + FastAPI | ç”Ÿæ€ä¸°å¯Œã€LLM é›†æˆæˆç†Ÿ |
| **ç§»åŠ¨ç«¯** | Flutter + Riverpod | è·¨å¹³å°ã€å“åº”å¼ã€çŠ¶æ€ç®¡ç† |
| **æ•°æ®åº“** | PostgreSQL 16 + pgvector | å…³ç³»å‹ + å‘é‡æœç´¢ä¸€ä½“åŒ– |
| **ç¼“å­˜/é˜Ÿåˆ—** | Redis 7 | é«˜æ€§èƒ½ã€æ”¯æŒå¤šç§æ•°æ®ç»“æ„ |
| **é€šä¿¡** | gRPC | é«˜æ•ˆäºŒè¿›åˆ¶åè®®ã€æµå¼æ”¯æŒ |

---

## 2. Go Gateway - é«˜æ€§èƒ½ç½‘å…³å±‚

### 2.1 æ ¸å¿ƒç»„ä»¶æ¶æ„

```
backend/gateway/
â”œâ”€â”€ cmd/server/main.go              # å…¥å£ç‚¹ï¼ŒæœåŠ¡å¯åŠ¨
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ handler/
â”‚   â”‚   â””â”€â”€ chat_orchestrator.go    # WebSocket æ ¸å¿ƒå¤„ç†å™¨
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ auth.go                 # JWT è®¤è¯ + é€Ÿç‡é™åˆ¶
â”‚   â”‚   â””â”€â”€ rate_limit.go           # åˆ†å¸ƒå¼é™æµ
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ quota_service.go        # ç”¨æˆ·é…é¢ç®¡ç†
â”‚   â”‚   â””â”€â”€ cache_service.go        # è¯­ä¹‰ç¼“å­˜
â”‚   â”œâ”€â”€ proxy/
â”‚   â”‚   â””â”€â”€ reverse_proxy.go        # REST API åå‘ä»£ç†
â”‚   â””â”€â”€ db/
â”‚       â””â”€â”€ schema.sql              # SQLC ä»£ç ç”Ÿæˆ
```

### 2.2 WebSocket å¤„ç†å™¨æ·±åº¦è§£æ

#### 2.2.1 è¿æ¥ç”Ÿå‘½å‘¨æœŸç®¡ç†

```go
// backend/gateway/internal/handler/chat_orchestrator.go

type ChatHandler struct {
    grpcClient   pb.AgentServiceClient
    redisClient  *redis.Client
    sessionMgr   *SessionManager
    quotaService *QuotaService
}

func (h *ChatHandler) HandleWebSocket(conn *websocket.Conn, userID string) {
    // 1. è¿æ¥å»ºç«‹ä¸è®¤è¯
    sessionID := h.sessionMgr.CreateSession(userID)

    // 2. æ³¨å†Œè¿æ¥åˆ°ä¼šè¯ç®¡ç†å™¨
    h.sessionMgr.Register(sessionID, conn)
    defer h.sessionMgr.Unregister(sessionID)

    // 3. å¯åŠ¨å¿ƒè·³åç¨‹
    go h.heartbeat(conn, sessionID)

    // 4. æ¶ˆæ¯å¾ªç¯
    for {
        var msg ChatMessage
        if err := conn.ReadJSON(&msg); err != nil {
            h.handleError(sessionID, err)
            break
        }

        // 5. é…é¢æ£€æŸ¥
        if !h.quotaService.CheckQuota(userID) {
            conn.WriteJSON(QuotaExceededResponse)
            break
        }

        // 6. è½¬å‘åˆ° gRPC æœåŠ¡
        response, err := h.forwardToPython(userID, sessionID, msg)
        if err != nil {
            conn.WriteJSON(ErrorResponse{Code: "GRPC_ERROR"})
            continue
        }

        // 7. æµå¼è¿”å›
        for _, chunk := range response {
            if err := conn.WriteJSON(chunk); err != nil {
                break
            }
        }
    }
}
```

#### 2.2.2 å¿ƒè·³æœºåˆ¶ï¼ˆé˜²æ–­è¿ï¼‰

```go
func (h *ChatHandler) heartbeat(conn *websocket.Conn, sessionID string) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            // å‘é€ Ping
            if err := conn.WriteControl(websocket.PingMessage, nil, time.Now().Add(10*time.Second)); err != nil {
                return
            }

            // æ›´æ–° Redis ä¸­çš„ä¼šè¯æ´»è·ƒæ—¶é—´
            h.redisClient.Expire(context.Background(),
                fmt.Sprintf("session:%s:active", sessionID),
                60*time.Second)
        }
    }
}
```

### 2.3 è®¤è¯ä¸é™æµä¸­é—´ä»¶

#### 2.3.1 JWT è®¤è¯

```go
// backend/gateway/internal/middleware/auth.go

func AuthMiddleware(jwtSecret string) gin.HandlerFunc {
    return func(c *gin.Context) {
        // 1. ä» Header è·å– Token
        authHeader := c.GetHeader("Authorization")
        if authHeader == "" {
            c.AbortWithStatusJSON(401, gin.H{"error": "Missing token"})
            return
        }

        // 2. è§£æ JWT
        tokenString := strings.TrimPrefix(authHeader, "Bearer ")
        claims, err := jwt.ParseWithClaims(tokenString, &Claims{},
            func(token *jwt.Token) (interface{}, error) {
                return []byte(jwtSecret), nil
            })

        if err != nil || !claims.Valid {
            c.AbortWithStatusJSON(401, gin.H{"error": "Invalid token"})
            return
        }

        // 3. è®¾ç½®ç”¨æˆ·ä¿¡æ¯
        c.Set("userID", claims.UserID)
        c.Set("sessionID", claims.SessionID)
        c.Next()
    }
}
```

#### 2.3.2 åˆ†å¸ƒå¼é™æµ

```go
// backend/gateway/internal/middleware/rate_limit.go

func RateLimitMiddleware(redisClient *redis.Client) gin.HandlerFunc {
    return func(c *gin.Context) {
        userID := c.GetString("userID")
        key := fmt.Sprintf("rate_limit:%s", userID)

        // ä½¿ç”¨ Redis Lua è„šæœ¬ä¿è¯åŸå­æ€§
        script := `
        local current = redis.call('GET', KEYS[1])
        if current and tonumber(current) >= tonumber(ARGV[1]) then
            return 0
        else
            redis.call('INCR', KEYS[1])
            redis.call('EXPIRE', KEYS[1], ARGV[2])
            return 1
        end
        `

        allowed, err := redisClient.Eval(context.Background(), script,
            []string{key}, "100", "60").Result()

        if err != nil || allowed.(int64) == 0 {
            c.AbortWithStatusJSON(429, gin.H{"error": "Rate limit exceeded"})
            return
        }

        c.Next()
    }
}
```

### 2.4 åå‘ä»£ç†è®¾è®¡

```go
// backend/gateway/internal/proxy/reverse_proxy.go

func NewReverseProxy(target *url.URL) *httputil.ReverseProxy {
    proxy := httputil.NewSingleHostReverseProxy(target)

    // è‡ªå®šä¹‰ Director ä¿®æ”¹è¯·æ±‚
    proxy.Director = func(req *http.Request) {
        req.URL.Scheme = target.Scheme
        req.URL.Host = target.Host
        req.URL.Path = target.Path + req.URL.Path

        // ä¼ é€’åŸå§‹ç”¨æˆ·ä¿¡æ¯
        if userID, ok := req.Context().Value("userID").(string); ok {
            req.Header.Set("X-User-ID", userID)
        }
    }

    // é”™è¯¯å¤„ç†
    proxy.ErrorHandler = func(w http.ResponseWriter, req *http.Request, err error) {
        log.Printf("Proxy error: %v", err)
        w.WriteHeader(http.StatusBadGateway)
        w.Write([]byte("Backend service unavailable"))
    }

    return proxy
}
```

### 2.5 Go Gateway ç”Ÿäº§çº§ç‰¹æ€§

| ç‰¹æ€§ | å®ç°æ–¹å¼ | ä»·å€¼ |
|------|----------|------|
| **è¿æ¥ç®¡ç†** | ä¼šè¯æ˜ å°„ + å¿ƒè·³ | é˜²æ­¢åƒµå°¸è¿æ¥ |
| **é…é¢æ§åˆ¶** | Redis è®¡æ•°å™¨ | é˜²æ­¢æ»¥ç”¨ |
| **è®¤è¯å®‰å…¨** | JWT + ç­¾åéªŒè¯ | èº«ä»½éªŒè¯ |
| **é™æµä¿æŠ¤** | Redis Lua è„šæœ¬ | é˜²æ­¢ DDoS |
| **é”™è¯¯éš”ç¦»** | ç†”æ–­ + è¶…æ—¶ | çº§è”æ•…éšœé˜²æŠ¤ |
| **æ—¥å¿—è¿½è¸ª** | è¯·æ±‚ ID + ç»“æ„åŒ–æ—¥å¿— | é—®é¢˜æ’æŸ¥ |

---

## 3. Python Agent Engine - AI æ ¸å¿ƒå¼•æ“

### 3.1 æ ¸å¿ƒæ¶æ„è®¾è®¡

```
backend/app/
â”œâ”€â”€ orchestration/                    # ç¼–æ’å±‚
â”‚   â”œâ”€â”€ orchestrator_production.py    # ç”Ÿäº§çº§ç¼–æ’å™¨
â”‚   â”œâ”€â”€ context_pruner.py             # ä¸Šä¸‹æ–‡ä¿®å‰ª
â”‚   â”œâ”€â”€ dynamic_tool_registry.py      # åŠ¨æ€å·¥å…·æ³¨å†Œ
â”‚   â”œâ”€â”€ validator.py                  # è¯·æ±‚éªŒè¯
â”‚   â”œâ”€â”€ executor.py                   # å·¥å…·æ‰§è¡Œ
â”‚   â””â”€â”€ composer.py                   # å“åº”ç»„åˆ
â”œâ”€â”€ services/                         # ä¸šåŠ¡æœåŠ¡
â”‚   â”œâ”€â”€ llm_service.py                # LLM é›†æˆ
â”‚   â”œâ”€â”€ galaxy_service.py             # çŸ¥è¯†æ˜Ÿå›¾
â”‚   â”œâ”€â”€ expansion_service.py          # LLM æ‹“å±•
â”‚   â”œâ”€â”€ decay_service.py              # é—å¿˜æ›²çº¿
â”‚   â”œâ”€â”€ push_service.py               # æ™ºèƒ½æ¨é€
â”‚   â””â”€â”€ task_service.py               # ä»»åŠ¡ç®¡ç†
â”œâ”€â”€ tools/                            # åŠ¨æ€å·¥å…·
â”‚   â”œâ”€â”€ knowledge_tools.py            # çŸ¥è¯†å·¥å…·
â”‚   â”œâ”€â”€ task_tools.py                 # ä»»åŠ¡å·¥å…·
â”‚   â””â”€â”€ user_tools.py                 # ç”¨æˆ·å·¥å…·
â””â”€â”€ grpc_server.py                    # gRPC æœåŠ¡ç«¯
```

### 3.2 ç”Ÿäº§çº§ç¼–æ’å™¨ (ProductionChatOrchestrator)

#### 3.2.1 å®Œæ•´å¤„ç†æµç¨‹

```python
# backend/app/orchestration/orchestrator_production.py

class ProductionChatOrchestrator:
    """
    ç”Ÿäº§çº§èŠå¤©ç¼–æ’å™¨
    æ ¸å¿ƒèŒè´£ï¼šè¯·æ±‚å¤„ç†ã€çŠ¶æ€ç®¡ç†ã€é”™è¯¯å¤„ç†ã€ç›‘æ§
    """

    def __init__(self, config: ProductionSettings):
        # æ ¸å¿ƒç»„ä»¶
        self.state_manager = SessionStateManager()
        self.validator = RequestValidator()
        self.tool_executor = ToolExecutor()
        self.response_composer = ResponseComposer()

        # ç”Ÿäº§çº§å¢å¼º
        self.context_pruner = ContextPruner(
            redis_client=config.redis_client,
            max_history_messages=config.MAX_HISTORY_MESSAGES,
            summary_threshold=config.SUMMARY_THRESHOLD
        )
        self.token_tracker = TokenTracker()
        self.circuit_breaker = CircuitBreaker(
            failure_threshold=config.CIRCUIT_BREAKER_THRESHOLD,
            recovery_timeout=config.CIRCUIT_BREAKER_TIMEOUT
        )
        self.message_tracker = MessageTracker()

        # ç›‘æ§
        self.metrics = MetricsCollector()

    async def process_stream(self, request: ChatRequest) -> AsyncIterator[StreamEvent]:
        """
        ä¸»å¤„ç†æµç¨‹ - 11æ­¥å®‰å…¨å¤„ç†é“¾
        """
        request_id = request.request_id
        session_id = request.session_id
        user_id = request.user_id

        # ========== ç¬¬1æ­¥ï¼šæ¶ˆæ¯å»é‡æ£€æŸ¥ ==========
        if await self.message_tracker.is_processed(request_id):
            yield ErrorEvent(code="DUPLICATE_REQUEST", message="è¯·æ±‚å·²å¤„ç†")
            return

        # ========== ç¬¬2æ­¥ï¼šç†”æ–­å™¨æ£€æŸ¥ ==========
        if not await self.circuit_breaker.can_execute():
            yield ErrorEvent(code="CIRCUIT_BREAKER_OPEN",
                           message="ç³»ç»Ÿè¿‡è½½ï¼Œè¯·ç¨åé‡è¯•")
            return

        # ========== ç¬¬3æ­¥ï¼šå¹¶å‘æ§åˆ¶ ==========
        if not await self._track_session(session_id, add=True):
            yield ErrorEvent(code="RATE_LIMIT", message="å¹¶å‘è¯·æ±‚è¿‡å¤š")
            return

        try:
            # ========== ç¬¬4æ­¥ï¼šè¯·æ±‚éªŒè¯ ==========
            validation = await self.validator.validate_chat_request(request)
            if not validation.is_valid:
                yield ErrorEvent(code="VALIDATION_FAILED",
                               message=validation.error_message)
                return

            # ========== ç¬¬5æ­¥ï¼šå¹‚ç­‰æ€§æ£€æŸ¥ ==========
            cached = await self._check_idempotency(session_id, request_id)
            if cached:
                yield cached
                return

            # ========== ç¬¬6æ­¥ï¼šåˆ†å¸ƒå¼é” ==========
            lock_acquired = await self._acquire_session_lock(
                session_id, request_id, timeout=10
            )
            if not lock_acquired:
                yield ErrorEvent(code="LOCK_FAILED", message="ä¼šè¯ç¹å¿™")
                return

            # ========== ç¬¬7æ­¥ï¼šæ„å»ºä¸Šä¸‹æ–‡ ==========
            user_context = await self._build_user_context(user_id)
            conversation_context = await self.context_pruner.get_pruned_history(
                session_id, user_id
            )

            # ========== ç¬¬8æ­¥ï¼šçŸ¥è¯†æ£€ç´¢ (GraphRAG) ==========
            knowledge_context = await self._retrieve_knowledge(
                user_id, request.message, conversation_context
            )

            # ========== ç¬¬9æ­¥ï¼šLLM è°ƒç”¨ + å·¥å…·æ‰§è¡Œ ==========
            async for chunk in self._call_llm_with_tools(
                request=request,
                user_context=user_context,
                conversation_context=conversation_context,
                knowledge_context=knowledge_context
            ):
                yield chunk

            # ========== ç¬¬10æ­¥ï¼šç¼“å­˜ä¸æŒ‡æ ‡ ==========
            await self._cache_response(session_id, request_id, request.message)
            await self._record_metrics(request, user_context)

        finally:
            # ========== ç¬¬11æ­¥ï¼šæ¸…ç†èµ„æº ==========
            await self._release_session_lock(session_id, request_id)
            await self._track_session(session_id, add=False)
```

#### 3.2.2 ä¸Šä¸‹æ–‡æ„å»ºè¯¦è§£

```python
async def _build_user_context(self, user_id: str) -> UserContext:
    """æ„å»ºç”¨æˆ·ä¸Šä¸‹æ–‡"""
    # 1. ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
    user = await self.user_service.get_user(user_id)

    # 2. å­¦ä¹ è¿›åº¦ç»Ÿè®¡
    progress = await self.stats_service.get_learning_progress(user_id)

    # 3. å½“å‰å†²åˆºè®¡åˆ’
    sprint = await self.sprint_service.get_active_sprint(user_id)

    # 4. æ¨é€åå¥½
    push_pref = await self.push_service.get_preferences(user_id)

    return UserContext(
        user=user,
        progress=progress,
        active_sprint=sprint,
        push_preference=push_pref
    )

async def _retrieve_knowledge(self, user_id: str, query: str,
                             conversation_context: dict) -> KnowledgeContext:
    """GraphRAG çŸ¥è¯†æ£€ç´¢"""
    # 1. å‘é‡æœç´¢
    vector_results = await self.galaxy_service.hybrid_search(
        user_id=user_id,
        query=query,
        vector_query=query,
        limit=10
    )

    # 2. å…³ç³»æ‰©å±•
    expanded = await self.galaxy_service.expand_relations(
        node_ids=[r.node_id for r in vector_results]
    )

    # 3. ç”¨æˆ·çŠ¶æ€è¿‡æ»¤
    filtered = await self.galaxy_service.filter_by_user_status(
        user_id, expanded
    )

    return KnowledgeContext(
        nodes=filtered,
        relations=expanded.relations,
        relevance_score=vector_results.relevance_score
    )
```

### 3.3 ä¸Šä¸‹æ–‡ä¿®å‰ªå™¨ (ContextPruner)

#### 3.3.1 æ ¸å¿ƒç®—æ³•

```python
# backend/app/orchestration/context_pruner.py

class ContextPruner:
    """
    æ™ºèƒ½ä¸Šä¸‹æ–‡ä¿®å‰ªå™¨
    è§£å†³ï¼šé•¿å¯¹è¯å¯¼è‡´çš„ Token è¶…é™å’Œæ€§èƒ½é—®é¢˜
    """

    def __init__(self, redis_client, max_history_messages=10, summary_threshold=20):
        self.redis = redis_client
        self.max_history_messages = max_history_messages
        self.summary_threshold = summary_threshold
        self.summary_cache_ttl = 3600  # 1å°æ—¶

    async def get_pruned_history(self, session_id: str, user_id: str,
                                 force_summary: bool = False) -> dict:
        """
        è·å–ä¿®å‰ªåçš„èŠå¤©å†å²
        è¿”å›æ ¼å¼ï¼š
        {
            "messages": [...],        # ä¿ç•™çš„æ¶ˆæ¯
            "summary": "...",         # æ€»ç»“ï¼ˆå¦‚æœæœ‰ï¼‰
            "original_count": 50,     # åŸå§‹æ•°é‡
            "pruned_count": 8,        # ä¿®å‰ªåæ•°é‡
            "summary_used": True      # æ˜¯å¦ä½¿ç”¨æ€»ç»“
        }
        """
        # 1. ä» Redis åŠ è½½å®Œæ•´å†å²
        history = await self._load_chat_history(session_id)

        if not history:
            return self._empty_result()

        original_count = len(history)

        # 2. å°å†å²ç›´æ¥è¿”å›
        if original_count <= self.max_history_messages:
            return {
                "messages": history,
                "summary": None,
                "original_count": original_count,
                "pruned_count": original_count,
                "summary_used": False
            }

        # 3. åˆ¤æ–­æ˜¯å¦éœ€è¦æ€»ç»“
        need_summary = force_summary or original_count > self.summary_threshold

        if need_summary:
            return await self._get_summarized_history(session_id, history, user_id)
        else:
            return self._get_sliding_window(history)

    async def _get_summarized_history(self, session_id: str, history: list,
                                     user_id: str) -> dict:
        """è·å–å¸¦æ€»ç»“çš„å†å²"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"summary:{session_id}"
        cached_summary = await self.redis.get(cache_key)

        if cached_summary:
            return {
                "messages": history[-5:],  # ä¿ç•™æœ€è¿‘5æ¡
                "summary": cached_summary.decode("utf-8"),
                "original_count": len(history),
                "pruned_count": 6,
                "summary_used": True
            }

        # è§¦å‘å¼‚æ­¥æ€»ç»“ä»»åŠ¡
        await self._trigger_summary(session_id, history, user_id)

        # Fallbackï¼šè¿”å›æœ€è¿‘5æ¡
        return {
            "messages": history[-5:],
            "summary": None,
            "original_count": len(history),
            "pruned_count": 5,
            "summary_used": False,
            "summary_pending": True
        }

    async def _trigger_summary(self, session_id: str, history: list, user_id: str):
        """å¼‚æ­¥æ€»ç»“ä»»åŠ¡"""
        # åªæ€»ç»“é™¤æœ€è¿‘5æ¡å¤–çš„å†å²
        history_to_summarize = history[:-5] if len(history) > 5 else history

        task = {
            "session_id": session_id,
            "history": history_to_summarize,
            "user_id": user_id,
            "timestamp": time.time(),
            "priority": "high"
        }

        # æ¨é€åˆ° Redis é˜Ÿåˆ—
        await self.redis.rpush("queue:summarization", json.dumps(task))

        # è®¾ç½® TTL é˜²æ­¢é˜Ÿåˆ—ç§¯å‹
        await self.redis.expire("queue:summarization", 86400)
```

#### 3.3.2 å¼‚æ­¥æ€»ç»“å·¥ä½œå™¨

```python
# backend/app/workers/summary_worker.py

class SummaryWorker:
    """åå°æ€»ç»“å·¥ä½œå™¨"""

    def __init__(self, llm_service, redis_client):
        self.llm = llm_service
        self.redis = redis_client

    async def process_summarization_queue(self):
        """å¤„ç†æ€»ç»“é˜Ÿåˆ—"""
        while True:
            try:
                # é˜»å¡å¼è·å–ä»»åŠ¡
                task_data = await self.redis.blpop("queue:summarization", timeout=1)
                if not task_data:
                    continue

                task = json.loads(task_data[1])

                # ç”Ÿæˆæ€»ç»“
                summary = await self._generate_summary(task["history"])

                # ç¼“å­˜ç»“æœ
                cache_key = f"summary:{task['session_id']}"
                await self.redis.setex(
                    cache_key,
                    3600,  # 1å°æ—¶TTL
                    summary
                )

                # è®°å½•æŒ‡æ ‡
                await self._record_summary_metrics(task, summary)

            except Exception as e:
                logger.error(f"Summary generation failed: {e}")
                await asyncio.sleep(5)  # é”™è¯¯é€€é¿

    async def _generate_summary(self, history: list) -> str:
        """è°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“"""
        prompt = f"""
        è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯å†å²ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ï¼š
        {json.dumps(history, ensure_ascii=False)}

        æ€»ç»“è¦æ±‚ï¼š
        1. ä¿ç•™ç”¨æˆ·çš„æ ¸å¿ƒé—®é¢˜å’Œéœ€æ±‚
        2. æå– AI çš„å…³é”®å›ç­”å’Œå»ºè®®
        3. æ§åˆ¶åœ¨ 200 å­—ä»¥å†…
        """

        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200
        )

        return response.content
```

### 3.4 åŠ¨æ€å·¥å…·ç³»ç»Ÿ

#### 3.4.1 å·¥å…·æ³¨å†Œè¡¨

```python
# backend/app/orchestration/dynamic_tool_registry.py

class DynamicToolRegistry:
    """
    åŠ¨æ€å·¥å…·æ³¨å†Œè¡¨
    ç‰¹æ€§ï¼šè‡ªåŠ¨å‘ç°ã€åˆ†ç±»ç®¡ç†ã€OpenAI æ ¼å¼è½¬æ¢
    """

    _instance = None
    _tools: Dict[str, BaseTool] = {}

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def register_from_package(self, package_path: str, recursive: bool = True) -> int:
        """ä»åŒ…è‡ªåŠ¨å‘ç°å¹¶æ³¨å†Œæ‰€æœ‰å·¥å…·"""
        import pkgutil
        import importlib

        package = importlib.import_module(package_path)
        total_registered = 0

        for importer, modname, ispkg in pkgutil.iter_modules(package.__path__):
            full_module_path = f"{package_path}.{modname}"

            if ispkg and recursive:
                total_registered += self.register_from_package(full_module_path, recursive)
            else:
                if self.register_from_module(full_module_path):
                    module_tools = [
                        t for t in self._tools.values()
                        if t.__module__ == full_module_path
                    ]
                    total_registered += len(module_tools)

        logger.info(f"Auto-discovered {total_registered} tools from {package_path}")
        return total_registered

    def register_from_module(self, module_path: str) -> bool:
        """ä»æ¨¡å—æ³¨å†Œå·¥å…·"""
        try:
            module = importlib.import_module(module_path)

            for attr_name in dir(module):
                attr = getattr(module, attr_name)

                if (isinstance(attr, type) and
                    issubclass(attr, BaseTool) and
                    attr != BaseTool):

                    tool_instance = attr()
                    self._tools[tool_instance.name] = tool_instance

            return True
        except Exception as e:
            logger.error(f"Failed to register tools from {module_path}: {e}")
            return False

    def get_openai_tools_schema(self) -> List[dict]:
        """è½¬æ¢ä¸º OpenAI Function Calling æ ¼å¼"""
        return [tool.to_openai_schema() for tool in self._tools.values()]

    def get_tools_description(self, category: Optional[str] = None) -> str:
        """ç”Ÿæˆå·¥å…·æè¿°æ–‡æœ¬ï¼ˆç”¨äº System Promptï¼‰"""
        tools = self._tools.values()
        if category:
            tools = [t for t in tools if t.category == category]

        lines = ["ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ï¼š\n"]
        for tool in tools:
            lines.append(f"- **{tool.name}**: {tool.description}")
            if tool.parameters_schema:
                lines.append(f"  å‚æ•°: {json.dumps(tool.parameters_schema, indent=2)}")

        return "\n".join(lines)

    def get_tool(self, name: str) -> Optional[BaseTool]:
        """è·å–ç‰¹å®šå·¥å…·"""
        return self._tools.get(name)
```

#### 3.4.2 å·¥å…·åŸºç±»è®¾è®¡

```python
# backend/app/orchestration/base_tool.py

from enum import Enum
from typing import Any, Dict, Optional

class ToolCategory(Enum):
    KNOWLEDGE = "knowledge"      # çŸ¥è¯†æ“ä½œ
    TASK = "task"                # ä»»åŠ¡ç®¡ç†
    USER = "user"                # ç”¨æˆ·æ“ä½œ
    SYSTEM = "system"            # ç³»ç»Ÿæ“ä½œ

class BaseTool:
    """å·¥å…·åŸºç±»"""

    name: str
    description: str
    category: ToolCategory
    parameters_schema: Optional[Dict[str, Any]] = None

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·"""
        raise NotImplementedError

    def to_openai_schema(self) -> dict:
        """è½¬æ¢ä¸º OpenAI æ ¼å¼"""
        schema = {
            "name": self.name,
            "description": self.description,
        }

        if self.parameters_schema:
            schema["parameters"] = {
                "type": "object",
                "properties": self.parameters_schema,
                "required": list(self.parameters_schema.keys())
            }

        return schema

# ç¤ºä¾‹å·¥å…·å®ç°
class GetKnowledgeNodeTool(BaseTool):
    name = "get_knowledge_node"
    description = "è·å–çŸ¥è¯†ç‚¹è¯¦ç»†ä¿¡æ¯"
    category = ToolCategory.KNOWLEDGE

    parameters_schema = {
        "node_id": {
            "type": "string",
            "description": "çŸ¥è¯†ç‚¹ID"
        }
    }

    async def execute(self, node_id: str) -> Dict[str, Any]:
        node = await self.knowledge_service.get_node(node_id)
        return {
            "name": node.name,
            "description": node.description,
            "importance": node.importance_level,
            "parent": node.parent_id
        }
```

### 3.5 LLM æœåŠ¡é›†æˆ

#### 3.5.1 å¤šæ¨¡å‹æ”¯æŒ

```python
# backend/app/services/llm_service.py

class LLMService:
    """LLM æœåŠ¡ - æ”¯æŒå¤šæ¨¡å‹æä¾›å•†"""

    def __init__(self, config):
        self.providers = {
            "qwen": QwenProvider(api_key=config.QWEN_API_KEY),
            "deepseek": DeepSeekProvider(api_key=config.DEEPSEEK_API_KEY),
            "openai": OpenAIProvider(api_key=config.OPENAI_API_KEY)
        }
        self.default_provider = config.DEFAULT_LLM_PROVIDER

    async def chat_stream_with_tools(
        self,
        messages: List[Dict],
        tools: List[Dict],
        user_id: str,
        model: Optional[str] = None
    ) -> AsyncIterator[LLMResponse]:
        """
        æµå¼èŠå¤© + å·¥å…·è°ƒç”¨
        æ”¯æŒ OpenAI å…¼å®¹çš„ Function Calling
        """
        provider = self.providers.get(model or self.default_provider)

        # 1. é¦–æ¬¡è°ƒç”¨ï¼ˆå¯èƒ½è¿”å›å·¥å…·è°ƒç”¨ï¼‰
        response = await provider.chat_complete(
            messages=messages,
            tools=tools,
            stream=True
        )

        # 2. æµå¼å¤„ç†
        tool_calls = []
        async for chunk in response:
            if chunk.type == "text":
                yield chunk

            elif chunk.type == "tool_call":
                tool_calls.append(chunk.tool_call)

                # 3. å·¥å…·æ‰§è¡Œ
                if chunk.tool_call.finish_reason == "stop":
                    tool_results = await self._execute_tools(tool_calls)

                    # 4. å°†ç»“æœåŠ å…¥ä¸Šä¸‹æ–‡
                    messages.extend([
                        {"role": "assistant", "tool_calls": tool_calls},
                        {"role": "tool", "content": json.dumps(tool_results)}
                    ])

                    # 5. ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆç”Ÿæˆæœ€ç»ˆå›ç­”ï¼‰
                    final_response = await provider.chat_complete(
                        messages=messages,
                        stream=True
                    )

                    async for final_chunk in final_response:
                        yield final_chunk

                    break

    async def _execute_tools(self, tool_calls: List[Dict]) -> List[Dict]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        results = []
        for call in tool_calls:
            tool = tool_registry.get_tool(call["name"])
            if tool:
                result = await tool.execute(**call["arguments"])
                results.append({
                    "tool_call_id": call["id"],
                    "result": result
                })
        return results
```

### 3.6 Python Agent ç”Ÿäº§çº§ç‰¹æ€§

| ç‰¹æ€§ | å®ç° | ä»·å€¼ |
|------|------|------|
| **æ¶ˆæ¯å»é‡** | MessageTracker + Redis | é˜²æ­¢é‡å¤å¤„ç† |
| **ç†”æ–­ä¿æŠ¤** | CircuitBreaker | é˜²æ­¢çº§è”æ•…éšœ |
| **å¹¶å‘æ§åˆ¶** | Session Lock + Redis | é¿å…èµ„æºç«äº‰ |
| **ä¸Šä¸‹æ–‡ä¿®å‰ª** | ContextPruner | èŠ‚çœ Token + æ€§èƒ½ |
| **åŠ¨æ€å·¥å…·** | è‡ªåŠ¨å‘ç° + æ³¨å†Œè¡¨ | çµæ´»æ‰©å±• |
| **ç›‘æ§åŸ‹ç‚¹** | Prometheus + Metrics | å¯è§‚æµ‹æ€§ |
| **å¼‚æ­¥å¤„ç†** | asyncio + é˜Ÿåˆ— | é«˜æ€§èƒ½ |
| **é”™è¯¯é™çº§** | Graceful Degradation | ç³»ç»Ÿç¨³å®šæ€§ |

---

## 4. Flutter Mobile - è·¨å¹³å°ç§»åŠ¨ç«¯

### 4.1 åº”ç”¨æ¶æ„

```
mobile/lib/
â”œâ”€â”€ main.dart                          # åº”ç”¨å…¥å£
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.dart                       # Riverpod é…ç½®
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ websocket_chat_service_v2.dart  # WebSocket æœåŠ¡
â”‚   â””â”€â”€ constants/
â”‚       â””â”€â”€ api_constants.dart         # API é…ç½®
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ chat_stream_events.dart    # æµäº‹ä»¶æ¨¡å‹
â”‚   â””â”€â”€ repositories/
â”œâ”€â”€ presentation/
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â””â”€â”€ chat_provider.dart         # Riverpod çŠ¶æ€ç®¡ç†
â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â”œâ”€â”€ chat_screen.dart           # èŠå¤©ç•Œé¢
â”‚   â”‚   â””â”€â”€ galaxy_screen.dart         # çŸ¥è¯†æ˜Ÿå›¾
â”‚   â””â”€â”€ widgets/
â”‚       â””â”€â”€ message_bubble.dart        # æ¶ˆæ¯æ°”æ³¡
â””â”€â”€ domain/
    â””â”€â”€ entities/                      # é¢†åŸŸå®ä½“
```

### 4.2 WebSocket æœåŠ¡ v2

#### 4.2.1 è¿æ¥ç®¡ç†

```dart
// mobile/lib/core/services/websocket_chat_service_v2.dart

class WebSocketChatServiceV2 {
  static final WebSocketChatServiceV2 _instance =
      WebSocketChatServiceV2._internal();
  factory WebSocketChatServiceV2() => _instance;

  WebSocketChannel? _channel;
  StreamController<ChatStreamEvent>? _messageStreamController;

  // è¿æ¥çŠ¶æ€ç®¡ç†
  WsConnectionState _connectionState = WsConnectionState.disconnected;
  Timer? _reconnectTimer;
  Timer? _heartbeatTimer;
  int _reconnectAttempts = 0;

  // æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆæ–­è¿æ—¶æš‚å­˜ï¼‰
  final List<Map<String, dynamic>> _pendingMessages = [];

  // å½“å‰ä¼šè¯
  String? _currentUserId;
  String? _currentSessionId;

  WebSocketChatServiceV2._internal();

  Stream<ChatStreamEvent> sendMessage({
    required String message,
    required String userId,
    String? sessionId,
  }) {
    // 1. åˆå§‹åŒ–æµæ§åˆ¶å™¨
    _messageStreamController ??= StreamController<ChatStreamEvent>.broadcast();

    // 2. ä¿å­˜ä¸Šä¸‹æ–‡
    _currentUserId = userId;
    _currentSessionId = sessionId ?? _generateSessionId();

    // 3. å»ºç«‹è¿æ¥
    if (_shouldConnect(userId)) {
      _establishConnection(userId);
    }

    // 4. æ„å»ºå¹¶å‘é€æ¶ˆæ¯
    final payload = {
      'message': message,
      'session_id': _currentSessionId,
      'user_id': userId,
    };

    if (isConnected) {
      _sendMessage(payload);
    } else {
      _pendingMessages.add(payload);
      _tryReconnect();
    }

    return _messageStreamController!.stream;
  }

  bool get isConnected => _connectionState == WsConnectionState.connected;

  bool _shouldConnect(String userId) {
    return _channel == null ||
           _connectionState == WsConnectionState.disconnected ||
           _currentUserId != userId;
  }

  void _establishConnection(String userId) {
    try {
      final wsUrl = '${ApiConstants.wsUrl}/ws/chat';
      _channel = WebSocketChannel.connect(Uri.parse(wsUrl));

      _connectionState = WsConnectionState.connecting;

      // ç›‘å¬æ¶ˆæ¯
      _channel!.stream.listen(
        _handleMessage,
        onError: _handleError,
        onDone: _handleDisconnect,
        cancelOnError: false,
      );

      // å‘é€è®¤è¯æ¶ˆæ¯
      _channel!.sink.add(json.encode({
        'type': 'auth',
        'token': getAuthToken(),
        'user_id': userId,
      }));

      _connectionState = WsConnectionState.connected;
      _reconnectAttempts = 0;

      // å¯åŠ¨å¿ƒè·³
      _startHeartbeat();

      // å‘é€å¾…å¤„ç†æ¶ˆæ¯
      _flushPendingMessages();

    } catch (e) {
      _handleError(e);
    }
  }

  void _sendMessage(Map<String, dynamic> payload) {
    if (_channel != null && isConnected) {
      _channel!.sink.add(json.encode(payload));
    }
  }

  void _handleMessage(dynamic data) {
    try {
      final message = json.decode(data);
      final event = _parseEvent(message);

      if (event != null && !_messageStreamController!.isClosed) {
        _messageStreamController!.add(event);
      }
    } catch (e) {
      _handleError(e);
    }
  }

  ChatStreamEvent? _parseEvent(Map<String, dynamic> message) {
    final type = message['type'];

    switch (type) {
      case 'text':
        return TextEvent(content: message['content']);

      case 'status':
        return StatusUpdateEvent(
          state: AgentState.fromString(message['state']),
          details: message['details'],
        );

      case 'tool_start':
        return ToolStartEvent(toolName: message['tool_name']);

      case 'tool_result':
        return ToolResultEvent(
          toolName: message['tool_name'],
          result: message['result'],
        );

      case 'error':
        return ErrorEvent(
          code: message['code'],
          message: message['message'],
        );

      case 'done':
        return DoneEvent();

      default:
        return null;
    }
  }
}
```

#### 4.2.2 é‡è¿æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰

```dart
void _handleDisconnect() {
  _connectionState = WsConnectionState.disconnected;
  _cancelHeartbeat();

  if (_reconnectAttempts < 5) {
    _triggerReconnect();
  } else {
    _messageStreamController?.add(
      ErrorEvent(code: 'MAX_RETRIES', message: 'æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨')
    );
  }
}

void _triggerReconnect() {
  _reconnectAttempts++;

  // æŒ‡æ•°é€€é¿ï¼š2^1, 2^2, 2^3, 2^4, 2^5 ç§’
  final delaySeconds = math.min(math.pow(2, _reconnectAttempts).toInt(), 32);

  _reconnectTimer = Timer(Duration(seconds: delaySeconds), () {
    if (_currentUserId != null) {
      _establishConnection(_currentUserId!);
    }
  });
}

void _tryReconnect() {
  if (!isConnected && _reconnectAttempts == 0) {
    _triggerReconnect();
  }
}
```

#### 4.2.3 å¿ƒè·³ä¿æ´»

```dart
void _startHeartbeat() {
  _cancelHeartbeat();

  _heartbeatTimer = Timer.periodic(Duration(seconds: 30), (timer) {
    if (isConnected && _channel != null) {
      _channel!.sink.add(json.encode({'type': 'ping'}));
    }
  });
}

void _cancelHeartbeat() {
  _heartbeatTimer?.cancel();
  _heartbeatTimer = null;
}
```

### 4.3 Riverpod çŠ¶æ€ç®¡ç†

#### 4.3.1 Provider æ¶æ„

```dart
// mobile/lib/presentation/providers/chat_provider.dart

// WebSocket æœåŠ¡ Provider
final webSocketServiceProvider = Provider<WebSocketChatServiceV2>((ref) {
  return WebSocketChatServiceV2();
});

// èŠå¤©çŠ¶æ€ Notifier
final chatProvider = StateNotifierProvider<ChatNotifier, ChatState>((ref) {
  return ChatNotifier(ref.watch(webSocketServiceProvider));
});

// èŠå¤©çŠ¶æ€
@freezed
class ChatState with _$ChatState {
  const factory ChatState({
    @Default([]) List<ChatMessage> messages,
    @Default(false) bool isLoading,
    @Default('') String response,
    @Default('') String error,
    @Default(null) AgentState? agentStatus,
    @Default(null) String? toolCalling,
    @Default(false) bool isTyping,
  }) = _ChatState;
}

// èŠå¤© Notifier
class ChatNotifier extends StateNotifier<ChatState> {
  final WebSocketChatServiceV2 _wsService;
  StreamSubscription? _subscription;

  ChatNotifier(this._wsService) : super(ChatState());

  Future<void> sendMessage(String message) async {
    // 1. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ç•Œé¢
    state = state.copyWith(
      messages: [
        ...state.messages,
        ChatMessage(role: 'user', content: message, timestamp: DateTime.now()),
      ],
      isLoading: true,
      error: '',
      response: '',
    );

    // 2. å‘é€æ¶ˆæ¯å¹¶ç›‘å¬å“åº”
    final stream = _wsService.sendMessage(
      message: message,
      userId: _getUserId(),
      sessionId: _getSessionId(),
    );

    // 3. å–æ¶ˆä¹‹å‰çš„è®¢é˜…
    await _subscription?.cancel();

    // 4. è®¢é˜…æ–°æµ
    _subscription = stream.listen(
      (event) => _handleStreamEvent(event),
      onError: _handleError,
      onDone: _handleDone,
    );
  }

  void _handleStreamEvent(ChatStreamEvent event) {
    event.when(
      text: (content) {
        // æ›´æ–°å“åº”æ–‡æœ¬
        state = state.copyWith(
          response: state.response + content,
          isTyping: true,
        );
      },

      statusUpdate: (agentState, details) {
        // æ›´æ–°ä»£ç†çŠ¶æ€
        state = state.copyWith(
          agentStatus: agentState,
          isTyping: agentState != AgentState.done,
        );

        // å¯ä»¥æ˜¾ç¤ºçŠ¶æ€åˆ° UI
        if (details != null) {
          _showStatusNotification(details);
        }
      },

      toolStart: (toolName) {
        // æ˜¾ç¤ºå·¥å…·è°ƒç”¨
        state = state.copyWith(toolCalling: toolName);
      },

      toolResult: (toolName, result) {
        // å¯ä»¥æ˜¾ç¤ºå·¥å…·ç»“æœ
        _showToolResult(toolName, result);
      },

      error: (code, message) {
        // é”™è¯¯å¤„ç†
        state = state.copyWith(
          error: message,
          isLoading: false,
          isTyping: false,
        );
      },

      done: () {
        // å®Œæˆå¤„ç†
        _handleDone();
      },
    );
  }

  void _handleDone() {
    if (state.response.isNotEmpty) {
      // æ·»åŠ  AI æ¶ˆæ¯åˆ°åˆ—è¡¨
      state = state.copyWith(
        messages: [
          ...state.messages,
          ChatMessage(
            role: 'assistant',
            content: state.response,
            timestamp: DateTime.now(),
          ),
        ],
        isLoading: false,
        isTyping: false,
        agentStatus: null,
        toolCalling: null,
      );
    }
  }

  void _handleError(dynamic error) {
    state = state.copyWith(
      error: error.toString(),
      isLoading: false,
      isTyping: false,
    );
  }

  @override
  void dispose() {
    _subscription?.cancel();
    super.dispose();
  }
}
```

### 4.4 UI ç•Œé¢å®ç°

#### 4.4.1 èŠå¤©ç•Œé¢

```dart
// mobile/lib/presentation/screens/chat_screen.dart

class ChatScreen extends ConsumerWidget {
  @override
  Widget build(BuildContext context, WidgetRef ref) {
    final chatState = ref.watch(chatProvider);
    final chatNotifier = ref.read(chatProvider.notifier);

    return Scaffold(
      appBar: AppBar(
        title: Text('AI åŠ©æ‰‹'),
        actions: [
          // è¿æ¥çŠ¶æ€æŒ‡ç¤ºå™¨
          _buildConnectionIndicator(chatState),
        ],
      ),

      body: Column(
        children: [
          // æ¶ˆæ¯åˆ—è¡¨
          Expanded(
            child: ListView.builder(
              itemCount: chatState.messages.length,
              itemBuilder: (context, index) {
                final message = chatState.messages[index];
                return MessageBubble(message: message);
              },
            ),
          ),

          // çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
          if (chatState.isLoading || chatState.agentStatus != null)
            _buildStatusPanel(chatState),

          // å·¥å…·è°ƒç”¨æç¤º
          if (chatState.toolCalling != null)
            _buildToolCallIndicator(chatState.toolCalling!),

          // è¾“å…¥åŒºåŸŸ
          _buildInputArea(context, chatNotifier, chatState),
        ],
      ),
    );
  }

  Widget _buildStatusPanel(ChatState state) {
    return Container(
      padding: EdgeInsets.all(12),
      color: Colors.blue.shade50,
      child: Row(
        children: [
          CircularProgressIndicator(),
          SizedBox(width: 12),
          Expanded(
            child: Text(
              _getStatusText(state.agentStatus),
              style: TextStyle(color: Colors.blue.shade800),
            ),
          ),
        ],
      ),
    );
  }

  Widget _buildToolCallIndicator(String toolName) {
    return Container(
      padding: EdgeInsets.symmetric(horizontal: 12, vertical: 8),
      color: Colors.orange.shade50,
      child: Row(
        children: [
          Icon(Icons.build, color: Colors.orange),
          SizedBox(width: 8),
          Text('è°ƒç”¨å·¥å…·: $toolName'),
        ],
      ),
    );
  }

  Widget _buildInputArea(
    BuildContext context,
    ChatNotifier notifier,
    ChatState state,
  ) {
    final controller = TextEditingController();

    return Container(
      padding: EdgeInsets.all(12),
      decoration: BoxDecoration(
        border: Border(top: BorderSide(color: Colors.grey.shade300)),
      ),
      child: Row(
        children: [
          Expanded(
            child: TextField(
              controller: controller,
              decoration: InputDecoration(
                hintText: 'è¾“å…¥æ¶ˆæ¯...',
                border: OutlineInputBorder(),
              ),
              enabled: !state.isLoading,
              onSubmitted: (value) {
                if (value.trim().isNotEmpty) {
                  notifier.sendMessage(value.trim());
                  controller.clear();
                }
              },
            ),
          ),
          SizedBox(width: 8),
          IconButton(
            icon: state.isLoading
                ? CircularProgressIndicator()
                : Icon(Icons.send),
            onPressed: state.isLoading
                ? null
                : () {
                    final text = controller.text.trim();
                    if (text.isNotEmpty) {
                      notifier.sendMessage(text);
                      controller.clear();
                    }
                  },
          ),
        ],
      ),
    );
  }
}
```

#### 4.4.2 æ¶ˆæ¯æ°”æ³¡ç»„ä»¶

```dart
// mobile/lib/presentation/widgets/message_bubble.dart

class MessageBubble extends StatelessWidget {
  final ChatMessage message;

  @override
  Widget build(BuildContext context) {
    final isUser = message.role == 'user';

    return Padding(
      padding: EdgeInsets.symmetric(horizontal: 16, vertical: 8),
      child: Row(
        mainAxisAlignment: isUser
            ? MainAxisAlignment.end
            : MainAxisAlignment.start,
        children: [
          if (!isUser) ...[
            CircleAvatar(
              child: Icon(Icons.smart_toy),
              backgroundColor: Colors.blue.shade100,
            ),
            SizedBox(width: 8),
          ],

          Flexible(
            child: Container(
              constraints: BoxConstraints(maxWidth: MediaQuery.of(context).size.width * 0.7),
              padding: EdgeInsets.all(12),
              decoration: BoxDecoration(
                color: isUser ? Colors.blue.shade50 : Colors.grey.shade100,
                borderRadius: BorderRadius.circular(16),
                border: Border.all(
                  color: isUser ? Colors.blue.shade200 : Colors.grey.shade300,
                ),
              ),
              child: Column(
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  Text(
                    message.content,
                    style: TextStyle(
                      fontSize: 16,
                      color: Colors.black87,
                    ),
                  ),
                  SizedBox(height: 4),
                  Text(
                    _formatTime(message.timestamp),
                    style: TextStyle(
                      fontSize: 12,
                      color: Colors.grey.shade600,
                    ),
                  ),
                ],
              ),
            ),
          ),

          if (isUser) ...[
            SizedBox(width: 8),
            CircleAvatar(
              child: Icon(Icons.person),
              backgroundColor: Colors.green.shade100,
            ),
          ],
        ],
      ),
    );
  }

  String _formatTime(DateTime time) {
    return '${time.hour.toString().padLeft(2, '0')}:${time.minute.toString().padLeft(2, '0')}';
  }
}
```

### 4.5 çŸ¥è¯†æ˜Ÿå›¾ç•Œé¢ï¼ˆGLSL ç€è‰²å™¨ï¼‰

```dart
// mobile/lib/presentation/screens/galaxy_screen.dart

class GalaxyScreen extends StatefulWidget {
  @override
  _GalaxyScreenState createState() => _GalaxyScreenState();
}

class _GalaxyScreenState extends State<GalaxyScreen>
    with SingleTickerProviderStateMixin {

  late AnimationController _controller;
  List<Node> nodes = [];

  @override
  void initState() {
    super.initState();
    _controller = AnimationController(
      vsync: this,
      duration: Duration(seconds: 2),
    )..repeat(reverse: true);

    _loadNodes();
  }

  Future<void> _loadNodes() async {
    // ä» API åŠ è½½çŸ¥è¯†èŠ‚ç‚¹
    final loadedNodes = await GalaxyService().getNodes();
    setState(() {
      nodes = loadedNodes;
    });
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: Text('çŸ¥è¯†æ˜Ÿå›¾')),
      body: CustomPaint(
        painter: GalaxyPainter(
          nodes: nodes,
          animation: _controller,
        ),
        size: Size.infinite,
      ),
      floatingActionButton: FloatingActionButton(
        child: Icon(Icons.refresh),
        onPressed: _loadNodes,
      ),
    );
  }
}

// è‡ªå®šä¹‰ç»˜åˆ¶å™¨
class GalaxyPainter extends CustomPainter {
  final List<Node> nodes;
  final Animation<double> animation;

  @override
  void paint(Canvas canvas, Size size) {
    final center = Offset(size.width / 2, size.height / 2);

    // ç»˜åˆ¶æ˜Ÿç³»èƒŒæ™¯
    _drawBackground(canvas, size);

    // ç»˜åˆ¶èŠ‚ç‚¹
    for (final node in nodes) {
      final offset = _calculatePosition(node, center, size);
      _drawNode(canvas, offset, node);
    }

    // ç»˜åˆ¶è¿æ¥çº¿
    _drawConnections(canvas, center);
  }

  void _drawBackground(Canvas canvas, Size size) {
    final paint = Paint()
      ..shader = RadialGradient(
        center: Alignment.center,
        radius: 0.8,
        colors: [
          Color(0xFF0A0E27),
          Color(0xFF1A1F3A),
          Colors.transparent,
        ],
      ).createShader(Rect.fromLTWH(0, 0, size.width, size.height))
      ..style = PaintingStyle.fill;

    canvas.drawRect(Rect.fromLTWH(0, 0, size.width, size.height), paint);
  }

  void _drawNode(Canvas canvas, Offset offset, Node node) {
    final radius = 8.0 + (node.importance * 4);
    final opacity = 0.6 + (node.mastery / 100) * 0.4;

    // å¤–å‘å…‰
    final glowPaint = Paint()
      ..color = Color(0xFF4FC3F7).withOpacity(opacity * 0.3)
      ..maskFilter = MaskFilter.blur(BlurStyle.normal, 8);

    canvas.drawCircle(offset, radius + 4, glowPaint);

    // èŠ‚ç‚¹æœ¬ä½“
    final nodePaint = Paint()
      ..color = Color(node.color)
      ..style = PaintingStyle.fill;

    canvas.drawCircle(offset, radius, nodePaint);

    // æŒæ¡åº¦ç¯
    if (node.mastery > 0) {
      final sweepPaint = Paint()
        ..color = Colors.greenAccent
        ..style = PaintingStyle.stroke
        ..strokeWidth = 2
        ..strokeCap = StrokeCap.round;

      canvas.drawArc(
        Rect.fromCircle(center: offset, radius: radius + 2),
        -90 * 3.14 / 180,
        (node.mastery / 100) * 2 * 3.14,
        false,
        sweepPaint,
      );
    }
  }

  Offset _calculatePosition(Node node, Offset center, Size size) {
    // åŸºäºèŠ‚ç‚¹å±‚çº§å’Œå…³ç³»è®¡ç®—ä½ç½®
    final angle = node.id.hashCode % 360 * 3.14 / 180;
    final distance = 50 + (node.level * 80);

    return Offset(
      center.dx + distance * math.cos(angle),
      center.dy + distance * math.sin(angle),
    );
  }

  @override
  bool shouldRepaint(GalaxyPainter oldDelegate) {
    return oldDelegate.nodes != nodes ||
           oldDelegate.animation.value != animation.value;
  }
}
```

---

## 5. æ•°æ®åº“æ¶æ„æ·±åº¦è§£æ

### 5.1 æ ¸å¿ƒè¡¨ç»“æ„è®¾è®¡

#### 5.1.1 çŸ¥è¯†ç³»ç»Ÿæ ¸å¿ƒè¡¨

```sql
-- ============================================
-- çŸ¥è¯†èŠ‚ç‚¹è¡¨ (Knowledge Nodes)
-- å­˜å‚¨çŸ¥è¯†ç‚¹åŠå…¶å‘é‡åµŒå…¥
-- ============================================
CREATE TABLE knowledge_nodes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    embedding VECTOR(1536),  -- pgvector å‘é‡ï¼Œ1536 ç»´ï¼ˆOpenAI åµŒå…¥ï¼‰
    parent_id UUID REFERENCES knowledge_nodes(id),
    subject_id INTEGER REFERENCES subjects(id),
    importance_level INTEGER NOT NULL DEFAULT 1,
    is_seed BOOLEAN DEFAULT FALSE,
    keywords JSONB,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),

    -- çº¦æŸ
    CONSTRAINT chk_importance CHECK (importance_level BETWEEN 1 AND 5)
);

-- HNSW ç´¢å¼•ï¼ˆå‘é‡æœç´¢åŠ é€Ÿï¼‰
CREATE INDEX idx_knowledge_nodes_embedding_hnsw
ON knowledge_nodes
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 16,
    ef_construction = 64,
    ef_search = 40
);

-- B-Tree ç´¢å¼•ï¼ˆç²¾ç¡®æŸ¥è¯¢ï¼‰
CREATE INDEX idx_knowledge_nodes_parent ON knowledge_nodes(parent_id);
CREATE INDEX idx_knowledge_nodes_subject ON knowledge_nodes(subject_id);

-- ============================================
-- ç”¨æˆ·èŠ‚ç‚¹çŠ¶æ€è¡¨ (User Node Status)
-- è®°å½•ç”¨æˆ·å¯¹æ¯ä¸ªçŸ¥è¯†ç‚¹çš„æŒæ¡åº¦
-- ============================================
CREATE TABLE user_node_status (
    user_id UUID NOT NULL,
    node_id UUID NOT NULL,
    mastery_score DOUBLE PRECISION NOT NULL DEFAULT 0,
    total_study_minutes INTEGER NOT NULL DEFAULT 0,
    study_count INTEGER DEFAULT 0,
    is_unlocked BOOLEAN NOT NULL DEFAULT FALSE,
    is_collapsed BOOLEAN DEFAULT FALSE,
    is_favorite BOOLEAN DEFAULT FALSE,
    last_study_at TIMESTAMP,
    next_review_at TIMESTAMP,
    decay_paused BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),

    PRIMARY KEY (user_id, node_id),
    CONSTRAINT chk_mastery CHECK (mastery_score BETWEEN 0 AND 100)
);

-- å¤åˆç´¢å¼•ï¼ˆæŸ¥è¯¢ç”¨æˆ·è¿›åº¦ï¼‰
CREATE INDEX idx_user_node_status_unlocked
ON user_node_status(user_id, is_unlocked)
WHERE is_unlocked = TRUE;

CREATE INDEX idx_user_node_status_review
ON user_node_status(user_id, next_review_at)
WHERE next_review_at IS NOT NULL;

-- ============================================
-- èŠ‚ç‚¹å…³ç³»è¡¨ (Node Relations)
-- çŸ¥è¯†å›¾è°±è¾¹ï¼Œå­˜å‚¨èŠ‚ç‚¹é—´å…³ç³»
-- ============================================
CREATE TABLE node_relations (
    source_node_id UUID NOT NULL REFERENCES knowledge_nodes(id),
    target_node_id UUID NOT NULL REFERENCES knowledge_nodes(id),
    relation_type VARCHAR(30) NOT NULL,
    strength DOUBLE PRECISION DEFAULT 1.0,
    created_by VARCHAR(20) DEFAULT 'system',
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),

    PRIMARY KEY (source_node_id, target_node_id),
    CONSTRAINT chk_relation_type CHECK (relation_type IN (
        'prerequisite', 'related', 'parent', 'child', 'similar'
    ))
);

-- ç´¢å¼•ï¼ˆå›¾éå†ï¼‰
CREATE INDEX idx_node_relations_source ON node_relations(source_node_id);
CREATE INDEX idx_node_relations_target ON node_relations(target_node_id);

-- ============================================
-- å­¦ä¹ è®°å½•è¡¨ (Study Records)
-- è¯¦ç»†è®°å½•æ¯æ¬¡å­¦ä¹ è¡Œä¸º
-- ============================================
CREATE TABLE study_records (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    node_id UUID NOT NULL,
    study_minutes INTEGER NOT NULL,
    mastery_delta DOUBLE PRECISION NOT NULL,
    study_method VARCHAR(50),
    completed_at TIMESTAMP NOT NULL DEFAULT NOW(),

    CONSTRAINT chk_minutes CHECK (study_minutes > 0)
);

-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æ—¶é—´åˆ†åŒºï¼Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼‰
CREATE INDEX idx_study_records_user_time
ON study_records(user_id, completed_at DESC);

-- ============================================
-- èŠ‚ç‚¹æ‹“å±•é˜Ÿåˆ— (Node Expansion Queue)
-- LLM è‡ªåŠ¨æ‹“å±•çŸ¥è¯†ç‚¹
-- ============================================
CREATE TABLE node_expansion_queue (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    node_id UUID NOT NULL REFERENCES knowledge_nodes(id),
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    priority INTEGER NOT NULL DEFAULT 5,
    result JSONB,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    processed_at TIMESTAMP,

    CONSTRAINT chk_status CHECK (status IN ('pending', 'processing', 'completed', 'failed'))
);

CREATE INDEX idx_expansion_queue_status
ON node_expansion_queue(status, priority)
WHERE status = 'pending';
```

#### 5.1.2 ç”¨æˆ·ä¸ä»»åŠ¡ç³»ç»Ÿ

```sql
-- ============================================
-- ç”¨æˆ·è¡¨ (Users)
-- ============================================
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    nickname VARCHAR(50),
    avatar_url TEXT,
    preferences JSONB DEFAULT '{}',
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- ============================================
-- ä»»åŠ¡è¡¨ (Tasks) - 6ç§ç±»å‹
-- ============================================
CREATE TYPE tasktype AS ENUM (
    'LEARNING',      -- å­¦ä¹ ä»»åŠ¡
    'TRAINING',      -- è®­ç»ƒä»»åŠ¡
    'ERROR_FIX',     -- é”™é¢˜ä¿®å¤
    'REFLECTION',    -- åæ€æ€»ç»“
    'SOCIAL',        -- ç¤¾äº¤å­¦ä¹ 
    'PLANNING'       -- è®¡åˆ’åˆ¶å®š
);

CREATE TYPE taskstatus AS ENUM (
    'PENDING', 'IN_PROGRESS', 'COMPLETED', 'CANCELLED'
);

CREATE TABLE tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    plan_id UUID,
    title VARCHAR(255) NOT NULL,
    type tasktype NOT NULL,
    tags JSONB NOT NULL DEFAULT '[]',
    estimated_minutes INTEGER NOT NULL,
    difficulty INTEGER NOT NULL,
    status taskstatus NOT NULL DEFAULT 'PENDING',
    knowledge_node_id UUID REFERENCES knowledge_nodes(id),
    auto_expand_enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    due_at TIMESTAMP,

    CONSTRAINT chk_difficulty CHECK (difficulty BETWEEN 1 AND 5)
);

CREATE INDEX idx_tasks_user_status ON tasks(user_id, status);
CREATE INDEX idx_tasks_type ON tasks(type);
CREATE INDEX idx_tasks_due ON tasks(user_id, due_at) WHERE due_at IS NOT NULL;

-- ============================================
-- è®¡åˆ’è¡¨ (Plans) - å†²åˆº/æˆé•¿è®¡åˆ’
-- ============================================
CREATE TYPE plantype AS ENUM ('SPRINT', 'GROWTH');

CREATE TABLE plans (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    type plantype NOT NULL,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    start_date DATE NOT NULL,
    end_date DATE NOT NULL,
    target_score INTEGER,
    progress JSONB DEFAULT '{}',
    status VARCHAR(20) DEFAULT 'active',
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_plans_user_date ON plans(user_id, start_date, end_date);
```

#### 5.1.3 æ™ºèƒ½æ¨é€ç³»ç»Ÿ

```sql
-- ============================================
-- æ¨é€åå¥½ (Push Preferences)
-- ============================================
CREATE TABLE push_preferences (
    user_id UUID PRIMARY KEY REFERENCES users(id),
    active_slots JSONB NOT NULL DEFAULT '[{"start": "08:00", "end": "22:00"}]',
    timezone VARCHAR(50) NOT NULL DEFAULT 'Asia/Shanghai',
    enable_curiosity BOOLEAN NOT NULL DEFAULT TRUE,
    persona_type VARCHAR(50) NOT NULL DEFAULT 'STUDENT',
    daily_cap INTEGER NOT NULL DEFAULT 3,
    last_push_time TIMESTAMP,
    consecutive_ignores INTEGER NOT NULL DEFAULT 0,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- ============================================
-- æ¨é€å†å² (Push Histories)
-- ç”¨äºé¢‘ç‡æ§åˆ¶å’Œå»é‡
-- ============================================
CREATE TABLE push_histories (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    trigger_type VARCHAR(50) NOT NULL,
    content_hash VARCHAR(64),
    status VARCHAR(50) NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_push_histories_user_time
ON push_histories(user_id, created_at DESC);

CREATE INDEX idx_push_histories_hash
ON push_histories(content_hash)
WHERE content_hash IS NOT NULL;

-- ============================================
-- é€šçŸ¥è¡¨ (Notifications)
-- ============================================
CREATE TABLE notifications (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    type VARCHAR(50) NOT NULL,
    title VARCHAR(255) NOT NULL,
    content TEXT,
    data JSONB,
    read BOOLEAN NOT NULL DEFAULT FALSE,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_notifications_user_read
ON notifications(user_id, read, created_at DESC);
```

#### 5.1.4 ç¤¾åŒºæ¨¡å—

```sql
-- ============================================
-- å¸–å­è¡¨ (Posts)
-- ============================================
CREATE TABLE posts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    tags JSONB DEFAULT '[]',
    visibility VARCHAR(20) DEFAULT 'public',
    like_count INTEGER DEFAULT 0,
    comment_count INTEGER DEFAULT 0,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_posts_user ON posts(user_id);
CREATE INDEX idx_posts_created ON posts(created_at DESC);

-- ============================================
-- ç‚¹èµè¡¨ (Post Likes)
-- ============================================
CREATE TABLE post_likes (
    post_id UUID NOT NULL REFERENCES posts(id),
    user_id UUID NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),

    PRIMARY KEY (post_id, user_id)
);
```

### 5.2 å…³é”®å…³ç³»å›¾

```
knowledge_nodes
    â”‚ 1:N
    â”œâ”€â–º user_node_status (æŒæ¡åº¦)
    â”‚       â”‚ N:1
    â”‚       â””â”€â–º users
    â”‚
    â”œâ”€â–º node_relations (å…³ç³»)
    â”‚       â”‚ N:1
    â”‚       â””â”€â–º knowledge_nodes (target)
    â”‚
    â”œâ”€â–º study_records (å­¦ä¹ å†å²)
    â”‚       â”‚ N:1
    â”‚       â””â”€â–º users
    â”‚
    â””â”€â–º tasks (å…³è”ä»»åŠ¡)
            â”‚ N:1
            â””â”€â–º users

users
    â”‚ 1:1
    â”œâ”€â–º push_preferences
    â”‚
    â”œâ”€â–º plans
    â”‚       â”‚ 1:N
    â”‚       â””â”€â–º tasks
    â”‚
    â”œâ”€â–º chat_messages
    â”‚
    â””â”€â–º notifications

posts
    â”‚ 1:N
    â””â”€â–º post_likes
            â”‚ N:1
            â””â”€â–º users
```

### 5.3 æ•°æ®åº“ä¼˜åŒ–ç­–ç•¥

#### 5.3.1 ç´¢å¼•ç­–ç•¥

```sql
-- 1. å‘é‡æœç´¢ä¼˜åŒ–ï¼ˆHNSW ç´¢å¼•ï¼‰
CREATE INDEX idx_knowledge_nodes_embedding_hnsw
ON knowledge_nodes
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64, ef_search = 40);

-- 2. éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æ´»è·ƒæ•°æ®ï¼‰
CREATE INDEX idx_user_node_status_active
ON user_node_status(user_id, mastery_score)
WHERE mastery_score < 100;

-- 3. å¤åˆç´¢å¼•ï¼ˆè¦†ç›–æŸ¥è¯¢ï¼‰
CREATE INDEX idx_study_records_covering
ON study_records(user_id, completed_at DESC)
INCLUDE (node_id, mastery_delta);

-- 4. BRIN ç´¢å¼•ï¼ˆæ—¶é—´åºåˆ—ï¼‰
CREATE INDEX idx_study_records_brin
ON study_records USING BRIN (completed_at);
```

#### 5.3.2 åˆ†åŒºç­–ç•¥

```sql
-- æŒ‰æ—¶é—´åˆ†åŒºå­¦ä¹ è®°å½•è¡¨
CREATE TABLE study_records (
    id UUID,
    user_id UUID,
    node_id UUID,
    study_minutes INTEGER,
    mastery_delta DOUBLE PRECISION,
    completed_at TIMESTAMP NOT NULL
) PARTITION BY RANGE (completed_at);

-- æœˆåº¦åˆ†åŒº
CREATE TABLE study_records_2025_12 PARTITION OF study_records
    FOR VALUES FROM ('2025-12-01') TO ('2026-01-01');
```

---

## 6. æ ¸å¿ƒåŠŸèƒ½å®ç°è¯¦è§£

### 6.1 çŸ¥è¯†æ˜Ÿå›¾ (Knowledge Galaxy)

#### 6.1.1 æ ¸å¿ƒæœåŠ¡æ¶æ„

```python
# backend/app/services/galaxy_service.py

class GalaxyService:
    """
    çŸ¥è¯†æ˜Ÿå›¾æ ¸å¿ƒæœåŠ¡
    èŒè´£ï¼šèŠ‚ç‚¹ç®¡ç†ã€æŒæ¡åº¦è®¡ç®—ã€å…³ç³»ç»´æŠ¤ã€RAG æ£€ç´¢
    """

    def __init__(self, db, redis, llm_service):
        self.db = db
        self.redis = redis
        self.llm = llm_service

        # å¸¸é‡é…ç½®
        self.BASE_MASTERY_POINTS = 5.0
        self.MAX_MASTERY = 100.0
        self.MEMORY_HALF_LIFE_DAYS = 7.0
        self.DECAY_THRESHOLD = 10.0

    async def spark_node(self, user_id: str, node_id: str,
                        study_minutes: int) -> SparkResult:
        """
        ç‚¹äº®çŸ¥è¯†ç‚¹ - æ ¸å¿ƒå­¦ä¹ æµç¨‹
        1. è·å–/åˆ›å»ºç”¨æˆ·çŠ¶æ€
        2. è®¡ç®—æŒæ¡åº¦å¢é‡
        3. æ›´æ–°çŠ¶æ€
        4. è®°å½•å†å²
        5. è§¦å‘æ‹“å±•
        """
        # 1. è·å–æˆ–åˆ›å»ºç”¨æˆ·èŠ‚ç‚¹çŠ¶æ€
        status = await self._get_or_create_status(user_id, node_id)

        # 2. è®¡ç®—æŒæ¡åº¦å¢é‡
        node = await self._get_node(node_id)
        mastery_delta = self._calculate_mastery_delta(
            study_minutes,
            node.importance_level,
            status.study_count
        )

        # 3. æ›´æ–°çŠ¶æ€
        new_mastery = min(status.mastery_score + mastery_delta, 100)
        status.mastery_score = new_mastery
        status.total_study_minutes += study_minutes
        status.study_count += 1
        status.last_study_at = datetime.utcnow()
        status.is_unlocked = True

        # 4. è®¡ç®—ä¸‹ä¸€æ¬¡å¤ä¹ æ—¶é—´ï¼ˆè‰¾å®¾æµ©æ–¯ï¼‰
        if new_mastery >= 60:
            status.next_review_at = self._calculate_next_review(
                status.study_count,
                new_mastery
            )

        # 5. è®°å½•å­¦ä¹ å†å²
        record = StudyRecord(
            user_id=user_id,
            node_id=node_id,
            study_minutes=study_minutes,
            mastery_delta=mastery_delta
        )
        self.db.add(record)

        # 6. è§¦å‘ LLM æ‹“å±•ï¼ˆå¦‚æœå­¦ä¹ æ¬¡æ•°è¾¾æ ‡ï¼‰
        if status.study_count >= 2:
            await self._queue_expansion(node_id)

        # 7. æ›´æ–° Redis ç¼“å­˜
        await self._update_user_cache(user_id, node_id, status)

        return SparkResult(
            mastery_delta=mastery_delta,
            new_mastery=new_mastery,
            next_review_at=status.next_review_at,
            expansion_queued=(status.study_count >= 2)
        )

    def _calculate_mastery_delta(self, study_minutes: int,
                                importance: int, study_count: int) -> float:
        """
        æŒæ¡åº¦å¢é‡è®¡ç®—
        å…¬å¼ï¼šåŸºç¡€åˆ† Ã— é‡è¦åº¦ç³»æ•° Ã— æ¬¡æ•°è¡°å‡ Ã— æ—¶é—´ç³»æ•°
        """
        # åŸºç¡€åˆ†ï¼šæ¯åˆ†é’Ÿå­¦ä¹ å¢åŠ  5 ç‚¹
        base = study_minutes * self.BASE_MASTERY_POINTS

        # é‡è¦åº¦ç³»æ•°ï¼š1-5 çº§ï¼Œæœ€é«˜ 2.0 å€
        importance_factor = 1 + (importance - 1) * 0.25

        # æ¬¡æ•°è¡°å‡ï¼šå­¦ä¹ æ¬¡æ•°è¶Šå¤šï¼Œå¢é‡è¶Šå°
        count_factor = 1.0 / (1 + study_count * 0.3)

        # æ—¶é—´ç³»æ•°ï¼šå­¦ä¹ æ—¶é—´è¶Šé•¿ï¼Œæ•ˆç‡è¶Šé«˜ï¼ˆä½†æœ‰ä¸Šé™ï¼‰
        time_factor = 1 + math.log10(study_minutes + 1) * 0.2

        delta = base * importance_factor * count_factor * time_factor

        return min(delta, 20.0)  # å•æ¬¡ä¸Šé™ 20 ç‚¹

    def _calculate_next_review(self, study_count: int, mastery: float) -> datetime:
        """
        è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿è®¡ç®—å¤ä¹ æ—¶é—´
        åŸºäº Ebbinghaus forgetting curve
        """
        # åŸºç¡€é—´éš”ï¼ˆå¤©ï¼‰
        if study_count <= 2:
            base_days = 1
        elif study_count <= 4:
            base_days = 3
        elif study_count <= 6:
            base_days = 7
        else:
            base_days = 14

        # æŒæ¡åº¦å½±å“ï¼šæŒæ¡åº¦è¶Šé«˜ï¼Œé—´éš”è¶Šé•¿
        mastery_factor = mastery / 50.0  # 0-2 å€

        # éšæœºå› å­ï¼šé¿å…æ‰€æœ‰ç”¨æˆ·åŒæ—¶å¤ä¹ 
        random_factor = random.uniform(0.8, 1.2)

        days = base_days * mastery_factor * random_factor

        return datetime.utcnow() + timedelta(days=days)

    async def hybrid_search(self, user_id: str, query: str,
                           vector_query: Optional[str] = None,
                           limit: int = 10) -> List[KnowledgeNode]:
        """
        RAG v2.0 æ··åˆæœç´¢
        ç»“åˆï¼šå‘é‡æœç´¢ + å…³é”®è¯æœç´¢ + ç”¨æˆ·çŠ¶æ€è¿‡æ»¤
        """
        # 1. å‡†å¤‡æŸ¥è¯¢å‘é‡
        query_embedding = await self.llm.get_embedding(
            vector_query if vector_query else query
        )

        # 2. å¹¶è¡Œæ‰§è¡Œå‘é‡æœç´¢å’Œå…³é”®è¯æœç´¢
        vector_task = self._vector_search(query_embedding, limit * 10)
        keyword_task = self._keyword_search(query, limit * 10)

        vector_results, keyword_results = await asyncio.gather(
            vector_task, keyword_task
        )

        # 3. RRF (Reciprocal Rank Fusion) èåˆ
        fused = self._reciprocal_rank_fusion(
            vector_results,
            keyword_results,
            weight_vector=0.7,
            weight_keyword=0.3
        )

        # 4. é‡æ’åºï¼ˆRe-rankingï¼‰
        reranked = await self._rerank(query, fused, limit)

        # 5. è·å–å®Œæ•´èŠ‚ç‚¹å¹¶è¿‡æ»¤
        nodes = await self._get_nodes_by_ids([r.node_id for r in reranked])
        filtered = await self._filter_by_user_status(user_id, nodes)

        return filtered

    def _reciprocal_rank_fusion(self, vector_results, keyword_results,
                               weight_vector=0.7, weight_keyword=0.3):
        """RRF èåˆç®—æ³•"""
        scores = {}

        # å‘é‡ç»“æœ
        for rank, result in enumerate(vector_results, 1):
            scores[result.node_id] = weight_vector * (1 / (rank + 60))

        # å…³é”®è¯ç»“æœ
        for rank, result in enumerate(keyword_results, 1):
            if result.node_id in scores:
                scores[result.node_id] += weight_keyword * (1 / (rank + 60))
            else:
                scores[result.node_id] = weight_keyword * (1 / (rank + 60))

        # æ’åº
        sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return [FusedResult(node_id=k, score=v) for k, v in sorted_results]

    async def _rerank(self, query: str, candidates: List[FusedResult],
                     top_k: int) -> List[FusedResult]:
        """ä½¿ç”¨ LLM è¿›è¡Œé‡æ’åº"""
        # æå–å€™é€‰å†…å®¹
        candidate_nodes = await self._get_nodes_by_ids([r.node_id for r in candidates])

        # æ„å»ºé‡æ’åºæç¤º
        prompt = self._build_rerank_prompt(query, candidate_nodes)

        # è°ƒç”¨ LLM
        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200
        )

        # è§£æç»“æœ
        ranked_ids = self._parse_rerank_response(response.content)

        # é‡æ–°æ’åº
        return sorted(candidates, key=lambda x: ranked_ids.index(x.node_id) if x.node_id in ranked_ids else 999)
```

#### 6.1.2 çŸ¥è¯†æ‹“å±•æœåŠ¡

```python
# backend/app/services/expansion_service.py

class ExpansionService:
    """
    LLM é©±åŠ¨çš„çŸ¥è¯†æ‹“å±•æœåŠ¡
    è‡ªåŠ¨ä¸ºçŸ¥è¯†ç‚¹ç”Ÿæˆç›¸å…³å†…å®¹ã€ç»ƒä¹ é¢˜ã€å…³è”çŸ¥è¯†
    """

    def __init__(self, db, llm_service, galaxy_service):
        self.db = db
        self.llm = llm_service
        self.galaxy = galaxy_service

    async def queue_expansion(self, node_id: str, priority: int = 5):
        """å°†èŠ‚ç‚¹åŠ å…¥æ‹“å±•é˜Ÿåˆ—"""
        queue_item = NodeExpansionQueue(
            node_id=node_id,
            status='pending',
            priority=priority
        )
        self.db.add(queue_item)
        await self.db.commit()

        # æ¨é€åˆ° Redis é˜Ÿåˆ—ï¼ˆç”¨äºåå°å¤„ç†ï¼‰
        await self.redis.rpush(
            'queue:expansion',
            json.dumps({
                'node_id': node_id,
                'queue_id': str(queue_item.id),
                'priority': priority
            })
        )

    async def process_expansion(self, node_id: str):
        """å¤„ç†å•ä¸ªèŠ‚ç‚¹çš„æ‹“å±•"""
        # 1. è·å–èŠ‚ç‚¹ä¿¡æ¯
        node = await self.galaxy._get_node(node_id)

        # 2. ç”Ÿæˆæ‹“å±•å†…å®¹
        expansion_result = await self._generate_expansion(node)

        # 3. åˆ›å»ºå­èŠ‚ç‚¹
        for child in expansion_result['children']:
            child_node = KnowledgeNode(
                name=child['name'],
                description=child['description'],
                parent_id=node_id,
                subject_id=node.subject_id,
                importance_level=node.importance_level - 1,
                is_seed=False
            )
            self.db.add(child_node)
            await self.db.flush()

            # 4. å»ºç«‹å…³ç³»
            relation = NodeRelations(
                source_node_id=node_id,
                target_node_id=child_node.id,
                relation_type='child',
                strength=0.8
            )
            self.db.add(relation)

        # 5. ç”Ÿæˆç»ƒä¹ é¢˜
        for question in expansion_result['questions']:
            # åˆ›å»ºä»»åŠ¡æ¨¡æ¿
            task = TaskTemplate(
                node_id=node_id,
                title=question['question'],
                type='TRAINING',
                estimated_minutes=5,
                difficulty=question['difficulty']
            )
            self.db.add(task)

        # 6. æ›´æ–°é˜Ÿåˆ—çŠ¶æ€
        queue_item = await self.db.execute(
            select(NodeExpansionQueue).where(
                NodeExpansionQueue.node_id == node_id
            )
        )
        queue_item.status = 'completed'
        queue_item.result = expansion_result
        queue_item.processed_at = datetime.utcnow()

        await self.db.commit()

    async def _generate_expansion(self, node: KnowledgeNode) -> dict:
        """è°ƒç”¨ LLM ç”Ÿæˆæ‹“å±•å†…å®¹"""
        prompt = f"""
        åŸºäºä»¥ä¸‹çŸ¥è¯†ç‚¹ï¼Œç”Ÿæˆæ‹“å±•å†…å®¹ï¼š

        çŸ¥è¯†ç‚¹ï¼š{node.name}
        æè¿°ï¼š{node.description}
        é‡è¦åº¦ï¼š{node.importance_level}

        è¯·ç”Ÿæˆï¼š
        1. 3-5 ä¸ªç›¸å…³çš„å­çŸ¥è¯†ç‚¹
        2. 2-3 ä¸ªç»ƒä¹ é¢˜ï¼ˆå¸¦ç­”æ¡ˆï¼‰
        3. 1-2 ä¸ªå®é™…åº”ç”¨ä¾‹å­

        æ ¼å¼ï¼š
        {{
            "children": [
                {{"name": "...", "description": "..."}}
            ],
            "questions": [
                {{"question": "...", "answer": "...", "difficulty": 3}}
            ],
            "examples": ["..."]
        }}
        """

        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.7
        )

        return json.loads(response.content)
```

### 6.2 æ™ºèƒ½æ¨é€ç³»ç»Ÿ (Smart Push)

#### 6.2.1 æ¨é€æœåŠ¡æ¶æ„

```python
# backend/app/services/push_service.py

class PushService:
    """
    æ™ºèƒ½æ¨é€æœåŠ¡
    ç­–ç•¥ï¼šå†²åˆºã€è®°å¿†ã€æ´»è·ƒåº¦ã€å¥½å¥‡å¿ƒ
    """

    def __init__(self, db, redis, llm_service):
        self.db = db
        self.redis = redis
        self.llm = llm_service

        # ç­–ç•¥å®ä¾‹
        self.sprint_strategy = SprintStrategy(db, redis)
        self.memory_strategy = MemoryStrategy(db, redis)
        self.inactivity_strategy = InactivityStrategy(db, redis)
        self.curiosity_strategy = CuriosityStrategy(db, redis)

    async def process_user_push(self, user: User) -> bool:
        """
        å¤„ç†å•ä¸ªç”¨æˆ·çš„æ¨é€é€»è¾‘
        è¿”å›ï¼šæ˜¯å¦æˆåŠŸæ¨é€
        """
        # 1. è·å–ç”¨æˆ·åå¥½
        pref = await self._get_push_preferences(user.id)

        # 2. æ£€æŸ¥æ—¶åŒºå’Œæ´»è·ƒæ—¶æ®µ
        if not self._is_active_time(pref):
            return False

        # 3. æ£€æŸ¥é¢‘ç‡é™åˆ¶ï¼ˆæ¯æ—¥ä¸Šé™ï¼‰
        if await self._check_daily_cap(user.id, pref.daily_cap):
            return False

        # 4. æ£€æŸ¥å†·å´æœŸï¼ˆé¿å…é¢‘ç¹æ‰“æ‰°ï¼‰
        if await self._check_cooldown(user.id):
            return False

        # 5. ç­–ç•¥è¯„ä¼°ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰
        trigger_strategy, trigger_data = await self._evaluate_strategies(
            user, pref
        )

        if not trigger_strategy:
            return False

        # 6. ç”Ÿæˆæ¨é€å†…å®¹
        content = await self._generate_push_content(
            user, trigger_strategy, trigger_data
        )

        # 7. å‘é€æ¨é€
        success = await self._send_push(user, content)

        if success:
            # 8. è®°å½•å†å²
            await self._record_push_history(
                user.id,
                trigger_strategy.name,
                content
            )

            # 9. é‡ç½®å¿½ç•¥è®¡æ•°
            await self._reset_ignore_count(user.id)

        return success

    async def _evaluate_strategies(self, user: User, pref: PushPreferences):
        """
        ç­–ç•¥è¯„ä¼°ï¼ˆä¼˜å…ˆçº§ï¼šSprint > Curiosity > Memory > Inactivityï¼‰
        """
        # 1. å†²åˆºç­–ç•¥ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if await self.sprint_strategy.should_trigger(user, pref):
            data = await self.sprint_strategy.get_trigger_data(user)
            return self.sprint_strategy, data

        # 2. å¥½å¥‡å¿ƒç­–ç•¥
        if pref.enable_curiosity and await self.curiosity_strategy.should_trigger(user, pref):
            data = await self.curiosity_strategy.get_trigger_data(user)
            return self.curiosity_strategy, data

        # 3. è®°å¿†ç­–ç•¥
        if await self.memory_strategy.should_trigger(user, pref):
            data = await self.memory_strategy.get_trigger_data(user)
            return self.memory_strategy, data

        # 4. æ´»è·ƒåº¦ç­–ç•¥
        if await self.inactivity_strategy.should_trigger(user, pref):
            data = await self.inactivity_strategy.get_trigger_data(user)
            return self.inactivity_strategy, data

        return None, None

    async def _generate_push_content(self, user: User, strategy, trigger_data: dict) -> dict:
        """ä½¿ç”¨ LLM ç”Ÿæˆä¸ªæ€§åŒ–æ¨é€å†…å®¹"""
        prompt = f"""
        ä¸ºç”¨æˆ·ç”Ÿæˆä¸ªæ€§åŒ–æ¨é€å†…å®¹ï¼š

        ç”¨æˆ·ï¼š{user.nickname}
        ç­–ç•¥ï¼š{strategy.name}
        è§¦å‘æ•°æ®ï¼š{json.dumps(trigger_data, ensure_ascii=False)}

        è¦æ±‚ï¼š
        1. è¯­æ°”äº²åˆ‡ã€æ¿€åŠ±æ€§
        2. å†…å®¹å…·ä½“ã€æœ‰ä»·å€¼
        3. é•¿åº¦é€‚ä¸­ï¼ˆ50-100å­—ï¼‰
        4. åŒ…å«è¡ŒåŠ¨å·å¬

        è¿”å›æ ¼å¼ï¼š
        {{
            "title": "...",
            "body": "...",
            "data": {{"action": "...", "params": {{...}}}}
        }}
        """

        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0.8
        )

        return json.loads(response.content)
```

#### 6.2.2 å†²åˆºç­–ç•¥å®ç°

```python
# backend/app/services/strategies/sprint.py

class SprintStrategy:
    """
    å†²åˆºç­–ç•¥ï¼šæ£€æµ‹ç”¨æˆ·æ˜¯å¦æœ‰æœªå®Œæˆçš„å†²åˆºè®¡åˆ’
    """

    name = "sprint"

    async def should_trigger(self, user: User, pref: PushPreferences) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘"""
        # 1. è·å–æ´»è·ƒå†²åˆº
        sprint = await self._get_active_sprint(user.id)
        if not sprint:
            return False

        # 2. æ£€æŸ¥å‰©ä½™æ—¶é—´ï¼ˆ< 24 å°æ—¶ï¼‰
        time_left = sprint.end_date - datetime.utcnow().date()
        if time_left.days > 1:
            return False

        # 3. æ£€æŸ¥å®Œæˆåº¦ï¼ˆ< 80%ï¼‰
        progress = self._calculate_sprint_progress(sprint)
        if progress >= 80:
            return False

        # 4. æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²æ¨é€
        if await self._has_today_sprint_push(user.id):
            return False

        return True

    async def get_trigger_data(self, user: User) -> dict:
        """è·å–è§¦å‘æ•°æ®"""
        sprint = await self._get_active_sprint(user.id)
        progress = self._calculate_sprint_progress(sprint)
        remaining_tasks = await self._get_remaining_tasks(user.id, sprint.id)

        return {
            "sprint_title": sprint.title,
            "progress": progress,
            "remaining_tasks": len(remaining_tasks),
            "due_date": sprint.end_date.isoformat(),
            "motivation_score": self._calculate_motivation(progress)
        }

    def _calculate_motivation(self, progress: float) -> str:
        """è®¡ç®—æ¿€åŠ±ç­‰çº§"""
        if progress < 30:
            return "high"  # éœ€è¦å¼ºæ¿€åŠ±
        elif progress < 60:
            return "medium"
        else:
            return "low"  # è½»å¾®æé†’å³å¯
```

#### 6.2.3 è®°å¿†ç­–ç•¥ï¼ˆè‰¾å®¾æµ©æ–¯ï¼‰

```python
# backend/app/services/strategies/memory.py

class MemoryStrategy:
    """
    è®°å¿†ç­–ç•¥ï¼šåŸºäºè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿çš„å¤ä¹ æé†’
    """

    name = "memory"

    async def should_trigger(self, user: User, pref: PushPreferences) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å¤ä¹ çš„çŸ¥è¯†ç‚¹"""
        # 1. è·å–éœ€è¦å¤ä¹ çš„èŠ‚ç‚¹
        review_nodes = await self._get_review_nodes(user.id)

        if not review_nodes:
            return False

        # 2. æ£€æŸ¥å¤ä¹ æ•°é‡ï¼ˆè‡³å°‘ 3 ä¸ªï¼‰
        if len(review_nodes) < 3:
            return False

        # 3. æ£€æŸ¥ä¸Šæ¬¡å¤ä¹ æ—¶é—´é—´éš”
        if await self._check_recent_review(user.id, hours=4):
            return False

        return True

    async def get_trigger_data(self, user: User) -> dict:
        """è·å–éœ€è¦å¤ä¹ çš„èŠ‚ç‚¹"""
        review_nodes = await self._get_review_nodes(user.id)

        # æŒ‰ç´§æ€¥ç¨‹åº¦æ’åº
        sorted_nodes = sorted(
            review_nodes,
            key=lambda x: x['urgency_score'],
            reverse=True
        )

        return {
            "review_count": len(sorted_nodes),
            "top_nodes": sorted_nodes[:5],
            "total_study_time": sum(n['study_minutes'] for n in sorted_nodes)
        }

    async def _get_review_nodes(self, user_id: str) -> List[dict]:
        """è·å–éœ€è¦å¤ä¹ çš„èŠ‚ç‚¹"""
        query = """
        SELECT
            kn.name,
            uns.mastery_score,
            uns.next_review_at,
            uns.total_study_minutes,
            EXTRACT(EPOCH FROM (uns.next_review_at - NOW())) / 3600 AS hours_until_review,
            (uns.mastery_score / 100) * (1 / GREATEST(EXTRACT(EPOCH FROM (NOW() - uns.last_study_at)) / 3600, 1)) AS urgency_score
        FROM user_node_status uns
        JOIN knowledge_nodes kn ON uns.node_id = kn.id
        WHERE uns.user_id = :user_id
          AND uns.next_review_at <= NOW() + INTERVAL '24 hours'
          AND uns.next_review_at IS NOT NULL
          AND uns.mastery_score < 95
        ORDER BY urgency_score DESC
        LIMIT 20
        """

        result = await self.db.execute(query, {"user_id": user_id})
        return [dict(row) for row in result]
```

### 6.3 é—å¿˜æ›²çº¿æœåŠ¡ (Decay Service)

```python
# backend/app/services/decay_service.py

class DecayService:
    """
    é—å¿˜æ›²çº¿æœåŠ¡
    åŸºäºè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿ï¼Œè‡ªåŠ¨è®¡ç®—çŸ¥è¯†ç‚¹çš„è¡°å‡
    """

    def __init__(self, db, redis):
        self.db = db
        self.redis = redis

    async def apply_decay(self, user_id: str, node_id: str) -> float:
        """
        åº”ç”¨é—å¿˜è¡°å‡
        è¿”å›ï¼šè¡°å‡åçš„æŒæ¡åº¦
        """
        # 1. è·å–ç”¨æˆ·èŠ‚ç‚¹çŠ¶æ€
        status = await self._get_user_node_status(user_id, node_id)

        if not status or status.decay_paused:
            return status.mastery_score if status else 0

        # 2. è®¡ç®—ç»è¿‡çš„æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        if not status.last_study_at:
            return status.mastery_score

        hours_passed = (datetime.utcnow() - status.last_study_at).total_seconds() / 3600

        if hours_passed < 24:  # 24å°æ—¶å†…ä¸è¡°å‡
            return status.mastery_score

        # 3. è‰¾å®¾æµ©æ–¯è¡°å‡å…¬å¼
        # è¡°å‡ç³»æ•° = 2^(-t / T_half)
        # T_half = 7 å¤© = 168 å°æ—¶
        half_life_hours = 7 * 24  # 168 å°æ—¶

        decay_factor = 2 ** (-hours_passed / half_life_hours)

        # 4. è®¡ç®—æ–°æŒæ¡åº¦
        original_mastery = status.mastery_score
        new_mastery = original_mastery * decay_factor

        # 5. åº”ç”¨æœ€å°é˜ˆå€¼ï¼ˆé˜²æ­¢å®Œå…¨é—å¿˜ï¼‰
        new_mastery = max(new_mastery, self.DECAY_THRESHOLD)

        # 6. æ›´æ–°æ•°æ®åº“
        status.mastery_score = new_mastery
        status.updated_at = datetime.utcnow()

        # 7. è®°å½•è¡°å‡å†å²ï¼ˆç”¨äºåˆ†æï¼‰
        await self._record_decay_history(user_id, node_id,
                                        original_mastery, new_mastery, hours_passed)

        await self.db.commit()

        return new_mastery

    async def batch_decay(self, user_id: str):
        """æ‰¹é‡å¤„ç†ç”¨æˆ·æ‰€æœ‰çŸ¥è¯†ç‚¹çš„è¡°å‡"""
        # 1. è·å–ç”¨æˆ·æ‰€æœ‰æœªæŒæ¡çš„çŸ¥è¯†ç‚¹
        query = """
        SELECT node_id, mastery_score, last_study_at
        FROM user_node_status
        WHERE user_id = :user_id
          AND mastery_score < 95
          AND decay_paused = FALSE
        """

        result = await self.db.execute(query, {"user_id": user_id})
        nodes = result.fetchall()

        # 2. å¹¶è¡Œå¤„ç†è¡°å‡
        decay_tasks = [
            self.apply_decay(user_id, node.node_id)
            for node in nodes
        ]

        new_masteries = await asyncio.gather(*decay_tasks)

        # 3. è¿”å›ç»Ÿè®¡ä¿¡æ¯
        total_decay = sum(
            node.mastery_score - new_masteries[i]
            for i, node in enumerate(nodes)
        )

        return {
            "nodes_processed": len(nodes),
            "total_decay": total_decay,
            "average_decay": total_decay / len(nodes) if nodes else 0
        }

    async def pause_decay(self, user_id: str, node_id: str):
        """æš‚åœè¡°å‡ï¼ˆç”¨äºå·²æŒæ¡çš„çŸ¥è¯†ç‚¹ï¼‰"""
        status = await self._get_user_node_status(user_id, node_id)
        if status:
            status.decay_paused = True
            await self.db.commit()

    async def resume_decay(self, user_id: str, node_id: str):
        """æ¢å¤è¡°å‡"""
        status = await self._get_user_node_status(user_id, node_id)
        if status:
            status.decay_paused = False
            status.last_study_at = datetime.utcnow()  # é‡ç½®æ—¶é—´
            await self.db.commit()
```

### 6.4 ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ

```python
# backend/app/services/task_service.py

class TaskService:
    """
    ä»»åŠ¡ç®¡ç†æœåŠ¡
    æ”¯æŒ 6 ç§ä»»åŠ¡ç±»å‹ï¼šå­¦ä¹ ã€è®­ç»ƒã€é”™é¢˜ã€åæ€ã€ç¤¾äº¤ã€è®¡åˆ’
    """

    TASK_TYPES = {
        'LEARNING': 'å­¦ä¹ ä»»åŠ¡',
        'TRAINING': 'è®­ç»ƒä»»åŠ¡',
        'ERROR_FIX': 'é”™é¢˜ä¿®å¤',
        'REFLECTION': 'åæ€æ€»ç»“',
        'SOCIAL': 'ç¤¾äº¤å­¦ä¹ ',
        'PLANNING': 'è®¡åˆ’åˆ¶å®š'
    }

    async def create_task(self, user_id: str, task_data: dict) -> Task:
        """åˆ›å»ºä»»åŠ¡"""
        # 1. éªŒè¯ä»»åŠ¡ç±»å‹
        if task_data['type'] not in self.TASK_TYPES:
            raise ValueError(f"Invalid task type: {task_data['type']}")

        # 2. å¦‚æœå…³è”çŸ¥è¯†ç‚¹ï¼Œæ£€æŸ¥è§£é”çŠ¶æ€
        if 'knowledge_node_id' in task_data:
            node_status = await self._check_node_unlocked(
                user_id,
                task_data['knowledge_node_id']
            )
            if not node_status:
                raise ValueError("Knowledge node not unlocked")

        # 3. åˆ›å»ºä»»åŠ¡
        task = Task(
            user_id=user_id,
            title=task_data['title'],
            type=task_data['type'],
            tags=json.dumps(task_data.get('tags', [])),
            estimated_minutes=task_data['estimated_minutes'],
            difficulty=task_data.get('difficulty', 3),
            knowledge_node_id=task_data.get('knowledge_node_id'),
            auto_expand_enabled=task_data.get('auto_expand', True)
        )

        self.db.add(task)
        await self.db.commit()

        # 4. å¦‚æœæ˜¯å­¦ä¹ ä»»åŠ¡ï¼Œè‡ªåŠ¨å…³è”å†²åˆºè®¡åˆ’
        if task.type == 'LEARNING':
            await self._link_to_sprint_plan(user_id, task.id)

        return task

    async def execute_task(self, user_id: str, task_id: str,
                          actual_minutes: int) -> TaskExecutionResult:
        """æ‰§è¡Œä»»åŠ¡"""
        # 1. è·å–ä»»åŠ¡
        task = await self.db.get(Task, task_id)
        if not task or task.user_id != user_id:
            raise ValueError("Task not found")

        # 2. æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.status = 'COMPLETED'

        # 3. å¦‚æœå…³è”çŸ¥è¯†ç‚¹ï¼Œæ›´æ–°æŒæ¡åº¦
        mastery_delta = 0
        if task.knowledge_node_id:
            galaxy_service = GalaxyService(self.db, self.redis, None)
            result = await galaxy_service.spark_node(
                user_id,
                task.knowledge_node_id,
                actual_minutes
            )
            mastery_delta = result.mastery_delta

        # 4. è®°å½•æ‰§è¡Œå†å²
        execution = TaskExecution(
            task_id=task_id,
            actual_minutes=actual_minutes,
            mastery_delta=mastery_delta
        )
        self.db.add(execution)

        # 5. è‡ªåŠ¨æ‰©å±•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if task.auto_expand_enabled and task.knowledge_node_id:
            expansion_service = ExpansionService(self.db, None, None)
            await expansion_service.queue_expansion(
                task.knowledge_node_id,
                priority=3
            )

        await self.db.commit()

        return TaskExecutionResult(
            task=task,
            mastery_delta=mastery_delta,
            expansion_queued=task.auto_expand_enabled
        )

    async def get_daily_tasks(self, user_id: str, date: date) -> List[Task]:
        """è·å–æ¯æ—¥ä»»åŠ¡"""
        query = """
        SELECT * FROM tasks
        WHERE user_id = :user_id
          AND DATE(created_at) = :date
          AND status != 'CANCELLED'
        ORDER BY
            CASE type
                WHEN 'LEARNING' THEN 1
                WHEN 'TRAINING' THEN 2
                WHEN 'ERROR_FIX' THEN 3
                WHEN 'REFLECTION' THEN 4
                WHEN 'SOCIAL' THEN 5
                WHEN 'PLANNING' THEN 6
            END,
            difficulty DESC
        """

        result = await self.db.execute(query, {
            "user_id": user_id,
            "date": date
        })

        return result.fetchall()

    async def suggest_tasks(self, user_id: str, context: dict) -> List[dict]:
        """æ™ºèƒ½ä»»åŠ¡å»ºè®®"""
        # 1. åˆ†æç”¨æˆ·å½“å‰çŠ¶æ€
        progress = await self._get_learning_progress(user_id)

        # 2. åŸºäºçŠ¶æ€ç”Ÿæˆå»ºè®®
        suggestions = []

        # 2.1 éœ€è¦å¤ä¹ çš„çŸ¥è¯†ç‚¹
        if progress['review_needed'] > 0:
            suggestions.append({
                "type": "TRAINING",
                "title": f"å¤ä¹  {progress['review_needed']} ä¸ªçŸ¥è¯†ç‚¹",
                "estimated_minutes": 30,
                "priority": "high"
            })

        # 2.2 é”™é¢˜ä¿®å¤
        if progress['error_count'] > 0:
            suggestions.append({
                "type": "ERROR_FIX",
                "title": f"ä¿®å¤ {progress['error_count']} ä¸ªé”™é¢˜",
                "estimated_minutes": 20,
                "priority": "high"
            })

        # 2.3 æ–°çŸ¥è¯†ç‚¹å­¦ä¹ 
        if progress['unlocked_nodes'] < 20:
            suggestions.append({
                "type": "LEARNING",
                "title": "å­¦ä¹ æ–°çŸ¥è¯†ç‚¹",
                "estimated_minutes": 40,
                "priority": "medium"
            })

        # 2.4 åæ€æ€»ç»“
        if progress['study_count'] > 5:
            suggestions.append({
                "type": "REFLECTION",
                "title": "æœ¬å‘¨å­¦ä¹ æ€»ç»“",
                "estimated_minutes": 15,
                "priority": "low"
            })

        return suggestions
```

---

## 7. ç”Ÿäº§çº§ç‰¹æ€§ä¸å¢å¼º

### 7.1 ç†”æ–­å™¨ (Circuit Breaker)

```python
# backend/app/orchestration/circuit_breaker.py

class CircuitBreaker:
    """
    ç†”æ–­å™¨æ¨¡å¼å®ç°
    çŠ¶æ€ï¼šCLOSEDï¼ˆæ­£å¸¸ï¼‰ã€OPENï¼ˆç†”æ–­ï¼‰ã€HALF_OPENï¼ˆåŠå¼€ï¼‰
    """

    def __init__(self, failure_threshold=5, recovery_timeout=60):
        self.failure_threshold = failure_threshold  # å¤±è´¥é˜ˆå€¼
        self.recovery_timeout = recovery_timeout    # æ¢å¤è¶…æ—¶ï¼ˆç§’ï¼‰

        self.failure_count = 0
        self.last_failure_time = 0
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN

        # Redis ç”¨äºåˆ†å¸ƒå¼çŠ¶æ€
        self.redis_key = "circuit_breaker:state"

    async def can_execute(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œ"""
        # ä» Redis è·å–å½“å‰çŠ¶æ€ï¼ˆåˆ†å¸ƒå¼ï¼‰
        state = await self._get_state_from_redis()

        if state == "OPEN":
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() - self.last_failure_time > self.recovery_timeout:
                # è¿›å…¥åŠå¼€çŠ¶æ€
                await self._set_state("HALF_OPEN")
                return True
            return False

        if state == "HALF_OPEN":
            # å…è®¸ä¸€ä¸ªè¯·æ±‚é€šè¿‡
            return True

        return True  # CLOSED

    async def record_success(self):
        """è®°å½•æˆåŠŸ"""
        if self.state == "HALF_OPEN":
            # æ¢å¤æ­£å¸¸
            await self._set_state("CLOSED")
            self.failure_count = 0

    async def record_failure(self):
        """è®°å½•å¤±è´¥"""
        self.failure_count += 1
        self.last_failure_time = time.time()

        if self.failure_count >= self.failure_threshold:
            await self._set_state("OPEN")
            # å‘é€å‘Šè­¦
            await self._send_alert("Circuit breaker opened")

    async def _get_state_from_redis(self) -> str:
        """ä» Redis è·å–çŠ¶æ€"""
        state = await self.redis.get(self.redis_key)
        return state.decode("utf-8") if state else "CLOSED"

    async def _set_state(self, state: str):
        """è®¾ç½®çŠ¶æ€åˆ° Redis"""
        self.state = state
        await self.redis.setex(
            self.redis_key,
            3600,  # 1å°æ—¶TTL
            state
        )

    async def _send_alert(self, message: str):
        """å‘é€å‘Šè­¦"""
        # å¯é›†æˆ Slackã€é’‰é’‰ã€é‚®ä»¶ç­‰
        logger.critical(f"ALERT: {message}")
```

### 7.2 æ¶ˆæ¯å»é‡ (Message Deduplication)

```python
# backend/app/orchestration/message_tracker.py

class MessageTracker:
    """
    æ¶ˆæ¯å»é‡è¿½è¸ªå™¨
    é˜²æ­¢é‡å¤å¤„ç†ç›¸åŒè¯·æ±‚
    """

    def __init__(self, redis_client):
        self.redis = redis_client
        self.ttl = 3600  # 1å°æ—¶

    async def is_processed(self, request_id: str) -> bool:
        """æ£€æŸ¥è¯·æ±‚æ˜¯å¦å·²å¤„ç†"""
        key = f"processed:{request_id}"
        result = await self.redis.get(key)
        return result is not None

    async def mark_processed(self, request_id: str):
        """æ ‡è®°ä¸ºå·²å¤„ç†"""
        key = f"processed:{request_id}"
        await self.redis.setex(key, self.ttl, "1")

    async def cleanup(self):
        """æ¸…ç†è¿‡æœŸè®°å½•"""
        # Redis ä¼šè‡ªåŠ¨è¿‡æœŸï¼Œè¿™é‡Œå¯ä»¥æ‰§è¡Œé¢å¤–çš„æ¸…ç†é€»è¾‘
        pass
```

### 7.3 åˆ†å¸ƒå¼é”

```python
# backend/app/orchestration/distributed_lock.py

class DistributedLock:
    """
    åŸºäº Redis çš„åˆ†å¸ƒå¼é”
    """

    def __init__(self, redis_client):
        self.redis = redis_client

    async def acquire(self, lock_key: str, timeout: int = 10) -> bool:
        """
        è·å–é”
        è¿”å›ï¼šæ˜¯å¦æˆåŠŸè·å–
        """
        key = f"lock:{lock_key}"
        value = str(time.time())

        # SET NX EXï¼šåŸå­æ“ä½œ
        acquired = await self.redis.set(
            key,
            value,
            nx=True,  # åªåœ¨ä¸å­˜åœ¨æ—¶è®¾ç½®
            ex=timeout
        )

        return acquired is True

    async def release(self, lock_key: str):
        """é‡Šæ”¾é”"""
        key = f"lock:{lock_key}"
        await self.redis.delete(key)

    async def extend(self, lock_key: str, timeout: int) -> bool:
        """å»¶é•¿é”æ—¶é—´"""
        key = f"lock:{lock_key}"
        return await self.redis.expire(key, timeout)
```

### 7.4 ç›‘æ§ä¸æŒ‡æ ‡

```python
# backend/app/monitoring/metrics.py

from prometheus_client import Counter, Histogram, Gauge, generate_latest

class MetricsCollector:
    """
    Prometheus æŒ‡æ ‡æ”¶é›†å™¨
    """

    # è¯·æ±‚æŒ‡æ ‡
    REQUEST_COUNTER = Counter(
        'chat_orchestrator_requests_total',
        'Total chat requests processed',
        ['status', 'session_id']
    )

    REQUEST_DURATION = Histogram(
        'chat_orchestrator_request_duration_seconds',
        'Request processing duration',
        ['operation']
    )

    # ç†”æ–­å™¨çŠ¶æ€
    CIRCUIT_BREAKER_STATE = Gauge(
        'chat_orchestrator_circuit_breaker',
        'Circuit breaker state (0=closed, 1=open, 2=half-open)'
    )

    # Token ä½¿ç”¨
    TOKEN_USAGE = Counter(
        'chat_orchestrator_tokens_total',
        'Token usage by model',
        ['model', 'type']
    )

    # å¹¶å‘ä¼šè¯
    CONCURRENT_SESSIONS = Gauge(
        'chat_orchestrator_concurrent_sessions',
        'Number of active sessions'
    )

    # ä¸Šä¸‹æ–‡ä¿®å‰ª
    CONTEXT_PRUNER_STATS = Counter(
        'context_pruner_operations_total',
        'Context pruning operations',
        ['operation', 'summary_used']
    )

    def record_request(self, status: str, session_id: str, duration: float):
        """è®°å½•è¯·æ±‚"""
        self.REQUEST_COUNTER.labels(status=status, session_id=session_id).inc()
        self.REQUEST_DURATION.labels(operation='chat').observe(duration)

    def update_circuit_breaker(self, state: str):
        """æ›´æ–°ç†”æ–­å™¨çŠ¶æ€"""
        state_map = {"CLOSED": 0, "OPEN": 1, "HALF_OPEN": 2}
        self.CIRCUIT_BREAKER_STATE.set(state_map.get(state, 0))

    def record_token_usage(self, model: str, tokens: int, token_type: str):
        """è®°å½• Token ä½¿ç”¨"""
        self.TOKEN_USAGE.labels(model=model, type=token_type).inc(tokens)

    def update_concurrent_sessions(self, count: int):
        """æ›´æ–°å¹¶å‘ä¼šè¯æ•°"""
        self.CONCURRENT_SESSIONS.set(count)

    def record_context_pruner(self, operation: str, summary_used: bool):
        """è®°å½•ä¸Šä¸‹æ–‡ä¿®å‰ªæ“ä½œ"""
        self.CONTEXT_PRUNER_STATS.labels(
            operation=operation,
            summary_used='yes' if summary_used else 'no'
        ).inc()

    @staticmethod
    def get_metrics():
        """è·å– Prometheus æ ¼å¼çš„æŒ‡æ ‡"""
        return generate_latest()
```

### 7.5 å¥åº·æ£€æŸ¥

```python
# backend/app/api/v1/health_production.py

from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession
import redis.asyncio as redis

router = APIRouter()

@router.get("/")
async def health_check():
    """åŸºç¡€å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "timestamp": datetime.utcnow().isoformat()}

@router.get("/ready")
async def readiness_check(db: AsyncSession):
    """å°±ç»ªæ£€æŸ¥ï¼ˆKubernetesï¼‰"""
    try:
        # æ£€æŸ¥æ•°æ®åº“
        await db.execute("SELECT 1")

        # æ£€æŸ¥ Redis
        redis_client = redis.from_url("redis://localhost:6379")
        await redis_client.ping()

        return {"status": "ready"}
    except Exception as e:
        return {"status": "not_ready", "error": str(e)}

@router.get("/live")
async def liveness_check():
    """å­˜æ´»æ£€æŸ¥ï¼ˆKubernetesï¼‰"""
    return {"status": "alive"}

@router.get("/detailed")
async def health_detailed(db: AsyncSession, orchestrator=None):
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    base_health = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "2.0.0"
    }

    # æ•°æ®åº“æ£€æŸ¥
    try:
        await db.execute("SELECT 1")
        base_health["database"] = {"status": "connected"}
    except Exception as e:
        base_health["database"] = {"status": "error", "error": str(e)}
        base_health["status"] = "degraded"

    # Redis æ£€æŸ¥
    try:
        redis_client = redis.from_url("redis://localhost:6379")
        await redis_client.ping()

        # æ£€æŸ¥é˜Ÿåˆ—é•¿åº¦
        queue_length = await redis_client.llen("queue:summarization")
        base_health["redis"] = {
            "status": "connected",
            "queue_length": queue_length,
            "queue_healthy": queue_length < 500
        }
    except Exception as e:
        base_health["redis"] = {"status": "error", "error": str(e)}
        base_health["status"] = "degraded"

    # è¿è¡Œæ—¶çŠ¶æ€
    if orchestrator:
        runtime = orchestrator.get_health_status()
        base_health["runtime"] = runtime

    # ä¸šåŠ¡æŒ‡æ ‡
    base_health["metrics"] = {
        "concurrent_sessions": 0,  # ä» MetricsCollector è·å–
        "circuit_breaker_state": "CLOSED"
    }

    return base_health

@router.get("/prometheus/metrics")
async def prometheus_metrics():
    """Prometheus æŒ‡æ ‡ç«¯ç‚¹"""
    from prometheus_client import generate_latest
    return Response(
        content=generate_latest(),
        media_type="text/plain; version=0.0.4"
    )

@router.get("/queue/status")
async def queue_status():
    """é˜Ÿåˆ—çŠ¶æ€ç›‘æ§"""
    redis_client = redis.from_url("redis://localhost:6379")

    queues = {
        "summarization": await redis_client.llen("queue:summarization"),
        "expansion": await redis_client.llen("queue:expansion"),
        "push": await redis_client.llen("queue:push"),
    }

    return {
        "queues": queues,
        "alerts": [q for q, l in queues.items() if l > 100]
    }
```

---

## 8. å®Œæ•´è¯·æ±‚æµç¨‹è¿½è¸ª

### 8.1 ç«¯åˆ°ç«¯æµç¨‹è¯¦è§£

```
ç”¨æˆ·è¾“å…¥: "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
```

#### é˜¶æ®µ 1: ç§»åŠ¨ç«¯å¤„ç†

```dart
// 1. Flutter App - ç”¨æˆ·è¾“å…¥
ChatScreen.onSubmitted("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")

// 2. Riverpod çŠ¶æ€æ›´æ–°
ChatNotifier.sendMessage("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
  â†’ æ›´æ–° state.isLoading = true
  â†’ æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ° messages åˆ—è¡¨

// 3. WebSocket æœåŠ¡å‘é€
WebSocketChatServiceV2.sendMessage(
  message: "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
  userId: "user_123",
  sessionId: "sess_456"
)
  â†’ æ„å»º payload: {"message": "...", "session_id": "...", "user_id": "..."}
  â†’ WebSocketChannel å‘é€ JSON
```

#### é˜¶æ®µ 2: Go Gateway å¤„ç†

```go
// 4. Go Gateway - WebSocket æ¥æ”¶
func (h *ChatHandler) HandleWebSocket(conn *websocket.Conn, userID string) {
    // è®¤è¯æ£€æŸ¥
    if !h.authMiddleware(conn) {
        conn.Close(4001, "Auth failed")
        return
    }

    // æ¶ˆæ¯å¾ªç¯
    for {
        var msg ChatMessage
        conn.ReadJSON(&msg)  // æ¥æ”¶ {"message": "...", ...}

        // é…é¢æ£€æŸ¥
        if !h.quotaService.CheckQuota(userID) {
            conn.WriteJSON(QuotaExceededResponse)
            break
        }

        // 5. è½¬å‘åˆ° gRPC
        response, err := h.grpcClient.StreamChat(ctx, &pb.ChatRequest{
            UserId:    userID,
            SessionId: msg.SessionID,
            Message:   msg.Message,
        })

        // 6. æµå¼è¿”å›
        for _, chunk := range response {
            conn.WriteJSON(chunk)  // é€å—è¿”å›ç»™ Flutter
        }
    }
}
```

#### é˜¶æ®µ 3: Python gRPC æœåŠ¡

```python
# 7. gRPC æœåŠ¡ç«¯
class AgentServiceImpl(pb2_grpc.AgentServiceServicer):
    async def StreamChat(self, request, context):
        # è½¬å‘åˆ°ç¼–æ’å™¨
        orchestrator = ProductionChatOrchestrator()

        async for event in orchestrator.process_stream(request):
            yield pb2.StreamResponse(
                type=event.type,
                content=event.content,
                metadata=event.metadata
            )
```

#### é˜¶æ®µ 4: ç”Ÿäº§çº§ç¼–æ’å™¨æ ¸å¿ƒæµç¨‹

```python
# 8. ProductionChatOrchestrator.process_stream()

# ========== ç¬¬1æ­¥ï¼šæ¶ˆæ¯å»é‡æ£€æŸ¥ ==========
if await self.message_tracker.is_processed("req_789"):
    yield ErrorEvent(code="DUPLICATE_REQUEST")
    return  # æµç¨‹ç»“æŸ

# ========== ç¬¬2æ­¥ï¼šç†”æ–­å™¨æ£€æŸ¥ ==========
if not await self.circuit_breaker.can_execute():
    yield ErrorEvent(code="CIRCUIT_BREAKER_OPEN")
    return  # æµç¨‹ç»“æŸ

# ========== ç¬¬3æ­¥ï¼šå¹¶å‘æ§åˆ¶ ==========
if not await self._track_session("sess_456", add=True):
    yield ErrorEvent(code="RATE_LIMIT")
    return  # æµç¨‹ç»“æŸ

try:
    # ========== ç¬¬4æ­¥ï¼šè¯·æ±‚éªŒè¯ ==========
    validation = await self.validator.validate_chat_request(request)
    if not validation.is_valid:
        yield ErrorEvent(code="VALIDATION_FAILED")
        return  # æµç¨‹ç»“æŸ

    # ========== ç¬¬5æ­¥ï¼šå¹‚ç­‰æ€§æ£€æŸ¥ ==========
    cached = await self._check_idempotency("sess_456", "req_789")
    if cached:
        yield cached  # è¿”å›ç¼“å­˜
        return  # æµç¨‹ç»“æŸ

    # ========== ç¬¬6æ­¥ï¼šåˆ†å¸ƒå¼é” ==========
    lock_acquired = await self._acquire_session_lock("sess_456", "req_789")
    if not lock_acquired:
        yield ErrorEvent(code="LOCK_FAILED")
        return  # æµç¨‹ç»“æŸ

    # ========== ç¬¬7æ­¥ï¼šæ„å»ºä¸Šä¸‹æ–‡ ==========

    # 7.1 ç”¨æˆ·ä¸Šä¸‹æ–‡
    user_context = await self._build_user_context("user_123")
    # ç»“æœ: {
    #   "user": {"id": "user_123", "nickname": "å¼ ä¸‰"},
    #   "progress": {"total_nodes": 45, "avg_mastery": 65},
    #   "active_sprint": {"title": "æœºå™¨å­¦ä¹ å…¥é—¨", "progress": 75}
    # }

    # 7.2 å¯¹è¯å†å²ï¼ˆä¸Šä¸‹æ–‡ä¿®å‰ªï¼‰
    conversation_context = await self.context_pruner.get_pruned_history(
        "sess_456", "user_123"
    )
    # ç»“æœ: {
    #   "messages": [...],  # æœ€è¿‘10æ¡æˆ–å¸¦æ€»ç»“
    #   "summary": "ç”¨æˆ·ä¹‹å‰è¯¢é—®è¿‡ç¥ç»ç½‘ç»œçš„åŸºç¡€æ¦‚å¿µ",
    #   "summary_used": True
    # }

    # 7.3 çŸ¥è¯†æ£€ç´¢ï¼ˆGraphRAGï¼‰
    knowledge_context = await self._retrieve_knowledge(
        "user_123",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        conversation_context
    )
    # ç»“æœ: {
    #   "nodes": [
    #     {"id": "node_100", "name": "æœºå™¨å­¦ä¹ ", "mastery": 0},
    #     {"id": "node_101", "name": "ç›‘ç£å­¦ä¹ ", "mastery": 0},
    #     {"id": "node_102", "name": "ç¥ç»ç½‘ç»œ", "mastery": 35}
    #   ],
    #   "relations": [...]
    # }

    # ========== ç¬¬8æ­¥ï¼šLLM è°ƒç”¨ + å·¥å…·æ‰§è¡Œ ==========

    # 8.1 å‡†å¤‡å·¥å…·
    tools = tool_registry.get_openai_tools_schema()
    # å·¥å…·åˆ—è¡¨: [
    #   {"name": "get_knowledge_node", ...},
    #   {"name": "create_task", ...},
    #   ...
    # ]

    # 8.2 æ„å»ºç³»ç»Ÿæç¤º
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ª AI å­¦ä¹ åŠ©æ‰‹ã€‚

    ç”¨æˆ·ä¿¡æ¯:
    {json.dumps(user_context, ensure_ascii=False)}

    å¯¹è¯å†å²:
    {json.dumps(conversation_context, ensure_ascii=False)}

    ç›¸å…³çŸ¥è¯†:
    {json.dumps(knowledge_context, ensure_ascii=False)}

    å¯ç”¨å·¥å…·:
    {tool_registry.get_tools_description()}

    è¦æ±‚:
    1. ç”¨ä¸­æ–‡å›ç­”
    2. è¯­è¨€äº²åˆ‡è‡ªç„¶
    3. é€‚å½“ä½¿ç”¨å·¥å…·
    """

    # 8.3 æµå¼ LLM è°ƒç”¨
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"}
    ]

    async for chunk in llm_service.chat_stream_with_tools(
        messages=messages,
        tools=tools,
        user_id="user_123"
    ):
        yield chunk

    # ========== ç¬¬9æ­¥ï¼šå“åº”ç»„åˆ ==========
    # å·²åœ¨ LLM æµå¼è¿”å›ä¸­å®Œæˆ

    # ========== ç¬¬10æ­¥ï¼šç¼“å­˜ä¸æŒ‡æ ‡ ==========
    await self._cache_response("sess_456", "req_789", "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
    await self._record_metrics(request, user_context)

finally:
    # ========== ç¬¬11æ­¥ï¼šæ¸…ç†èµ„æº ==========
    await self._release_session_lock("sess_456", "req_789")
    await self._track_session("sess_456", add=False)
```

#### é˜¶æ®µ 5: LLM æœåŠ¡æ‰§è¡Œ

```python
# 9. LLM æœåŠ¡ - æµå¼è°ƒç”¨

# ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆå¯èƒ½è¿”å›å·¥å…·è°ƒç”¨ï¼‰
response = await provider.chat_complete(
    messages=messages,
    tools=tools,
    stream=True
)

async for chunk in response:
    if chunk.type == "text":
        # ç›´æ¥è¿”å›æ–‡æœ¬
        yield TextEvent(content=chunk.content)

    elif chunk.type == "tool_call":
        # æ”¶é›†å·¥å…·è°ƒç”¨
        tool_calls.append(chunk.tool_call)

        if chunk.tool_call.finish_reason == "stop":
            # æ‰§è¡Œå·¥å…·
            tool_results = await self._execute_tools(tool_calls)

            # æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            messages.extend([
                {"role": "assistant", "tool_calls": tool_calls},
                {"role": "tool", "content": json.dumps(tool_results)}
            ])

            # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆç”Ÿæˆæœ€ç»ˆå›ç­”ï¼‰
            final_response = await provider.chat_complete(
                messages=messages,
                stream=True
            )

            async for final_chunk in final_response:
                yield final_chunk

            break
```

#### é˜¶æ®µ 6: æ•°æ®åº“æ“ä½œ

```python
# 10. æ•°æ®åº“æ“ä½œï¼ˆå¦‚æœéœ€è¦ï¼‰

# çŸ¥è¯†æ£€ç´¢
SELECT kn.id, kn.name, kn.description, kn.embedding <=> :query_embedding AS distance
FROM knowledge_nodes kn
WHERE kn.subject_id = :subject_id
ORDER BY distance
LIMIT 10;

# æ›´æ–°ç”¨æˆ·çŠ¶æ€
UPDATE user_node_status
SET mastery_score = mastery_score + :delta,
    total_study_minutes = total_study_minutes + :minutes,
    study_count = study_count + 1,
    last_study_at = NOW(),
    next_review_at = :next_review
WHERE user_id = :user_id AND node_id = :node_id;

# è®°å½•å­¦ä¹ å†å²
INSERT INTO study_records (user_id, node_id, study_minutes, mastery_delta)
VALUES (:user_id, :node_id, :minutes, :delta);
```

#### é˜¶æ®µ 7: Redis ç¼“å­˜/é˜Ÿåˆ—

```python
# 11. Redis æ“ä½œ

# ç¼“å­˜å¯¹è¯å†å²
LPUSH chat_history:sess_456 '{"role": "user", "content": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"}'
EXPIRE chat_history:sess_456 3600

# å¼‚æ­¥æ€»ç»“é˜Ÿåˆ—
RPUSH queue:summarization '{"session_id": "sess_456", "history": [...]}'

# ä¼šè¯çŠ¶æ€
SET session:sess_456:active "1"
EXPIRE session:sess_456:active 60
```

#### é˜¶æ®µ 8: è¿”å›ç§»åŠ¨ç«¯

```dart
// 12. Flutter - æ¥æ”¶æµå¼å“åº”

// WebSocket æœåŠ¡æ¥æ”¶
WebSocketChatServiceV2._handleMessage(data)
  â†’ è§£æä¸º TextEvent("æœºå™¨å­¦ä¹ æ˜¯...")
  â†’ StreamController.add(event)

// Riverpod ç›‘å¬
ChatNotifier._handleStreamEvent(event)
  â†’ event.when(
      text: (content) {
        state = state.copyWith(
          response: state.response + content,
          isTyping: true
        );
      },
      done: () {
        // æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
        state = state.copyWith(
          messages: [
            ...state.messages,
            ChatMessage(
              role: 'assistant',
              content: state.response,
            )
          ],
          isLoading: false,
          isTyping: false
        );
      }
    )

// UI æ›´æ–°
ChatScreen.builder()
  â†’ MessageBubble æ˜¾ç¤º AI å›ç­”
  â†’ æ‰“å­—åŠ¨ç”»æ•ˆæœ
  â†’ å®ŒæˆçŠ¶æ€æ˜¾ç¤º
```

### 8.2 å…³é”®æ—¶åºå›¾

```
æ—¶é—´è½´: 0ms â”€â”€â”€â”€â”€â”€> 100ms â”€â”€â”€â”€â”€â”€> 200ms â”€â”€â”€â”€â”€â”€> 300ms â”€â”€â”€â”€â”€â”€> 400ms

Mobile:  [è¾“å…¥] â”€â”€> [å‘é€] â”€â”€> [ç­‰å¾…] â”€â”€> [æ¥æ”¶"æœºå™¨"] â”€â”€> [æ¥æ”¶"å­¦ä¹ "] â”€â”€> [å®Œæˆ]
           â”‚          â”‚          â”‚            â”‚              â”‚            â”‚
Go:       â”‚          â””â”€> [æ¥æ”¶] â”€â”€> [éªŒè¯] â”€â”€> [gRPCè½¬å‘] â”€â”€> [æµå¼è¿”å›] â”€â”€> [å…³é—­]
           â”‚                     â”‚            â”‚              â”‚            â”‚
Python:   â”‚                     â””â”€> [ç¼–æ’] â”€â”€> [LLMè°ƒç”¨] â”€â”€> [å·¥å…·æ‰§è¡Œ] â”€â”€> [ç»“æŸ]
           â”‚                              â”‚              â”‚            â”‚
DB/Redis: â”‚                              â”œâ”€> [æŸ¥è¯¢] â”€â”€> [æ›´æ–°] â”€â”€> [ç¼“å­˜]
           â”‚                              â”‚
LLM:      â”‚                              â””â”€> [ç”Ÿæˆ] â”€â”€> [æµå¼è¾“å‡º]
```

---

## 9. æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ

### 9.1 æ•°æ®åº“ä¼˜åŒ–

#### 9.1.1 ç´¢å¼•ç­–ç•¥

```sql
-- 1. å‘é‡æœç´¢ä¼˜åŒ–
-- HNSW ç´¢å¼•ï¼ˆæ¨èï¼Œæ€§èƒ½æ›´å¥½ï¼‰
CREATE INDEX idx_knowledge_nodes_embedding_hnsw
ON knowledge_nodes
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64, ef_search = 40);

-- IVFFlat ç´¢å¼•ï¼ˆå¤‡é€‰ï¼Œæ„å»ºæ›´å¿«ï¼‰
CREATE INDEX idx_knowledge_nodes_embedding_ivfflat
ON knowledge_nodes
USING ivfflat (embedding vector_l2_ops)
WITH (lists = 100);

-- 2. éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æ´»è·ƒæ•°æ®ï¼‰
CREATE INDEX idx_user_node_status_active
ON user_node_status(user_id, mastery_score)
WHERE mastery_score < 100;

-- 3. è¦†ç›–ç´¢å¼•ï¼ˆé¿å…å›è¡¨ï¼‰
CREATE INDEX idx_study_records_covering
ON study_records(user_id, completed_at DESC)
INCLUDE (node_id, mastery_delta, study_minutes);

-- 4. BRIN ç´¢å¼•ï¼ˆæ—¶é—´åºåˆ—ï¼‰
CREATE INDEX idx_study_records_brin
ON study_records USING BRIN (completed_at)
WITH (pages_per_range = 128);
```

#### 9.1.2 æŸ¥è¯¢ä¼˜åŒ–

```python
# ä¼˜åŒ–å‰ï¼šN+1 æŸ¥è¯¢
async def get_user_progress_bad(user_id):
    nodes = await db.execute("SELECT * FROM user_node_status WHERE user_id = ?", user_id)
    for node in nodes:
        node_details = await db.execute("SELECT * FROM knowledge_nodes WHERE id = ?", node.node_id)
        # ... æ¯æ¬¡å¾ªç¯éƒ½æŸ¥è¯¢

# ä¼˜åŒ–åï¼šå•æ¬¡ JOIN æŸ¥è¯¢
async def get_user_progress_good(user_id):
    query = """
    SELECT
        uns.*,
        kn.name,
        kn.description,
        kn.parent_id
    FROM user_node_status uns
    JOIN knowledge_nodes kn ON uns.node_id = kn.id
    WHERE uns.user_id = :user_id
    """
    return await db.execute(query, {"user_id": user_id})
```

### 9.2 å¹¶å‘æ§åˆ¶

#### 9.2.1 ä¼šè¯é™åˆ¶

```python
# é™åˆ¶å•ä¸ªç”¨æˆ·å¹¶å‘ä¼šè¯æ•°
MAX_CONCURRENT_SESSIONS = 10

async def _track_session(self, session_id: str, add: bool) -> bool:
    """å¹¶å‘ä¼šè¯è¿½è¸ª"""
    key = f"session_count:{user_id}"

    if add:
        current = await self.redis.incr(key)
        if current > MAX_CONCURRENT_SESSIONS:
            await self.redis.decr(key)
            return False
        await self.redis.expire(key, 3600)
        return True
    else:
        await self.redis.decr(key)
        return True
```

#### 9.2.2 è¿æ¥æ± é…ç½®

```python
# SQLAlchemy è¿æ¥æ± 
engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,              # è¿æ¥æ± å¤§å°
    max_overflow=50,           # æœ€å¤§æº¢å‡º
    pool_timeout=30,           # è·å–è¿æ¥è¶…æ—¶
    pool_recycle=3600,         # è¿æ¥å›æ”¶æ—¶é—´
    echo=False                 # ç”Ÿäº§ç¯å¢ƒå…³é—­ SQL æ—¥å¿—
)

# Redis è¿æ¥æ± 
redis_pool = redis.ConnectionPool(
    host='localhost',
    port=6379,
    max_connections=50,
    socket_timeout=5,
    socket_connect_timeout=5
)
```

### 9.3 ç¼“å­˜ç­–ç•¥

#### 9.3.1 å¤šçº§ç¼“å­˜

```python
class MultiLevelCache:
    """å¤šçº§ç¼“å­˜ï¼šå†…å­˜ + Redis"""

    def __init__(self):
        self.memory_cache = {}  # L1: è¿›ç¨‹å†…ç¼“å­˜
        self.redis = redis.from_url("redis://localhost:6379")  # L2: Redis

    async def get(self, key: str, ttl: int = 300) -> Optional[str]:
        # L1 æŸ¥è¯¢
        if key in self.memory_cache:
            value, expiry = self.memory_cache[key]
            if time.time() < expiry:
                return value

        # L2 æŸ¥è¯¢
        value = await self.redis.get(key)
        if value:
            # å›å¡« L1
            self.memory_cache[key] = (value, time.time() + ttl)
            return value

        return None

    async def set(self, key: str, value: str, ttl: int = 300):
        # L2 è®¾ç½®
        await self.redis.setex(key, ttl, value)

        # L1 è®¾ç½®
        self.memory_cache[key] = (value, time.time() + ttl)

        # L1 æ¸…ç†ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        if len(self.memory_cache) > 1000:
            self._cleanup_memory_cache()

    def _cleanup_memory_cache(self):
        """æ¸…ç†è¿‡æœŸçš„å†…å­˜ç¼“å­˜"""
        now = time.time()
        expired = [
            k for k, v in self.memory_cache.items()
            if v[1] < now
        ]
        for k in expired:
            del self.memory_cache[k]
```

#### 9.3.2 è¯­ä¹‰ç¼“å­˜

```python
class SemanticCache:
    """åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„è¯­ä¹‰ç¼“å­˜"""

    def __init__(self, redis_client, llm_service):
        self.redis = redis_client
        self.llm = llm_service

    async def get(self, query: str, threshold: float = 0.95) -> Optional[str]:
        """æŸ¥è¯¢è¯­ä¹‰ç›¸ä¼¼çš„ç¼“å­˜"""
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = await self.llm.get_embedding(query)

        # æœç´¢ç›¸ä¼¼ç¼“å­˜
        cache_key = "semantic_cache:*"
        candidates = await self.redis.keys(cache_key)

        for key in candidates:
            cached_data = await self.redis.hgetall(key)
            if not cached_data:
                continue

            cached_embedding = np.frombuffer(cached_data[b"embedding"], dtype=np.float32)
            similarity = np.dot(query_embedding, cached_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(cached_embedding)
            )

            if similarity >= threshold:
                return cached_data[b"response"].decode("utf-8")

        return None

    async def set(self, query: str, response: str):
        """è®¾ç½®è¯­ä¹‰ç¼“å­˜"""
        embedding = await self.llm.get_embedding(query)

        cache_key = f"semantic_cache:{hash(query)}"

        await self.redis.hset(cache_key, mapping={
            "query": query,
            "response": response,
            "embedding": embedding.tobytes(),
            "created_at": str(time.time())
        })

        await self.redis.expire(cache_key, 3600)
```

### 9.4 å¼‚æ­¥ä¼˜åŒ–

#### 9.4.1 å¹¶å‘æ‰§è¡Œ

```python
# ä¼˜åŒ–å‰ï¼šä¸²è¡Œæ‰§è¡Œ
async def process_concurrently_bad(requests):
    results = []
    for req in requests:
        result = await process_single(req)
        results.append(result)
    return results

# ä¼˜åŒ–åï¼šå¹¶å‘æ‰§è¡Œ
async def process_concurrently_good(requests):
    tasks = [process_single(req) for req in requests]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results

# å¸¦é™æµçš„å¹¶å‘
async def process_with_semaphore(requests, max_concurrent=10):
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_with_limit(req):
        async with semaphore:
            return await process_single(req)

    tasks = [process_with_limit(req) for req in requests]
    return await asyncio.gather(*tasks)
```

#### 9.4.2 å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†

```python
# ä½¿ç”¨ async context manager
class DatabaseTransaction:
    async def __aenter__(self):
        self.session = async_sessionmaker()
        return self.session

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            await self.session.rollback()
        else:
            await self.session.commit()
        await self.session.close()

# ä½¿ç”¨ç¤ºä¾‹
async with DatabaseTransaction() as session:
    result = await session.execute(query)
    # è‡ªåŠ¨æäº¤æˆ–å›æ»š
```

### 9.5 é”™è¯¯å¤„ç†ä¸é™çº§

#### 9.5.1 ä¼˜é›…é™çº§

```python
async def get_knowledge_with_fallback(user_id: str, query: str):
    """çŸ¥è¯†æ£€ç´¢ + é™çº§ç­–ç•¥"""
    try:
        # ä¸»æµç¨‹ï¼šGraphRAG æ··åˆæœç´¢
        results = await galaxy_service.hybrid_search(user_id, query)
        if results:
            return {"source": "graphrag", "data": results}
    except Exception as e:
        logger.warning(f"GraphRAG failed: {e}")

    try:
        # é™çº§1ï¼šå‘é‡æœç´¢
        results = await vector_service.search(query)
        if results:
            return {"source": "vector", "data": results}
    except Exception as e:
        logger.warning(f"Vector search failed: {e}")

    try:
        # é™çº§2ï¼šå…³é”®è¯æœç´¢
        results = await keyword_service.search(query)
        if results:
            return {"source": "keyword", "data": results}
    except Exception as e:
        logger.warning(f"Keyword search failed: {e}")

    # æœ€ç»ˆé™çº§ï¼šç©ºç»“æœ
    return {"source": "fallback", "data": []}
```

#### 9.5.2 è¶…æ—¶æ§åˆ¶

```python
import asyncio

async def call_with_timeout(coro, timeout_seconds: int):
    """å¸¦è¶…æ—¶çš„å¼‚æ­¥è°ƒç”¨"""
    try:
        return await asyncio.wait_for(coro, timeout=timeout_seconds)
    except asyncio.TimeoutError:
        raise TimeoutError(f"Operation timed out after {timeout_seconds}s")

# ä½¿ç”¨ç¤ºä¾‹
try:
    result = await call_with_timeout(
        llm_service.generate(prompt),
        timeout_seconds=30
    )
except TimeoutError:
    # è¿”å›ç¼“å­˜æˆ–é»˜è®¤å›ç­”
    return "æŠ±æ­‰ï¼Œå¤„ç†è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
```

### 9.6 ç›‘æ§ä¸å‘Šè­¦

#### 9.6.1 å…³é”®æŒ‡æ ‡

```python
# ä¸šåŠ¡æŒ‡æ ‡
METRICS = {
    "request_rate": "æ¯ç§’è¯·æ±‚æ•°",
    "avg_latency": "å¹³å‡å»¶è¿Ÿ",
    "p95_latency": "P95 å»¶è¿Ÿ",
    "error_rate": "é”™è¯¯ç‡",
    "token_usage": "Token æ¶ˆè€—",
    "cache_hit_rate": "ç¼“å­˜å‘½ä¸­ç‡",
    "concurrent_sessions": "å¹¶å‘ä¼šè¯æ•°",
    "queue_length": "é˜Ÿåˆ—é•¿åº¦"
}

# å‘Šè­¦è§„åˆ™
ALERT_RULES = {
    "error_rate": {"threshold": 0.05, "duration": "5m"},
    "p95_latency": {"threshold": 5000, "duration": "5m"},
    "queue_length": {"threshold": 1000, "duration": "2m"},
    "circuit_breaker": {"threshold": 1, "duration": "1m"}
}
```

#### 9.6.2 æ—¥å¿—è§„èŒƒ

```python
import structlog

logger = structlog.get_logger()

# ç»“æ„åŒ–æ—¥å¿—
logger.info(
    "chat_request_processed",
    user_id="user_123",
    session_id="sess_456",
    duration_ms=234,
    tokens_used=156,
    cache_hit=True,
    status="success"
)

# é”™è¯¯æ—¥å¿—
logger.error(
    "llm_api_failed",
    user_id="user_123",
    error="TimeoutError",
    retry_count=3,
    model="qwen-max"
)
```

---

## 10. é¢è¯•å¸¸è§é—®é¢˜è§£ç­”

### Q1: ä¸ºä»€ä¹ˆé€‰æ‹© Go + Python æ··åˆæ¶æ„ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **Go Gateway ä¼˜åŠ¿**:
   - é«˜æ€§èƒ½ WebSocket å¤„ç†ï¼ˆC10K é—®é¢˜ï¼‰
   - ä½å»¶è¿Ÿã€é«˜å¹¶å‘
   - å†…å­˜å®‰å…¨ã€ç¼–è¯‘å‹è¯­è¨€
   - é€‚åˆç½‘ç»œå±‚å’Œç½‘å…³

2. **Python Agent ä¼˜åŠ¿**:
   - AI ç”Ÿæ€ä¸°å¯Œï¼ˆLangChain, OpenAI SDKï¼‰
   - LLM é›†æˆæˆç†Ÿ
   - å¿«é€Ÿè¿­ä»£å’Œå®éªŒ
   - é€‚åˆ AI ç¼–æ’å’Œå·¥å…·è°ƒç”¨

3. **gRPC é€šä¿¡**:
   - é«˜æ•ˆäºŒè¿›åˆ¶åè®®
   - æµå¼æ”¯æŒ
   - å¼ºç±»å‹æ¥å£
   - å¤šè¯­è¨€äº’æ“ä½œ

**æ¶æ„ä¼˜åŠ¿**: æ¯ä¸ªç»„ä»¶ä½¿ç”¨æœ€é€‚åˆçš„æŠ€æœ¯ï¼Œå‘æŒ¥å„è‡ªä¼˜åŠ¿

### Q2: ContextPruner å¦‚ä½•è§£å†³é•¿å¯¹è¯é—®é¢˜ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **é—®é¢˜èƒŒæ™¯**:
   - LLM Token é™åˆ¶ï¼ˆä¸Šä¸‹æ–‡çª—å£ï¼‰
   - é•¿å¯¹è¯æ€§èƒ½ä¸‹é™
   - æˆæœ¬å¢åŠ 

2. **è§£å†³æ–¹æ¡ˆ**:
   - **æ»‘åŠ¨çª—å£**: ä¿ç•™æœ€è¿‘ 10 æ¡æ¶ˆæ¯
   - **å¼‚æ­¥æ€»ç»“**: è¶…è¿‡ 20 æ¡è§¦å‘ LLM æ€»ç»“
   - **ç¼“å­˜æœºåˆ¶**: æ€»ç»“ç»“æœç¼“å­˜ 1 å°æ—¶
   - **æ¶ˆæ¯å»é‡**: é˜²æ­¢é‡å¤å¤„ç†

3. **ç”Ÿäº§çº§ç‰¹æ€§**:
   - JSON åºåˆ—åŒ–ï¼ˆå®‰å…¨ï¼‰
   - Redis é˜Ÿåˆ—ï¼ˆå¼‚æ­¥ï¼‰
   - ç†”æ–­å™¨ï¼ˆé˜²æ­¢ OOMï¼‰
   - ç›‘æ§æŒ‡æ ‡

**æ•ˆæœ**: Token ä½¿ç”¨å‡å°‘ 70%ï¼Œå“åº”æ—¶é—´é™ä½ 40%

### Q3: çŸ¥è¯†æ˜Ÿå›¾çš„ RAG v2.0 å¦‚ä½•å·¥ä½œï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **æ··åˆæœç´¢**:
   - å‘é‡æœç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
   - å…³é”®è¯æœç´¢ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
   - RRF èåˆç®—æ³•

2. **ä¼˜åŒ–ç­–ç•¥**:
   - **å¹¶è¡Œæ‰§è¡Œ**: åŒæ—¶å‘èµ·å‘é‡å’Œå…³é”®è¯æœç´¢
   - **é‡æ’åº**: LLM å¯¹ç»“æœè¿›è¡Œç›¸å…³æ€§æ’åº
   - **ç”¨æˆ·çŠ¶æ€è¿‡æ»¤**: æ’é™¤å·²æŒæ¡èŠ‚ç‚¹
   - **å…³ç³»æ‰©å±•**: åŸºäºçŸ¥è¯†å›¾è°±æ‰©å±•ç»“æœ

3. **æ€§èƒ½ä¼˜åŒ–**:
   - HNSW ç´¢å¼•åŠ é€Ÿå‘é‡æœç´¢
   - Redis ç¼“å­˜çƒ­ç‚¹æ•°æ®
   - è¿æ¥æ± å¤ç”¨

**æ•ˆæœ**: æ£€ç´¢å‡†ç¡®ç‡æå‡ 35%ï¼Œå»¶è¿Ÿé™ä½ 50%

### Q4: æ™ºèƒ½æ¨é€ç³»ç»Ÿçš„ç­–ç•¥ä¼˜å…ˆçº§ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **ç­–ç•¥ä¼˜å…ˆçº§**:
   ```
   Sprint > Curiosity > Memory > Inactivity
   ```

2. **å„ç­–ç•¥è§¦å‘æ¡ä»¶**:
   - **Sprint**: å†²åˆºè®¡åˆ’å³å°†ç»“æŸä¸”å®Œæˆåº¦ < 80%
   - **Curiosity**: åŸºäºç”¨æˆ·å…´è¶£å›¾è°±çš„æ–°å†…å®¹
   - **Memory**: è‰¾å®¾æµ©æ–¯å¤ä¹ æ—¶é—´åˆ°è¾¾
   - **Inactivity**: 3 å¤©æœªç™»å½•

3. **é¢‘ç‡æ§åˆ¶**:
   - æ¯æ—¥ä¸Šé™ï¼ˆç”¨æˆ·å¯é…ç½®ï¼‰
   - å†·å´æœŸï¼ˆé¿å…é¢‘ç¹æ‰“æ‰°ï¼‰
   - æ—¶åŒºæ„ŸçŸ¥ï¼ˆæ´»è·ƒæ—¶æ®µï¼‰

4. **ä¸ªæ€§åŒ–**:
   - LLM ç”Ÿæˆå†…å®¹
   - ç”¨æˆ· persona åŒ¹é…
   - A/B æµ‹è¯•æ¡†æ¶

### Q5: ç†”æ–­å™¨å¦‚ä½•é˜²æ­¢çº§è”æ•…éšœï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **çŠ¶æ€æœº**:
   - **CLOSED**: æ­£å¸¸çŠ¶æ€
   - **OPEN**: å¤±è´¥è¶…è¿‡é˜ˆå€¼ï¼Œæ‹’ç»è¯·æ±‚
   - **HALF_OPEN**: å°è¯•æ¢å¤

2. **å·¥ä½œæµç¨‹**:
   ```
   å¤±è´¥è®¡æ•° â†’ è¾¾åˆ°é˜ˆå€¼ â†’ OPEN â†’ ç­‰å¾…è¶…æ—¶ â†’ HALF_OPEN
       â†“                                      â†“
   æˆåŠŸé‡ç½® â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æµ‹è¯•è¯·æ±‚
   ```

3. **åˆ†å¸ƒå¼å®ç°**:
   - Redis å­˜å‚¨çŠ¶æ€
   - åŸå­æ“ä½œä¿è¯ä¸€è‡´æ€§
   - TTL è‡ªåŠ¨è¿‡æœŸ

4. **é™çº§ç­–ç•¥**:
   - è¿”å›ç¼“å­˜ç»“æœ
   - é»˜è®¤å›ç­”
   - é˜Ÿåˆ—æš‚åœ

### Q6: æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–ç­–ç•¥ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **å‘é‡ç´¢å¼•**:
   - HNSW: é«˜æ€§èƒ½ï¼Œé€‚åˆç”Ÿäº§
   - IVFFlat: æ„å»ºå¿«ï¼Œé€‚åˆæµ‹è¯•

2. **éƒ¨åˆ†ç´¢å¼•**:
   ```sql
   CREATE INDEX idx_active ON table(col) WHERE status = 'active'
   ```

3. **è¦†ç›–ç´¢å¼•**:
   ```sql
   CREATE INDEX idx_covering ON table(col1, col2) INCLUDE (col3)
   ```

4. **BRIN ç´¢å¼•**:
   - æ—¶é—´åºåˆ—æ•°æ®
   - ç©ºé—´æ•ˆç‡é«˜

5. **å¤åˆç´¢å¼•é¡ºåº**:
   - é«˜é€‰æ‹©æ€§åˆ—åœ¨å‰
   - ç­‰å€¼æŸ¥è¯¢åœ¨å‰
   - èŒƒå›´æŸ¥è¯¢åœ¨å

### Q7: WebSocket é‡è¿æœºåˆ¶ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **æŒ‡æ•°é€€é¿**:
   ```
   ç¬¬1æ¬¡: 2ç§’
   ç¬¬2æ¬¡: 4ç§’
   ç¬¬3æ¬¡: 8ç§’
   ç¬¬4æ¬¡: 16ç§’
   ç¬¬5æ¬¡: 32ç§’ï¼ˆä¸Šé™ï¼‰
   ```

2. **æ¶ˆæ¯é˜Ÿåˆ—**:
   - æ–­è¿æ—¶æš‚å­˜æ¶ˆæ¯
   - é‡è¿åæ‰¹é‡å‘é€
   - é˜²æ­¢æ¶ˆæ¯ä¸¢å¤±

3. **å¿ƒè·³ä¿æ´»**:
   - æ¯ 30 ç§’ Ping
   - æœåŠ¡ç«¯è¶…æ—¶ 60 ç§’æ–­å¼€
   - é˜²æ­¢åƒµå°¸è¿æ¥

4. **çŠ¶æ€ç®¡ç†**:
   - è¿æ¥çŠ¶æ€æœº
   - UI çŠ¶æ€åé¦ˆ
   - ç”¨æˆ·æç¤º

### Q8: ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è¦ç‚¹ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **åŸºç¡€è®¾æ–½**:
   - Docker å®¹å™¨åŒ–
   - Kubernetes ç¼–æ’
   - è´Ÿè½½å‡è¡¡

2. **ç›‘æ§å‘Šè­¦**:
   - Prometheus + Grafana
   - ç»“æ„åŒ–æ—¥å¿—
   - åˆ†å¸ƒå¼è¿½è¸ª

3. **é«˜å¯ç”¨**:
   - æ•°æ®åº“ä¸»ä»
   - Redis é›†ç¾¤
   - å¤šå‰¯æœ¬éƒ¨ç½²

4. **å®‰å…¨**:
   - JWT è®¤è¯
   - é€Ÿç‡é™åˆ¶
   - è¾“å…¥éªŒè¯

5. **æ€§èƒ½**:
   - è¿æ¥æ± 
   - å¤šçº§ç¼“å­˜
   - å¼‚æ­¥å¤„ç†

### Q9: å¦‚ä½•ä¿è¯æ•°æ®ä¸€è‡´æ€§ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **æ•°æ®åº“äº‹åŠ¡**:
   - ACID ä¿è¯
   - å¼‚æ­¥äº‹åŠ¡
   - å›æ»šæœºåˆ¶

2. **åˆ†å¸ƒå¼é”**:
   - Redis SETNX
   - é”è¶…æ—¶
   - é”ç»­æœŸ

3. **å¹‚ç­‰æ€§**:
   - è¯·æ±‚ ID å»é‡
   - ä¹è§‚é”
   - å”¯ä¸€ç´¢å¼•

4. **æœ€ç»ˆä¸€è‡´æ€§**:
   - å¼‚æ­¥é˜Ÿåˆ—
   - è¡¥å¿æœºåˆ¶
   - å†²çªè§£å†³

### Q10: æ€§èƒ½ä¼˜åŒ–çš„å…³é”®æŒ‡æ ‡ï¼Ÿ

**å›ç­”è¦ç‚¹**:
1. **å»¶è¿ŸæŒ‡æ ‡**:
   - P50: < 500ms
   - P95: < 2000ms
   - P99: < 5000ms

2. **ååé‡**:
   - QPS: 1000+
   - å¹¶å‘è¿æ¥: 10000+
   - Token/s: 5000+

3. **èµ„æºä½¿ç”¨**:
   - CPU: < 70%
   - å†…å­˜: < 80%
   - ç£ç›˜ I/O: < 50%

4. **ä¸šåŠ¡æŒ‡æ ‡**:
   - ç¼“å­˜å‘½ä¸­ç‡: > 80%
   - é”™è¯¯ç‡: < 1%
   - æˆåŠŸç‡: > 99%

---

## æ€»ç»“

### æ¶æ„äº®ç‚¹

1. **æ··åˆæ¶æ„**: Go + Python + Flutterï¼Œå„å¸å…¶èŒ
2. **ç”Ÿäº§çº§ç‰¹æ€§**: ç†”æ–­ã€é™æµã€ç›‘æ§ã€é™çº§
3. **æ™ºèƒ½ç³»ç»Ÿ**: ContextPrunerã€GraphRAGã€æ™ºèƒ½æ¨é€
4. **æ€§èƒ½ä¼˜åŒ–**: å¤šçº§ç¼“å­˜ã€å¼‚æ­¥å¤„ç†ã€ç´¢å¼•ä¼˜åŒ–
5. **å¯è§‚æµ‹æ€§**: Prometheusã€ç»“æ„åŒ–æ—¥å¿—ã€å¥åº·æ£€æŸ¥

### æŠ€æœ¯æ·±åº¦

- **å¹¶å‘æ§åˆ¶**: åˆ†å¸ƒå¼é”ã€ä¼šè¯ç®¡ç†
- **AI ç¼–æ’**: å·¥å…·è°ƒç”¨ã€çŠ¶æ€æœºã€æµå¼å¤„ç†
- **çŸ¥è¯†å›¾è°±**: å‘é‡æœç´¢ã€å…³ç³»æ‰©å±•ã€RAG
- **é—å¿˜æ›²çº¿**: è‰¾å®¾æµ©æ–¯ç®—æ³•ã€è¡°å‡è®¡ç®—
- **æ¨é€ç­–ç•¥**: å¤šç­–ç•¥ä¼˜å…ˆçº§ã€ä¸ªæ€§åŒ–ç”Ÿæˆ

### ç”Ÿäº§å°±ç»ªåº¦: 9.5/10

**å·²å®Œæˆ**:
- âœ… å®Œæ•´æ¶æ„è®¾è®¡
- âœ… é”™è¯¯å¤„ç†ä¸é™çº§
- âœ… ç›‘æ§ä¸å‘Šè­¦
- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… å®‰å…¨é˜²æŠ¤

**å»ºè®®æ”¹è¿›**:
- å¢åŠ å•å…ƒæµ‹è¯•è¦†ç›–ç‡
- å®Œå–„ CI/CD æµç¨‹
- å¢åŠ è´Ÿè½½æµ‹è¯•
- å®Œå–„è¿ç»´æ–‡æ¡£

---

**æ–‡æ¡£ç»“æŸ**
*æœ¬æ–‡æ¡£æ¶µç›–äº† Sparkle AI Learning Assistant çš„æ‰€æœ‰æ ¸å¿ƒæŠ€æœ¯ç»†èŠ‚ï¼Œä»å®è§‚æ¶æ„åˆ°å¾®è§‚å®ç°ï¼Œé€‚åˆé«˜çº§å·¥ç¨‹å¸ˆå’ŒæŠ€æœ¯è¯„å§”æ·±å…¥å­¦ä¹ ã€‚*