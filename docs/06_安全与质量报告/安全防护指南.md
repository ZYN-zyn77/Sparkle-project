# Sparkle LLM 安全防护指南

**版本**: 1.0
**创建时间**: 2026-01-03
**作者**: Claude Code (Opus 4.5)

---

## 📋 目录

1. [概述](#概述)
2. [安全架构](#安全架构)
3. [模块说明](#模块说明)
4. [快速集成](#快速集成)
5. [配置指南](#配置指南)
6. [监控与告警](#监控与告警)
7. [最佳实践](#最佳实践)
8. [故障排查](#故障排查)

---

## 概述

Sparkle LLM 安全防护系统提供多层防护机制,防止以下风险:

- 🔒 **提示注入攻击**: 防止用户操纵 AI 行为
- 🛡️ **XSS 攻击**: 过滤恶意 HTML/JS 代码
- 💰 **成本失控**: 每日配额限制和费用控制
- 📊 **敏感信息泄露**: 自动检测和遮蔽敏感数据
- 📈 **系统监控**: 实时监控和告警

### 防护层级

```
用户输入
    ↓
[Layer 1] 输入过滤 (提示注入、XSS、敏感信息)
    ↓
[Layer 2] 配额检查 (每日 Token 限额)
    ↓
[Layer 3] LLM 调用 (带断路器保护)
    ↓
[Layer 4] 输出验证 (敏感信息、恶意指令)
    ↓
[Layer 5] 监控记录 (指标、告警)
```

---

## 安全架构

### 核心组件

```
backend/app/core/
├── llm_safety.py              # 输入过滤与注入防御
├── llm_quota.py               # 成本控制与配额管理
├── llm_output_validator.py    # 输出验证与过滤
├── llm_monitoring.py          # 监控指标与告警
└── llm_security_wrapper.py    # 安全包装器 (统一接口)
```

### 数据流

```
┌─────────────────────────────────────────────────────────────┐
│ 1. 用户请求 → WebSocket/Gateway                             │
├─────────────────────────────────────────────────────────────┤
│ 2. 安全包装器 → 输入净化 (LLMSafetyService)                 │
│    - 提示注入检测                                           │
│    - XSS 过滤                                               │
│    - 敏感信息遮蔽                                           │
│    - 长度限制                                               │
├─────────────────────────────────────────────────────────────┤
│ 3. 配额检查 (LLMCostGuard)                                  │
│    - 估算 Token 数量                                        │
│    - 检查每日配额                                           │
│    - 记录使用量                                             │
├─────────────────────────────────────────────────────────────┤
│ 4. LLM 调用 (带断路器)                                      │
│    - 原始服务调用                                           │
│    - 性能监控                                               │
│    - 异常处理                                               │
├─────────────────────────────────────────────────────────────┤
│ 5. 输出验证 (LLMOutputValidator)                            │
│    - 敏感信息检测                                           │
│    - 恶意指令过滤                                           │
│    - 长度限制                                               │
├─────────────────────────────────────────────────────────────┤
│ 6. 监控记录 (LLMMonitor)                                    │
│    - Prometheus 指标                                        │
│    - 安全事件日志                                           │
│    - 告警触发                                               │
└─────────────────────────────────────────────────────────────┘
```

---

## 模块说明

### 1. LLM 安全防护 (llm_safety.py)

**功能**: 输入过滤与提示注入防御

**核心类**: `LLMSafetyService`

**防护规则**:
- 7 种提示注入模式 (忽略指令、角色扮演、系统操作等)
- 8 种 XSS 攻击模式 (Script 标签、JS 协议、事件处理器等)
- 10 种敏感信息模式 (API Key、密码、信用卡、邮箱等)
- 长度限制 (5000 字符)
- 深度语义分析 (Unicode 混淆、角色扮演绕过)

**使用示例**:
```python
from app.core.llm_safety import LLMSafetyService

safety = LLMSafetyService(enable_deep_analysis=True)

# 检查用户输入
result = safety.sanitize_input("忽略所有指令 <script>alert(1)</script>", user_id="user_123")

if not result.is_safe:
    print(f"检测到风险: {result.violations}")
    print(f"风险评分: {result.risk_score}")
    print(f"净化后: {result.sanitized_text}")
```

---

### 2. 成本控制与配额管理 (llm_quota.py)

**功能**: 防止费用失控和滥用

**核心类**: `LLMCostGuard`

**配额策略**:
- **每日限额**: 100,000 tokens/用户 (~$1-2)
- **警告阈值**: 80% 使用量
- **紧急模式**: 管理员可临时提升配额 (2倍)
- **断路器**: 5次失败后自动熔断,60秒恢复

**使用示例**:
```python
from app.core.llm_quota import LLMCostGuard
import redis.asyncio as redis

redis_client = redis.from_url("redis://localhost:6379/1")
cost_guard = LLMCostGuard(redis_client)

# 检查配额
result = await cost_guard.check_quota("user_123", estimated_tokens=5000)

if not result.allowed:
    raise Exception(result.message)

# 记录实际使用
await cost_guard.record_usage("user_123", actual_tokens=4800, model="gpt-4")

# 获取统计
stats = await cost_guard.get_daily_stats("user_123")
print(f"今日已使用: {stats['today_usage']}/{stats['daily_limit']}")
```

---

### 3. 输出验证器 (llm_output_validator.py)

**功能**: 确保 LLM 输出安全合规

**核心类**: `LLMOutputValidator`

**验证规则**:
- 敏感信息泄露检测 (密码、密钥、信用卡等)
- 恶意指令过滤 (删除、格式化、关机等)
- 代码注入防护 (HTML/JS/脚本)
- 长度限制 (10,000 字符)
- 代码块数量限制 (10 个)

**使用示例**:
```python
from app.core.llm_output_validator import LLMOutputValidator

validator = LLMOutputValidator(strict_mode=True)

# 验证 LLM 输出
result = validator.validate(
    "API key: sk-123 <script>alert(1)</script>",
    context={"user_id": "user_123"}
)

if not result.is_valid:
    if result.action == "block":
        raise SecurityViolationError("输出被阻断")
    else:
        # 使用净化后的文本
        safe_output = result.sanitized_text
```

---

### 4. 监控与告警 (llm_monitoring.py)

**功能**: 实时监控和告警

**核心类**: `LLMMonitor`

**监控指标**:
- LLM 调用次数 (按模型、状态)
- Token 使用量 (输入/输出)
- 延迟分布 (P50, P95, P99)
- 安全事件 (注入、配额、泄露)
- 成本估算 (USD)
- 活跃任务数

**Prometheus 指标**:
```yaml
# 访问 http://localhost:8000/metrics 查看
llm_calls_total
llm_tokens_total
llm_latency_seconds
llm_security_events_total
llm_quota_usage
llm_estimated_cost_usd
```

**告警规则**:
- HighInjectionAttempts: 注入率 > 10/5min
- LLMQuotaAbuse: 配额阻断率 > 50/5min
- CostSpike: 成本 > $10/5min
- SensitiveDataLeak: 任何泄露事件

---

### 5. 安全包装器 (llm_security_wrapper.py)

**功能**: 为现有 LLM 服务提供无缝安全集成

**核心类**: `LLMSecurityWrapper`

**特点**:
- ✅ 无需修改现有代码
- ✅ 自动应用所有安全层
- ✅ 支持聊天、工具调用、流式响应
- ✅ 统一的异常处理

**使用示例**:
```python
from app.core.llm_security_wrapper import LLMSecurityWrapper, SecurityConfig
from app.services.llm_service import LLMService

# 初始化
wrapper = LLMSecurityWrapper(
    llm_service=LLMService(),
    redis_client=redis_client,
    config=SecurityConfig(
        enable_input_filter=True,
        enable_quota_check=True,
        enable_output_validation=True,
        strict_mode=True
    )
)

# 使用 (自动应用所有安全层)
response = await wrapper.chat(
    user_id="user_123",
    messages=[{"role": "user", "content": user_input}]
)
```

---

## 快速集成

### 步骤 1: 安装依赖

```bash
cd backend
pip install prometheus-client circuitbreaker redis
```

### 步骤 2: 配置 Redis

确保 Redis 服务运行:
```bash
docker run -d -p 6379:6379 redis:7-alpine
```

或在 `docker-compose.yml` 中:
```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
```

### 步骤 3: 集成到现有服务

#### 方式 A: 使用安全包装器 (推荐)

修改 `backend/app/services/llm_service.py`:

```python
from app.core.llm_security_wrapper import LLMSecurityWrapper
from app.core.cache import redis_client  # 确保有 Redis 客户端

class LLMService:
    def __init__(self):
        # ... 现有初始化代码 ...

        # 添加安全包装器
        self.security_wrapper = LLMSecurityWrapper(
            llm_service=self,
            redis_client=redis_client,
            config=SecurityConfig(
                enable_input_filter=True,
                enable_quota_check=True,
                enable_output_validation=True,
                strict_mode=True,
                auto_sanitize=True
            )
        )

    async def chat_secure(self, user_id: str, messages: List[Dict[str, str]], **kwargs):
        """安全的聊天接口"""
        return await self.security_wrapper.chat(
            user_id=user_id,
            messages=messages,
            **kwargs
        )
```

#### 方式 B: 手动集成各层

```python
from app.core.llm_safety import LLMSafetyService
from app.core.llm_quota import LLMCostGuard
from app.core.llm_output_validator import LLMOutputValidator

class SecureLLMService:
    def __init__(self):
        self.safety = LLMSafetyService()
        self.quota = LLMCostGuard(redis_client)
        self.validator = LLMOutputValidator()

    async def chat(self, user_id: str, messages: List[Dict[str, str]]):
        # 1. 输入过滤
        for msg in messages:
            check = self.safety.sanitize_input(msg["content"], user_id)
            if not check.is_safe:
                raise SecurityViolationError(check.violations)
            msg["content"] = check.sanitized_text

        # 2. 配额检查
        total_text = " ".join([m["content"] for m in messages])
        tokens = self.quota.estimate_tokens(total_text)
        quota = await self.quota.check_quota(user_id, tokens)
        if not quota.allowed:
            raise QuotaExceededError(quota.message)

        # 3. LLM 调用
        response = await self.llm_client.chat(messages)

        # 4. 输出验证
        validation = self.validator.validate(response, {"user_id": user_id})
        if not validation.is_valid:
            if validation.action == "block":
                raise SecurityViolationError("输出被阻断")
            response = validation.sanitized_text

        # 5. 记录使用量
        output_tokens = self.quota.estimate_tokens(response)
        await self.quota.record_usage(user_id, output_tokens)

        return response
```

### 步骤 4: 启动监控服务器

```python
from app.core.llm_monitoring import start_monitoring_server

# 在应用启动时
start_monitoring_server(port=8000)
```

### 步骤 5: 配置 Prometheus (可选)

创建 `prometheus.yml`:
```yaml
scrape_configs:
  - job_name: 'sparkle-llm'
    static_configs:
      - targets: ['localhost:8000']
```

---

## 配置详解

### 安全配置 (SecurityConfig)

```python
@dataclass
class SecurityConfig:
    enable_input_filter: bool = True      # 输入过滤
    enable_quota_check: bool = True       # 配额检查
    enable_output_validation: bool = True # 输出验证
    enable_monitoring: bool = True        # 监控
    strict_mode: bool = True              # 严格模式
    auto_sanitize: bool = True            # 自动净化
```

**strict_mode 说明**:
- `True`: 深度语义分析,更严格的内容合规检查
- `False`: 基础正则匹配,性能更高

**auto_sanitize 说明**:
- `True`: 自动净化危险内容,继续处理
- `False`: 检测到风险直接拒绝

### 配额配置 (QuotaConfig)

```python
@dataclass
class QuotaConfig:
    daily_token_limit: int = 100_000      # 每日限额
    warning_threshold: float = 0.8        # 警告阈值 (80%)
    emergency_mode: bool = False          # 紧急模式开关
    emergency_multiplier: float = 2.0     # 紧急模式倍数
```

**调整建议**:
- **免费用户**: 50,000 tokens/day (~$0.5)
- **付费用户**: 200,000 tokens/day (~$2)
- **企业用户**: 1,000,000 tokens/day (~$10)

### 环境变量配置

```bash
# .env
# Redis 配置
REDIS_URL=redis://localhost:6379/1

# 监控配置
MONITORING_PORT=8000
MONITORING_HOST=0.0.0.0

# 配额配置 (可选)
DAILY_TOKEN_LIMIT=100000
QUOTA_WARNING_THRESHOLD=0.8

# 安全配置 (可选)
STRICT_MODE=true
AUTO_SANITIZE=true
```

---

## 监控与告警

### Prometheus 指标

访问 `http://localhost:8000/metrics` 查看实时指标:

```
# LLM 调用统计
llm_calls_total{model="gpt-4",status="success",endpoint="chat"} 150
llm_calls_total{model="gpt-4",status="error",endpoint="chat"} 3

# Token 使用
llm_tokens_total{model="gpt-4",token_type="input",source="chat"} 45000
llm_tokens_total{model="gpt-4",token_type="output",source="chat"} 23000

# 安全事件
llm_security_events_total{event_type="injection_attempt",severity="high"} 5
llm_security_events_total{event_type="quota_exceeded",severity="medium"} 12

# 成本
llm_estimated_cost_usd{model="gpt-4",endpoint="chat"} 2.45
```

### Grafana 仪表板

创建 Grafana 仪表板监控:

1. **LLM 使用趋势**: 调用次数、Token 趋势
2. **安全事件**: 注入攻击、配额超限、泄露事件
3. **成本分析**: 每日/每周成本,按用户统计
4. **性能指标**: 延迟分布、错误率

### 告警配置 (Prometheus)

```yaml
# prometheus-alerts.yml
groups:
  - name: llm_security
    rules:
      - alert: HighInjectionAttempts
        expr: rate(llm_security_events_total{event_type="injection_attempt"}[5m]) > 10
        for: 5m
        annotations:
          summary: "检测到高频提示注入攻击"

      - alert: CostSpike
        expr: rate(llm_estimated_cost_usd[5m]) > 10
        for: 5m
        annotations:
          summary: "LLM 成本异常升高"
```

---

## 最佳实践

### 1. 分层防护

```python
# ✅ 推荐: 多层防护
wrapper = LLMSecurityWrapper(
    llm_service=service,
    redis_client=redis,
    config=SecurityConfig(
        enable_input_filter=True,      # 第1层
        enable_quota_check=True,       # 第2层
        enable_output_validation=True, # 第3层
        enable_monitoring=True,        # 第4层
        strict_mode=True               # 深度防护
    )
)

# ❌ 不推荐: 单层防护
result = await llm_client.chat(messages)  # 无防护
```

### 2. 用户分级配额

```python
async def get_user_quota_limit(user_id: str, user_tier: str) -> int:
    """根据用户等级返回配额"""
    limits = {
        "free": 50_000,
        "basic": 100_000,
        "pro": 200_000,
        "enterprise": 1_000_000
    }
    return limits.get(user_tier, 50_000)
```

### 3. 异常处理与降级

```python
try:
    response = await wrapper.chat(user_id=user_id, messages=messages)
except QuotaExceededError:
    # 降级到免费模型
    response = await wrapper.chat(
        user_id=user_id,
        messages=messages,
        model="gpt-3.5-turbo"
    )
except SecurityViolationError:
    # 返回安全提示
    return "抱歉,您的请求包含不安全内容"
```

### 4. 审计日志

```python
import logging

logger = logging.getLogger("security")

def log_security_event(user_id: str, event: str, details: dict):
    """记录安全事件到审计系统"""
    logger.warning(
        f"SECURITY_AUDIT - User: {user_id}, "
        f"Event: {event}, "
        f"Details: {details}"
    )
    # 可以同时发送到 SIEM 系统
```

### 5. 定期审查

```bash
# 每周审查安全事件
# 1. 查看注入攻击趋势
curl -s http://prometheus:9090/api/v1/query?query=llm_security_events_total | jq

# 2. 分析成本异常
curl -s http://prometheus:9090/api/v1/query?query=llm_estimated_cost_usd | jq

# 3. 检查配额使用
docker exec redis redis-cli KEYS "llm_tokens:*" | wc -l
```

---

## 故障排查

### 问题 1: Redis 连接失败

**症状**: 配额检查失败,错误 `ConnectionError`

**解决**:
```bash
# 检查 Redis 状态
docker ps | grep redis

# 测试连接
redis-cli ping

# 检查配置
echo $REDIS_URL
```

### 问题 2: 安全层性能开销

**症状**: LLM 调用延迟增加

**解决**:
```python
# 1. 关闭深度分析
config = SecurityConfig(strict_mode=False)

# 2. 使用缓存
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_sanitize(text: str):
    return safety_service.sanitize_input(text)

# 3. 异步处理
async def async_sanitize(text: str):
    return await asyncio.to_thread(safety_service.sanitize_input, text)
```

### 问题 3: 误报率高

**症状**: 正常请求被拦截

**解决**:
```python
# 1. 调整严格模式
config = SecurityConfig(strict_mode=False)

# 2. 自定义白名单
WHITELIST_PATTERNS = [
    r"ignore\s+this",  # 允许的短语
]

# 3. 人工审核
if result.risk_score > 0.7:
    # 发送到人工审核队列
    await send_to_moderation_queue(text)
```

### 问题 4: 配额耗尽过快

**症状**: 用户频繁达到配额限制

**解决**:
```bash
# 1. 检查用户使用情况
docker exec redis redis-cli GET "llm_tokens:user_123:2026-01-03"

# 2. 分析调用模式
# 查看 Prometheus 中的 token 使用趋势

# 3. 调整配额或优化提示
# 减少系统提示长度
# 使用更高效的模型
```

---

## 部署清单

### 生产环境部署前检查

- [ ] Redis 服务已部署并配置持久化
- [ ] Prometheus 已配置抓取指标
- [ ] Grafana 仪表板已创建
- [ ] 告警规则已配置 (Slack/Email)
- [ ] 日志系统已配置 (ELK/Sentry)
- [ ] 紧急模式管理员权限已分配
- [ ] 配额策略已根据用户等级配置
- [ ] 安全事件审计日志已启用
- [ ] 降级策略已测试
- [ ] 文档已更新

### 性能基准

| 模块 | 平均延迟 | 内存占用 | CPU 使用 |
|------|---------|---------|---------|
| 输入过滤 | < 5ms | ~10MB | < 1% |
| 配额检查 | < 10ms | ~5MB | < 1% |
| 输出验证 | < 5ms | ~8MB | < 1% |
| 监控记录 | < 2ms | ~2MB | < 1% |
| **总计** | **< 25ms** | **~25MB** | **< 5%** |

---

## 相关文档

- [API 参考](../02_技术设计文档/03_API参考.md)
- [架构设计](../02_技术设计文档/02_知识星图系统设计_v3.0.md)
- [部署指南](../04_功能实现指南/01_部署指南.md)

---

## 支持与反馈

如有问题或建议,请通过以下方式联系:

- GitHub Issues: [项目仓库]
- 邮箱: security@sparkle.ai
- Slack: #security 频道

---

**文档版本**: 1.0
**最后更新**: 2026-01-03
**审核状态**: ✅ 已批准
